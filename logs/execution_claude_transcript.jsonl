{"type":"system","subtype":"init","cwd":"/data/hypogenicai/workspaces/llm-washing-machine-claude","session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","tools":["Task","TaskOutput","Bash","Glob","Grep","ExitPlanMode","Read","Edit","Write","NotebookEdit","WebFetch","TodoWrite","WebSearch","TaskStop","AskUserQuestion","Skill","EnterPlanMode","ToolSearch"],"mcp_servers":[],"model":"claude-opus-4-6","permissionMode":"bypassPermissions","slash_commands":["keybindings-help","debug","citation-manager","paper-writer","data-analysis","research-brainstorming","critical-analysis","hypothesis-generation","peer-review","literature-review","grant-writing","paper-finder","code-review:code-review","compact","context","cost","init","pr-comments","release-notes","review","security-review","insights"],"apiKeySource":"none","claude_code_version":"2.1.37","output_style":"default","agents":["Bash","general-purpose","statusline-setup","Explore","Plan"],"skills":["keybindings-help","debug","citation-manager","paper-writer","data-analysis","research-brainstorming","critical-analysis","hypothesis-generation","peer-review","literature-review","grant-writing","paper-finder"],"plugins":[{"name":"code-review","path":"/home/haokunliu/.claude/plugins/cache/claude-plugins-official/code-review/2cd88e7947b7"}],"uuid":"869046a3-2026-4439-a5e4-1a40b2302aea"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01V1JpasWWUmm46aCv41VtXz","type":"message","role":"assistant","content":[{"type":"text","text":"\n\nI'll begin this research session by reviewing the pre-gathered resources, then execute all phases systematically. Let me start by reading the existing resources and checking the environment."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":19540,"cache_read_input_tokens":15360,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":19540},"output_tokens":2,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"5758e3ac-9cf4-41a6-9487-17ebaf004de1"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01V1JpasWWUmm46aCv41VtXz","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01Pt1wZ8Y6gjn5MLqvKXr1ia","name":"TodoWrite","input":{"todos":[{"content":"Review pre-gathered resources (literature_review.md, resources.md, papers/, datasets/, code/)","status":"in_progress","activeForm":"Reviewing pre-gathered resources"},{"content":"Phase 0: Motivation & Novelty Assessment","status":"pending","activeForm":"Writing motivation and novelty assessment"},{"content":"Phase 1: Create detailed research plan (planning.md)","status":"pending","activeForm":"Creating research plan"},{"content":"Phase 2: Environment & data setup","status":"pending","activeForm":"Setting up environment and data"},{"content":"Phase 3: Implementation - write experiment code","status":"pending","activeForm":"Implementing experiment code"},{"content":"Phase 4: Run experiments","status":"pending","activeForm":"Running experiments"},{"content":"Phase 5: Analysis - statistical analysis and visualizations","status":"pending","activeForm":"Analyzing results"},{"content":"Phase 6: Final documentation (REPORT.md, README.md)","status":"pending","activeForm":"Writing final documentation"}]}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":19540,"cache_read_input_tokens":15360,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":19540},"output_tokens":2,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"6c3772a3-6c90-4b3f-8d2f-6fa6308b4ce6"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Pt1wZ8Y6gjn5MLqvKXr1ia","type":"tool_result","content":"Todos have been modified successfully. Ensure that you continue to use the todo list to track your progress. Please proceed with the current tasks if applicable"}]},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"f52efc91-1825-406f-b9b5-defb67e82d2a","tool_use_result":{"oldTodos":[],"newTodos":[{"content":"Review pre-gathered resources (literature_review.md, resources.md, papers/, datasets/, code/)","status":"in_progress","activeForm":"Reviewing pre-gathered resources"},{"content":"Phase 0: Motivation & Novelty Assessment","status":"pending","activeForm":"Writing motivation and novelty assessment"},{"content":"Phase 1: Create detailed research plan (planning.md)","status":"pending","activeForm":"Creating research plan"},{"content":"Phase 2: Environment & data setup","status":"pending","activeForm":"Setting up environment and data"},{"content":"Phase 3: Implementation - write experiment code","status":"pending","activeForm":"Implementing experiment code"},{"content":"Phase 4: Run experiments","status":"pending","activeForm":"Running experiments"},{"content":"Phase 5: Analysis - statistical analysis and visualizations","status":"pending","activeForm":"Analyzing results"},{"content":"Phase 6: Final documentation (REPORT.md, README.md)","status":"pending","activeForm":"Writing final documentation"}]}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01D4JQDWJQHz3q5jfMJUffD8","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01WHMGqvA3EUNFb2QAKp4RZi","name":"Read","input":{"file_path":"/data/hypogenicai/workspaces/llm-washing-machine-claude/literature_review.md"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":405,"cache_read_input_tokens":34900,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":405},"output_tokens":25,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"cd36093c-c9e9-414d-867c-2a074e6f1cbd"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01WHMGqvA3EUNFb2QAKp4RZi","type":"tool_result","content":"     1→# Literature Review: Where is \"Washing Machine\" Stored in LLMs?\n     2→\n     3→## Research Area Overview\n     4→\n     5→This literature review surveys work relevant to understanding how compound concepts such as \"washing machine\" are represented in large language models (LLMs). The central hypothesis is that LLMs may not store compound concepts as unique directions in the residual stream; instead, they may store constituent parts (e.g., \"washing\") and rely on context to increase the likelihood of the subsequent token (\"machine\"). This question sits at the intersection of three active research areas: (1) the linear representation hypothesis and concept geometry in neural networks, (2) mechanistic interpretability through sparse autoencoders, and (3) compositional semantics and multi-token concept processing in transformers.\n     6→\n     7→---\n     8→\n     9→## 1. Linear Representation Hypothesis and Concept Directions\n    10→\n    11→### Foundational Theory\n    12→\n    13→**Park et al. (2024)** — \"The Linear Representation Hypothesis and the Geometry of Large Language Models\" — provides the most rigorous formalization of what it means for a concept to be \"stored as a direction\" in an LLM. They distinguish three variants of the hypothesis:\n    14→- **Subspace hypothesis**: Concepts correspond to directions in activation space (e.g., γ(\"queen\") − γ(\"king\") ≈ gender direction)\n    15→- **Measurement hypothesis**: Linear probes can predict concept presence from activations\n    16→- **Intervention hypothesis**: Adding concept vectors to activations steers model behavior\n    17→\n    18→They tested 27 concepts on LLaMA-2-7B using the BATS 3.0 dataset and found strong linear structure for 26/27 concepts. Critically, **the only concept that failed was the compositional relation \"thing→part\"**, suggesting that compositional/relational concepts may not follow the same linear representation pattern as simple attribute concepts. They also emphasize that the correct inner product for measuring concept geometry is the **causal inner product** (using the inverse covariance of unembeddings), not naive Euclidean distance. **Limitation**: Only single-token concepts were tested — multi-token compound concepts like \"washing machine\" remain unexplored.\n    19→\n    20→**Code**: github.com/KihoPark/linear_rep_geometry\n    21→\n    22→### Related Representation Work\n    23→\n    24→**Gurnee & Tegmark (2023)** showed that LLMs develop linear representations of space and time, with specific directions encoding geographic coordinates and temporal information. **Merullo et al. (2023)** demonstrated that LLMs implement Word2Vec-style vector arithmetic for relational tasks, suggesting that the additive composition principle (king − man + woman = queen) may apply to some multi-token constructs. **Arora et al. (2016)** showed that polysemous word senses reside in linear superposition within word embeddings, recoverable via sparse coding — a precursor to modern SAE work.\n    25→\n    26→### Implications for Compound Concepts\n    27→If \"washing machine\" has a unique direction, it should be recoverable via probing or steering. If it is compositionally derived, the direction should approximately equal some function of the \"washing\" and \"machine\" directions. The failure of \"thing→part\" relations in Park et al. suggests that relational/compositional concepts may require a different framework.\n    28→\n    29→---\n    30→\n    31→## 2. Superposition and Polysemanticity\n    32→\n    33→### Theoretical Foundation\n    34→\n    35→**Elhage et al. (2022)** — \"Toy Models of Superposition\" — established the theoretical framework for understanding how neural networks represent more features than they have dimensions. Key findings:\n    36→- **Superposition**: Models store sparse features as nearly-orthogonal directions, tolerating interference between features\n    37→- **Phase transitions**: Whether features use superposition depends on their sparsity and importance — sparse features (like \"washing machine\" occurrences) are MORE likely to be in superposition\n    38→- **Geometric structure**: Features arrange into regular polytopes (triangles, pentagons, tetrahedra), following solutions to the Thomson problem\n    39→- **Implication**: \"Washing machine\" as a concept is almost certainly NOT stored in a dedicated neuron but rather as a direction in superposition with other concepts\n    40→\n    41→**Scherlis et al. (2022)** — \"Polysemanticity and Capacity in Neural Networks\" — further analyzed why neurons become polysemantic, finding it emerges naturally from capacity constraints.\n    42→\n    43→### Practical Consequence\n    44→Any experiment probing for \"washing machine\" must account for superposition. Looking at individual neurons will fail; instead, we need directional analysis (probing classifiers, SAE features, or concept vectors in the residual stream).\n    45→\n    46→---\n    47→\n    48→## 3. Sparse Autoencoders for Feature Discovery\n    49→\n    50→### Core SAE Work\n    51→\n    52→**Cunningham et al. (2023)** introduced using SAEs to decompose polysemantic activations into interpretable, monosemantic features. **Gao et al. (2024)** scaled SAEs significantly and established evaluation metrics. **Rajamanoharan et al. (2024)** introduced Gated SAEs for improved dictionary learning. **Bussmann et al. (2024)** proposed BatchTopK SAEs. **Lieberum et al. (2024)** released Gemma Scope, providing pre-trained SAEs across all layers of Gemma-2 models. **He et al. (2024)** released Llama Scope with 256 SAEs across Llama-3.1-8B.\n    53→\n    54→### Feature Absorption Problem\n    55→\n    56→**Chanin et al. (2024)** — \"A is for Absorption\" — identified a critical problem for using SAEs to study compound concepts:\n    57→- **Feature absorption**: When features form hierarchies (e.g., \"washing machine\" → \"appliance\"), SAEs optimize for sparsity by absorbing parent features into child features, creating unreliable classifiers with arbitrary false negatives\n    58→- **Universal**: Every SAE tested (across Gemma-2-2B, Qwen2, Llama 3.2, with hundreds of SAEs) exhibited absorption\n    59→- **No fix**: No hyperparameter configuration solves it; it's inherent to the L1-sparsity objective\n    60→- **Implication**: SAE features for compound concepts may be unreliable — a \"washing machine\" feature might fail to fire on arbitrary instances because more specific features absorb it\n    61→\n    62→**Code**: github.com/lasr-spelling/sae-spelling\n    63→\n    64→### Feature Hedging\n    65→\n    66→**Chanin et al. (2025)** — \"Feature Hedging\" — showed that if SAEs are narrower than the true number of features and features are correlated, SAEs merge components into composite representations. This could cause compound concepts to be merged with semantically related concepts.\n    67→\n    68→### Dark Matter in SAEs\n    69→\n    70→**Engels et al. (2024)** analyzed the \"dark matter\" of SAEs — unexplained variance that SAEs fail to capture. This is relevant because compound concept representations may partially reside in this unexplained variance.\n    71→\n    72→### Practical Guidance for Experiments\n    73→- Use multiple SAE widths (16k, 65k, 128k) to check for feature splitting\n    74→- Verify features with ablation studies, not just max-activating examples\n    75→- Check for absorption: does a \"washing machine\" feature fire on all instances, or does it get absorbed into sub-features?\n    76→- Consider using the footprints/token erasure approach instead of or alongside SAEs\n    77→\n    78→---\n    79→\n    80→## 4. Multi-Token Concept Processing\n    81→\n    82→### Token Erasure (Most Directly Relevant)\n    83→\n    84→**Feucht et al. (2024)** — \"Token Erasure as a Footprint of Implicit Vocabulary Items in LLMs\" — is the most directly relevant work. Key findings:\n    85→\n    86→- **Token erasure**: At the last token position of multi-token words/entities, information about preceding tokens is rapidly \"erased\" (transformed) in early layers (1–9)\n    87→- **Implicit vocabulary**: LLMs develop internal representations for semantically meaningful units beyond their BPE token vocabulary — an \"implicit vocabulary\" of multi-token items\n    88→- **Mechanism**: Information transforms from token-level encoding to lexical-level encoding at the last token position, due to the autoregressive constraint (the model can only represent \"Space Needle\" after seeing \"Needle\")\n    89→- **Models**: Tested on Llama-2-7B and Llama-3-8B; similar patterns despite very different tokenizations\n    90→- **Measurement**: Linear probes trained on hidden states; accuracy for predicting preceding tokens drops from ~100% (layer 0) to ~20% (layer 9) at the last position of multi-token entities\n    91→\n    92→**Direct application to \"washing machine\"**: If \"washing machine\" is treated as a lexical unit by the model, we should observe token erasure at the \"machine\" token position — the hidden state for \"machine\" would \"forget\" the \"washing\" token information in early layers as it assembles the compound concept representation. Comparing this to compositional phrases like \"red machine\" (which should show less erasure) would test whether the model treats \"washing machine\" as a unified concept.\n    93→\n    94→**Code**: footprints.baulab.info, github.com/sfeucht/footprints\n    95→\n    96→### FFN Layer Concept Promotion\n    97→\n    98→**Geva et al. (2022)** — \"Transformer Feed-Forward Layers Build Predictions by Promoting Concepts in the Vocabulary Space\" — showed that:\n    99→- FFN layers build predictions through sub-updates that \"promote\" specific tokens/concepts\n   100→- Each value vector in the FFN encodes interpretable concepts\n   101→- Predictions are built gradually across layers via promotion rather than elimination\n   102→- **Relevance**: After processing \"washing\", FFN layers may promote \"machine\" through value vectors that encode the \"appliance\" concept, gradually increasing P(\"machine\") across layers\n   103→\n   104→### Compositional Probe Evidence\n   105→\n   106→**Ormerod et al. (2024)** — \"How Is a 'Kitchen Chair' like a 'Farm Horse'?\" — provides the most directly relevant probing study for compound noun semantics:\n   107→- Used Representational Similarity Analysis (RSA) to compare transformer representations with human judgments of compound noun thematic relations\n   108→- **Key experiment**: Compared representations when head+modifier are processed **together** (as compound) vs. **separately** (in different sentences)\n   109→- **Results**: RoBERTa and DistilRoBERTa show significantly stronger compound semantic representations in the \"together\" condition — evidence of genuine compositional processing, not just co-occurrence memorization\n   110→- **XLNet**: Relied more on distributional co-occurrence information from individual words\n   111→- **Datasets**: 300 compounds from Gagné (2001), 60 compounds with fine-grained 18-dimensional relation vectors from Devereux & Costello (2005)\n   112→- **Limitation**: Used BERT-family masked language models, not autoregressive GPT-family models\n   113→\n   114→---\n   115→\n   116→## 5. Compositionality and Idiomaticity\n   117→\n   118→### Token Compositionality Analysis\n   119→\n   120→**Aljaafari et al. (2024)** — \"Interpreting token compositionality in LLMs\" — introduced Constituent-Aware Pooling (CAP) to test compositional processing:\n   121→- **Finding**: No specific layer integrates tokens into unified semantic representations based on constituent parts\n   122→- **Fragmented processing**: Information is distributed across layers with long dependency paths\n   123→- **Larger models are worse**: Larger models exhibit greater information dispersion and fragmentation, suggesting scaling doesn't improve compositional integration\n   124→- **Implication**: LLMs may process \"washing machine\" through fragmented, distributed mechanisms rather than composing a unified compound representation at any single layer\n   125→\n   126→### Idiomaticity Probing\n   127→\n   128→**Garcia et al. (2021)** — \"Probing for idiomaticity in vector space models\" — tested whether BERT captures idiomatic vs. compositional meanings of noun compounds:\n   129→- **Finding**: Contextualised models fail to accurately capture idiomaticity\n   130→- Models prioritize lexical overlap over semantic understanding\n   131→- Context plays a surprisingly limited role in disambiguating compositional vs. idiomatic readings\n   132→- Developed the Noun Compound Senses (NCS) dataset with 280 English and 180 Portuguese compounds\n   133→\n   134→### Transformer Compositional Processing\n   135→\n   136→**Dankers et al. (2022)** — \"Can Transformer be Too Compositional?\" — analyzed idiom processing in NMT:\n   137→- Transformers tend to over-generate compositional translations of idioms\n   138→- Models struggle with non-compositional multi-word expressions\n   139→- Suggests a bias toward compositional processing even when inappropriate\n   140→\n   141→**Buijtelaar et al. (2023)** — \"A Psycholinguistic Analysis of BERT's Representations of Compounds\" — found that BERT's representations of compounds align with human semantic intuitions about compound meaning, but the alignment varies by layer.\n   142→\n   143→---\n   144→\n   145→## 6. Common Methodologies and Baselines\n   146→\n   147→### Probing Methods\n   148→- **Linear probes**: Train linear classifiers on hidden states to predict concept properties (Park et al., Feucht et al.)\n   149→- **RSA (Representational Similarity Analysis)**: Compare model RDMs with human judgment RDMs (Ormerod et al.)\n   150→- **Causal interventions**: Patch/ablate hidden states to test causal role of representations (Turner et al., Hernandez et al.)\n   151→- **SAE feature analysis**: Decompose activations using SAEs and inspect features (Cunningham et al., Chanin et al.)\n   152→\n   153→### Standard Baselines\n   154→- **Random baseline**: Permuted/shuffled labels for probing\n   155→- **Separate processing baseline**: Process constituent words in separate contexts (Ormerod et al.'s \"Separate\" condition)\n   156→- **Compositional control**: Compare compound nouns to clearly compositional phrases (e.g., \"washing machine\" vs. \"red machine\")\n   157→- **Different tokenizations**: Compare models with different BPE vocabularies to control for tokenization effects\n   158→\n   159→### Evaluation Metrics\n   160→- **Probe accuracy**: How well can a linear probe recover concept information\n   161→- **Erasure score (ψ)**: Quantifies token-level information loss (Feucht et al.)\n   162→- **RSA correlation**: Second-order correlation between model and human RDMs\n   163→- **Steering effect size**: Change in model behavior when adding concept vectors\n   164→- **SAE feature F1**: How reliably an SAE feature tracks a target concept\n   165→\n   166→---\n   167→\n   168→## 7. Datasets in the Literature\n   169→\n   170→| Dataset | Used In | Type | Size | Relevance |\n   171→|---------|---------|------|------|-----------|\n   172→| Gagné (2001) compounds | Ormerod et al. | 300 compounds, 16 relations | 300 | High |\n   173→| Devereux & Costello (2005) | Ormerod et al. | 60 compounds, 18-dim relation vectors | 60 | High |\n   174→| NCS (Garcia et al.) | Garcia et al. | Compounds with compositionality ratings | 280 EN, 180 PT | High |\n   175→| COUNTERFACT | Feucht et al. | Factual prompts with entities | 12K+ | Medium |\n   176→| MAGPIE | Idiom research | Idiom instances with labels | 56K | Medium |\n   177→| BATS 3.0 | Park et al. | Analogy/relation pairs | ~40 relations | Medium |\n   178→| The Pile | Feucht et al. | General text (probe training) | 800GB | Medium |\n   179→\n   180→---\n   181→\n   182→## 8. Gaps and Opportunities\n   183→\n   184→### Key Gap: No Study Directly Tests Compound Noun Directions in Residual Stream\n   185→- Park et al. tested single-token concepts but not multi-token compounds\n   186→- Ormerod et al. used masked LMs (BERT), not autoregressive models\n   187→- Feucht et al. focused on named entities, not common compound nouns\n   188→- No study has used SAEs to find features specifically for compound nouns like \"washing machine\"\n   189→\n   190→### Opportunity 1: Token Erasure for Compound Nouns\n   191→Adapt Feucht et al.'s methodology to test whether \"washing machine\" shows erasure patterns (suggesting unified representation) or maintains token-level information (suggesting compositional processing). Compare to compositional controls.\n   192→\n   193→### Opportunity 2: SAE Feature Analysis of Compound Concepts\n   194→Use pre-trained SAEs (Gemma Scope, Llama Scope) to search for features that specifically activate for \"washing machine\" as a compound, vs. features for \"washing\" and \"machine\" separately. Test for absorption effects.\n   195→\n   196→### Opportunity 3: Directional Probing with Causal Inner Product\n   197→Apply Park et al.'s framework to multi-token compounds: estimate the causal inner product, find concept directions for \"washing machine\" vs. constituent words, and test whether the compound direction is linearly independent of constituent directions.\n   198→\n   199→### Opportunity 4: Compositional vs. Holistic Representation Spectrum\n   200→Build a controlled dataset of compound nouns varying in compositionality (from \"coffee table\" to \"hot dog\") and measure representation properties across this spectrum — erasure scores, SAE feature patterns, probe accuracy, and steering effects.\n   201→\n   202→---\n   203→\n   204→## 9. Recommendations for Experiments\n   205→\n   206→### Primary Methodology: Token Erasure Analysis\n   207→1. Use Feucht et al.'s linear probes on Llama-2-7B or Llama-3-8B\n   208→2. Measure erasure scores for compound nouns varying in compositionality\n   209→3. Compare: \"washing machine\" (compound) vs. \"red machine\" (compositional) vs. \"hot dog\" (idiomatic)\n   210→\n   211→### Secondary Methodology: SAE Feature Search\n   212→1. Use pre-trained SAEs (Gemma Scope or Llama Scope)\n   213→2. Search for features that activate on compound nouns\n   214→3. Test for feature absorption: does the compound feature reliably fire?\n   215→4. Compare feature patterns across compositionality spectrum\n   216→\n   217→### Tertiary Methodology: Concept Direction Analysis\n   218→1. Collect contexts where \"washing machine\" appears vs. related contexts\n   219→2. Estimate concept directions using mean-difference or probing\n   220→3. Test: is the \"washing machine\" direction independent of \"washing\" and \"machine\" directions?\n   221→4. Measure causal effects of steering with compound vs. constituent vectors\n   222→\n   223→### Recommended Models\n   224→- **Llama-2-7B** or **Llama-3-8B**: Best supported by existing tools and pre-trained probes\n   225→- **Gemma-2-2B**: Best SAE coverage via Gemma Scope\n   226→- **GPT-2-small**: Good for initial experiments due to size and tooling support\n   227→\n   228→### Recommended Metrics\n   229→1. Erasure score (ψ) — quantifies lexicality\n   230→2. Probe accuracy across layers — maps representation formation\n   231→3. SAE feature reliability (F1) — tests feature absorption\n   232→4. Steering effect size — causal validation\n   233→5. Cosine similarity between compound and constituent directions\n   234→\n   235→---\n   236→\n   237→## References\n   238→\n   239→1. Aljaafari, N. et al. (2024). Interpreting token compositionality in LLMs. arXiv:2410.12924.\n   240→2. Arora, S. et al. (2016). Linear Algebraic Structure of Word Senses. arXiv:1601.03764.\n   241→3. Buijtelaar, L. et al. (2023). A Psycholinguistic Analysis of BERT's Representations of Compounds.\n   242→4. Bussmann, B. et al. (2024). BatchTopK Sparse Autoencoders. arXiv:2409.06981.\n   243→5. Chanin, D. et al. (2024). A is for Absorption. arXiv:2409.14507.\n   244→6. Chanin, D. et al. (2025). Feature Hedging. arXiv:2503.01370.\n   245→7. Cunningham, H. et al. (2023). Sparse Autoencoders Find Highly Interpretable Features. arXiv:2309.08600.\n   246→8. Dankers, V. et al. (2022). Can Transformer be Too Compositional? arXiv:2205.15301.\n   247→9. Elhage, N. et al. (2022). Toy Models of Superposition. arXiv:2209.10652.\n   248→10. Engels, J. et al. (2024). Decomposing The Dark Matter of SAEs. arXiv:2410.14670.\n   249→11. Feucht, S. et al. (2024). Token Erasure as a Footprint of Implicit Vocabulary Items. arXiv:2406.20086.\n   250→12. Gao, L. et al. (2024). Scaling and evaluating sparse autoencoders. arXiv:2406.04093.\n   251→13. Garcia, M. et al. (2021). Probing for idiomaticity in vector space models. EACL 2021.\n   252→14. Geva, M. et al. (2022). Transformer Feed-Forward Layers Build Predictions. arXiv:2203.14680.\n   253→15. Gurnee, W. & Tegmark, M. (2023). Language Models Represent Space and Time. arXiv:2310.02207.\n   254→16. He, Z. et al. (2024). Llama Scope. arXiv:2410.20526.\n   255→17. Hernandez, E. et al. (2023). Linearity of Relation Decoding. arXiv:2308.09124.\n   256→18. Lieberum, T. et al. (2024). Gemma Scope. arXiv:2408.05147.\n   257→19. Merullo, J. et al. (2023). Language Models Implement Simple Word2Vec-style Vector Arithmetic. arXiv:2305.16130.\n   258→20. Ormerod, M. et al. (2024). How Is a \"Kitchen Chair\" like a \"Farm Horse\"? Computational Linguistics, 50(1).\n   259→21. Park, K. et al. (2024). The Linear Representation Hypothesis. arXiv:2311.03658.\n   260→22. Rajamanoharan, S. et al. (2024). Improving Dictionary Learning with Gated SAEs. arXiv:2404.16014.\n   261→23. Scherlis, A. et al. (2022). Polysemanticity and Capacity in Neural Networks. arXiv:2210.01892.\n   262→24. Turner, A. et al. (2023). Steering Language Models With Activation Engineering. arXiv:2308.10248.\n   263→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"c49b847b-d535-4718-bb98-c16370b09d84","tool_use_result":{"type":"text","file":{"filePath":"/data/hypogenicai/workspaces/llm-washing-machine-claude/literature_review.md","content":"# Literature Review: Where is \"Washing Machine\" Stored in LLMs?\n\n## Research Area Overview\n\nThis literature review surveys work relevant to understanding how compound concepts such as \"washing machine\" are represented in large language models (LLMs). The central hypothesis is that LLMs may not store compound concepts as unique directions in the residual stream; instead, they may store constituent parts (e.g., \"washing\") and rely on context to increase the likelihood of the subsequent token (\"machine\"). This question sits at the intersection of three active research areas: (1) the linear representation hypothesis and concept geometry in neural networks, (2) mechanistic interpretability through sparse autoencoders, and (3) compositional semantics and multi-token concept processing in transformers.\n\n---\n\n## 1. Linear Representation Hypothesis and Concept Directions\n\n### Foundational Theory\n\n**Park et al. (2024)** — \"The Linear Representation Hypothesis and the Geometry of Large Language Models\" — provides the most rigorous formalization of what it means for a concept to be \"stored as a direction\" in an LLM. They distinguish three variants of the hypothesis:\n- **Subspace hypothesis**: Concepts correspond to directions in activation space (e.g., γ(\"queen\") − γ(\"king\") ≈ gender direction)\n- **Measurement hypothesis**: Linear probes can predict concept presence from activations\n- **Intervention hypothesis**: Adding concept vectors to activations steers model behavior\n\nThey tested 27 concepts on LLaMA-2-7B using the BATS 3.0 dataset and found strong linear structure for 26/27 concepts. Critically, **the only concept that failed was the compositional relation \"thing→part\"**, suggesting that compositional/relational concepts may not follow the same linear representation pattern as simple attribute concepts. They also emphasize that the correct inner product for measuring concept geometry is the **causal inner product** (using the inverse covariance of unembeddings), not naive Euclidean distance. **Limitation**: Only single-token concepts were tested — multi-token compound concepts like \"washing machine\" remain unexplored.\n\n**Code**: github.com/KihoPark/linear_rep_geometry\n\n### Related Representation Work\n\n**Gurnee & Tegmark (2023)** showed that LLMs develop linear representations of space and time, with specific directions encoding geographic coordinates and temporal information. **Merullo et al. (2023)** demonstrated that LLMs implement Word2Vec-style vector arithmetic for relational tasks, suggesting that the additive composition principle (king − man + woman = queen) may apply to some multi-token constructs. **Arora et al. (2016)** showed that polysemous word senses reside in linear superposition within word embeddings, recoverable via sparse coding — a precursor to modern SAE work.\n\n### Implications for Compound Concepts\nIf \"washing machine\" has a unique direction, it should be recoverable via probing or steering. If it is compositionally derived, the direction should approximately equal some function of the \"washing\" and \"machine\" directions. The failure of \"thing→part\" relations in Park et al. suggests that relational/compositional concepts may require a different framework.\n\n---\n\n## 2. Superposition and Polysemanticity\n\n### Theoretical Foundation\n\n**Elhage et al. (2022)** — \"Toy Models of Superposition\" — established the theoretical framework for understanding how neural networks represent more features than they have dimensions. Key findings:\n- **Superposition**: Models store sparse features as nearly-orthogonal directions, tolerating interference between features\n- **Phase transitions**: Whether features use superposition depends on their sparsity and importance — sparse features (like \"washing machine\" occurrences) are MORE likely to be in superposition\n- **Geometric structure**: Features arrange into regular polytopes (triangles, pentagons, tetrahedra), following solutions to the Thomson problem\n- **Implication**: \"Washing machine\" as a concept is almost certainly NOT stored in a dedicated neuron but rather as a direction in superposition with other concepts\n\n**Scherlis et al. (2022)** — \"Polysemanticity and Capacity in Neural Networks\" — further analyzed why neurons become polysemantic, finding it emerges naturally from capacity constraints.\n\n### Practical Consequence\nAny experiment probing for \"washing machine\" must account for superposition. Looking at individual neurons will fail; instead, we need directional analysis (probing classifiers, SAE features, or concept vectors in the residual stream).\n\n---\n\n## 3. Sparse Autoencoders for Feature Discovery\n\n### Core SAE Work\n\n**Cunningham et al. (2023)** introduced using SAEs to decompose polysemantic activations into interpretable, monosemantic features. **Gao et al. (2024)** scaled SAEs significantly and established evaluation metrics. **Rajamanoharan et al. (2024)** introduced Gated SAEs for improved dictionary learning. **Bussmann et al. (2024)** proposed BatchTopK SAEs. **Lieberum et al. (2024)** released Gemma Scope, providing pre-trained SAEs across all layers of Gemma-2 models. **He et al. (2024)** released Llama Scope with 256 SAEs across Llama-3.1-8B.\n\n### Feature Absorption Problem\n\n**Chanin et al. (2024)** — \"A is for Absorption\" — identified a critical problem for using SAEs to study compound concepts:\n- **Feature absorption**: When features form hierarchies (e.g., \"washing machine\" → \"appliance\"), SAEs optimize for sparsity by absorbing parent features into child features, creating unreliable classifiers with arbitrary false negatives\n- **Universal**: Every SAE tested (across Gemma-2-2B, Qwen2, Llama 3.2, with hundreds of SAEs) exhibited absorption\n- **No fix**: No hyperparameter configuration solves it; it's inherent to the L1-sparsity objective\n- **Implication**: SAE features for compound concepts may be unreliable — a \"washing machine\" feature might fail to fire on arbitrary instances because more specific features absorb it\n\n**Code**: github.com/lasr-spelling/sae-spelling\n\n### Feature Hedging\n\n**Chanin et al. (2025)** — \"Feature Hedging\" — showed that if SAEs are narrower than the true number of features and features are correlated, SAEs merge components into composite representations. This could cause compound concepts to be merged with semantically related concepts.\n\n### Dark Matter in SAEs\n\n**Engels et al. (2024)** analyzed the \"dark matter\" of SAEs — unexplained variance that SAEs fail to capture. This is relevant because compound concept representations may partially reside in this unexplained variance.\n\n### Practical Guidance for Experiments\n- Use multiple SAE widths (16k, 65k, 128k) to check for feature splitting\n- Verify features with ablation studies, not just max-activating examples\n- Check for absorption: does a \"washing machine\" feature fire on all instances, or does it get absorbed into sub-features?\n- Consider using the footprints/token erasure approach instead of or alongside SAEs\n\n---\n\n## 4. Multi-Token Concept Processing\n\n### Token Erasure (Most Directly Relevant)\n\n**Feucht et al. (2024)** — \"Token Erasure as a Footprint of Implicit Vocabulary Items in LLMs\" — is the most directly relevant work. Key findings:\n\n- **Token erasure**: At the last token position of multi-token words/entities, information about preceding tokens is rapidly \"erased\" (transformed) in early layers (1–9)\n- **Implicit vocabulary**: LLMs develop internal representations for semantically meaningful units beyond their BPE token vocabulary — an \"implicit vocabulary\" of multi-token items\n- **Mechanism**: Information transforms from token-level encoding to lexical-level encoding at the last token position, due to the autoregressive constraint (the model can only represent \"Space Needle\" after seeing \"Needle\")\n- **Models**: Tested on Llama-2-7B and Llama-3-8B; similar patterns despite very different tokenizations\n- **Measurement**: Linear probes trained on hidden states; accuracy for predicting preceding tokens drops from ~100% (layer 0) to ~20% (layer 9) at the last position of multi-token entities\n\n**Direct application to \"washing machine\"**: If \"washing machine\" is treated as a lexical unit by the model, we should observe token erasure at the \"machine\" token position — the hidden state for \"machine\" would \"forget\" the \"washing\" token information in early layers as it assembles the compound concept representation. Comparing this to compositional phrases like \"red machine\" (which should show less erasure) would test whether the model treats \"washing machine\" as a unified concept.\n\n**Code**: footprints.baulab.info, github.com/sfeucht/footprints\n\n### FFN Layer Concept Promotion\n\n**Geva et al. (2022)** — \"Transformer Feed-Forward Layers Build Predictions by Promoting Concepts in the Vocabulary Space\" — showed that:\n- FFN layers build predictions through sub-updates that \"promote\" specific tokens/concepts\n- Each value vector in the FFN encodes interpretable concepts\n- Predictions are built gradually across layers via promotion rather than elimination\n- **Relevance**: After processing \"washing\", FFN layers may promote \"machine\" through value vectors that encode the \"appliance\" concept, gradually increasing P(\"machine\") across layers\n\n### Compositional Probe Evidence\n\n**Ormerod et al. (2024)** — \"How Is a 'Kitchen Chair' like a 'Farm Horse'?\" — provides the most directly relevant probing study for compound noun semantics:\n- Used Representational Similarity Analysis (RSA) to compare transformer representations with human judgments of compound noun thematic relations\n- **Key experiment**: Compared representations when head+modifier are processed **together** (as compound) vs. **separately** (in different sentences)\n- **Results**: RoBERTa and DistilRoBERTa show significantly stronger compound semantic representations in the \"together\" condition — evidence of genuine compositional processing, not just co-occurrence memorization\n- **XLNet**: Relied more on distributional co-occurrence information from individual words\n- **Datasets**: 300 compounds from Gagné (2001), 60 compounds with fine-grained 18-dimensional relation vectors from Devereux & Costello (2005)\n- **Limitation**: Used BERT-family masked language models, not autoregressive GPT-family models\n\n---\n\n## 5. Compositionality and Idiomaticity\n\n### Token Compositionality Analysis\n\n**Aljaafari et al. (2024)** — \"Interpreting token compositionality in LLMs\" — introduced Constituent-Aware Pooling (CAP) to test compositional processing:\n- **Finding**: No specific layer integrates tokens into unified semantic representations based on constituent parts\n- **Fragmented processing**: Information is distributed across layers with long dependency paths\n- **Larger models are worse**: Larger models exhibit greater information dispersion and fragmentation, suggesting scaling doesn't improve compositional integration\n- **Implication**: LLMs may process \"washing machine\" through fragmented, distributed mechanisms rather than composing a unified compound representation at any single layer\n\n### Idiomaticity Probing\n\n**Garcia et al. (2021)** — \"Probing for idiomaticity in vector space models\" — tested whether BERT captures idiomatic vs. compositional meanings of noun compounds:\n- **Finding**: Contextualised models fail to accurately capture idiomaticity\n- Models prioritize lexical overlap over semantic understanding\n- Context plays a surprisingly limited role in disambiguating compositional vs. idiomatic readings\n- Developed the Noun Compound Senses (NCS) dataset with 280 English and 180 Portuguese compounds\n\n### Transformer Compositional Processing\n\n**Dankers et al. (2022)** — \"Can Transformer be Too Compositional?\" — analyzed idiom processing in NMT:\n- Transformers tend to over-generate compositional translations of idioms\n- Models struggle with non-compositional multi-word expressions\n- Suggests a bias toward compositional processing even when inappropriate\n\n**Buijtelaar et al. (2023)** — \"A Psycholinguistic Analysis of BERT's Representations of Compounds\" — found that BERT's representations of compounds align with human semantic intuitions about compound meaning, but the alignment varies by layer.\n\n---\n\n## 6. Common Methodologies and Baselines\n\n### Probing Methods\n- **Linear probes**: Train linear classifiers on hidden states to predict concept properties (Park et al., Feucht et al.)\n- **RSA (Representational Similarity Analysis)**: Compare model RDMs with human judgment RDMs (Ormerod et al.)\n- **Causal interventions**: Patch/ablate hidden states to test causal role of representations (Turner et al., Hernandez et al.)\n- **SAE feature analysis**: Decompose activations using SAEs and inspect features (Cunningham et al., Chanin et al.)\n\n### Standard Baselines\n- **Random baseline**: Permuted/shuffled labels for probing\n- **Separate processing baseline**: Process constituent words in separate contexts (Ormerod et al.'s \"Separate\" condition)\n- **Compositional control**: Compare compound nouns to clearly compositional phrases (e.g., \"washing machine\" vs. \"red machine\")\n- **Different tokenizations**: Compare models with different BPE vocabularies to control for tokenization effects\n\n### Evaluation Metrics\n- **Probe accuracy**: How well can a linear probe recover concept information\n- **Erasure score (ψ)**: Quantifies token-level information loss (Feucht et al.)\n- **RSA correlation**: Second-order correlation between model and human RDMs\n- **Steering effect size**: Change in model behavior when adding concept vectors\n- **SAE feature F1**: How reliably an SAE feature tracks a target concept\n\n---\n\n## 7. Datasets in the Literature\n\n| Dataset | Used In | Type | Size | Relevance |\n|---------|---------|------|------|-----------|\n| Gagné (2001) compounds | Ormerod et al. | 300 compounds, 16 relations | 300 | High |\n| Devereux & Costello (2005) | Ormerod et al. | 60 compounds, 18-dim relation vectors | 60 | High |\n| NCS (Garcia et al.) | Garcia et al. | Compounds with compositionality ratings | 280 EN, 180 PT | High |\n| COUNTERFACT | Feucht et al. | Factual prompts with entities | 12K+ | Medium |\n| MAGPIE | Idiom research | Idiom instances with labels | 56K | Medium |\n| BATS 3.0 | Park et al. | Analogy/relation pairs | ~40 relations | Medium |\n| The Pile | Feucht et al. | General text (probe training) | 800GB | Medium |\n\n---\n\n## 8. Gaps and Opportunities\n\n### Key Gap: No Study Directly Tests Compound Noun Directions in Residual Stream\n- Park et al. tested single-token concepts but not multi-token compounds\n- Ormerod et al. used masked LMs (BERT), not autoregressive models\n- Feucht et al. focused on named entities, not common compound nouns\n- No study has used SAEs to find features specifically for compound nouns like \"washing machine\"\n\n### Opportunity 1: Token Erasure for Compound Nouns\nAdapt Feucht et al.'s methodology to test whether \"washing machine\" shows erasure patterns (suggesting unified representation) or maintains token-level information (suggesting compositional processing). Compare to compositional controls.\n\n### Opportunity 2: SAE Feature Analysis of Compound Concepts\nUse pre-trained SAEs (Gemma Scope, Llama Scope) to search for features that specifically activate for \"washing machine\" as a compound, vs. features for \"washing\" and \"machine\" separately. Test for absorption effects.\n\n### Opportunity 3: Directional Probing with Causal Inner Product\nApply Park et al.'s framework to multi-token compounds: estimate the causal inner product, find concept directions for \"washing machine\" vs. constituent words, and test whether the compound direction is linearly independent of constituent directions.\n\n### Opportunity 4: Compositional vs. Holistic Representation Spectrum\nBuild a controlled dataset of compound nouns varying in compositionality (from \"coffee table\" to \"hot dog\") and measure representation properties across this spectrum — erasure scores, SAE feature patterns, probe accuracy, and steering effects.\n\n---\n\n## 9. Recommendations for Experiments\n\n### Primary Methodology: Token Erasure Analysis\n1. Use Feucht et al.'s linear probes on Llama-2-7B or Llama-3-8B\n2. Measure erasure scores for compound nouns varying in compositionality\n3. Compare: \"washing machine\" (compound) vs. \"red machine\" (compositional) vs. \"hot dog\" (idiomatic)\n\n### Secondary Methodology: SAE Feature Search\n1. Use pre-trained SAEs (Gemma Scope or Llama Scope)\n2. Search for features that activate on compound nouns\n3. Test for feature absorption: does the compound feature reliably fire?\n4. Compare feature patterns across compositionality spectrum\n\n### Tertiary Methodology: Concept Direction Analysis\n1. Collect contexts where \"washing machine\" appears vs. related contexts\n2. Estimate concept directions using mean-difference or probing\n3. Test: is the \"washing machine\" direction independent of \"washing\" and \"machine\" directions?\n4. Measure causal effects of steering with compound vs. constituent vectors\n\n### Recommended Models\n- **Llama-2-7B** or **Llama-3-8B**: Best supported by existing tools and pre-trained probes\n- **Gemma-2-2B**: Best SAE coverage via Gemma Scope\n- **GPT-2-small**: Good for initial experiments due to size and tooling support\n\n### Recommended Metrics\n1. Erasure score (ψ) — quantifies lexicality\n2. Probe accuracy across layers — maps representation formation\n3. SAE feature reliability (F1) — tests feature absorption\n4. Steering effect size — causal validation\n5. Cosine similarity between compound and constituent directions\n\n---\n\n## References\n\n1. Aljaafari, N. et al. (2024). Interpreting token compositionality in LLMs. arXiv:2410.12924.\n2. Arora, S. et al. (2016). Linear Algebraic Structure of Word Senses. arXiv:1601.03764.\n3. Buijtelaar, L. et al. (2023). A Psycholinguistic Analysis of BERT's Representations of Compounds.\n4. Bussmann, B. et al. (2024). BatchTopK Sparse Autoencoders. arXiv:2409.06981.\n5. Chanin, D. et al. (2024). A is for Absorption. arXiv:2409.14507.\n6. Chanin, D. et al. (2025). Feature Hedging. arXiv:2503.01370.\n7. Cunningham, H. et al. (2023). Sparse Autoencoders Find Highly Interpretable Features. arXiv:2309.08600.\n8. Dankers, V. et al. (2022). Can Transformer be Too Compositional? arXiv:2205.15301.\n9. Elhage, N. et al. (2022). Toy Models of Superposition. arXiv:2209.10652.\n10. Engels, J. et al. (2024). Decomposing The Dark Matter of SAEs. arXiv:2410.14670.\n11. Feucht, S. et al. (2024). Token Erasure as a Footprint of Implicit Vocabulary Items. arXiv:2406.20086.\n12. Gao, L. et al. (2024). Scaling and evaluating sparse autoencoders. arXiv:2406.04093.\n13. Garcia, M. et al. (2021). Probing for idiomaticity in vector space models. EACL 2021.\n14. Geva, M. et al. (2022). Transformer Feed-Forward Layers Build Predictions. arXiv:2203.14680.\n15. Gurnee, W. & Tegmark, M. (2023). Language Models Represent Space and Time. arXiv:2310.02207.\n16. He, Z. et al. (2024). Llama Scope. arXiv:2410.20526.\n17. Hernandez, E. et al. (2023). Linearity of Relation Decoding. arXiv:2308.09124.\n18. Lieberum, T. et al. (2024). Gemma Scope. arXiv:2408.05147.\n19. Merullo, J. et al. (2023). Language Models Implement Simple Word2Vec-style Vector Arithmetic. arXiv:2305.16130.\n20. Ormerod, M. et al. (2024). How Is a \"Kitchen Chair\" like a \"Farm Horse\"? Computational Linguistics, 50(1).\n21. Park, K. et al. (2024). The Linear Representation Hypothesis. arXiv:2311.03658.\n22. Rajamanoharan, S. et al. (2024). Improving Dictionary Learning with Gated SAEs. arXiv:2404.16014.\n23. Scherlis, A. et al. (2022). Polysemanticity and Capacity in Neural Networks. arXiv:2210.01892.\n24. Turner, A. et al. (2023). Steering Language Models With Activation Engineering. arXiv:2308.10248.\n","numLines":263,"startLine":1,"totalLines":263}}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01D4JQDWJQHz3q5jfMJUffD8","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_011YpZY8g93qXAeEJiwvASLX","name":"Read","input":{"file_path":"/data/hypogenicai/workspaces/llm-washing-machine-claude/resources.md"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":405,"cache_read_input_tokens":34900,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":405},"output_tokens":25,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"3024acd9-0fe9-46e7-aa26-f78945566cae"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_011YpZY8g93qXAeEJiwvASLX","type":"tool_result","content":"     1→# Resources Catalog\n     2→\n     3→## Summary\n     4→This document catalogs all resources gathered for the research project \"Where is Washing Machine Stored in LLMs?\", including papers, datasets, and code repositories.\n     5→\n     6→---\n     7→\n     8→## Papers\n     9→**Total papers downloaded: 36**\n    10→\n    11→| # | Title | Authors | Year | File | Key Info |\n    12→|---|-------|---------|------|------|----------|\n    13→| 1 | Token Erasure as a Footprint of Implicit Vocabulary Items in LLMs | Feucht et al. | 2024 | `2406.20086_token_erasure_implicit_vocabulary.pdf` | **Most relevant** — studies how multi-token concepts are assembled in early layers via \"token erasure\" |\n    14→| 2 | How Is a \"Kitchen Chair\" like a \"Farm Horse\"? | Ormerod et al. | 2024 | `ormerod2024_kitchen_chair_compound_semantics.pdf` | **Directly relevant** — probes compound noun semantics in transformers using RSA |\n    15→| 3 | The Linear Representation Hypothesis | Park et al. | 2024 | `2311.03658_linear_representation_hypothesis.pdf` | Formalizes concept directions; tested 27 concepts on LLaMA-2-7B |\n    16→| 4 | Toy Models of Superposition | Elhage et al. | 2022 | `2209.10652_toy_models_superposition.pdf` | Theoretical foundation for feature superposition in neural networks |\n    17→| 5 | A is for Absorption | Chanin et al. | 2024 | `2409.14507_absorption_feature_splitting.pdf` | Feature absorption problem in SAEs — hierarchical features are unreliable |\n    18→| 6 | Sparse Autoencoders Find Highly Interpretable Features | Cunningham et al. | 2023 | `2309.08600_sparse_autoencoders_interpretable.pdf` | Foundational SAE interpretability paper (838 citations) |\n    19→| 7 | Scaling and evaluating sparse autoencoders | Gao et al. | 2024 | `2406.04093_scaling_evaluating_sae.pdf` | Large-scale SAE training and evaluation (313 citations) |\n    20→| 8 | Transformer FF Layers Build Predictions by Promoting Concepts | Geva et al. | 2022 | `2203.14680_ff_layers_promoting_concepts.pdf` | How FFN layers promote next-token predictions (475 citations) |\n    21→| 9 | Interpreting token compositionality in LLMs | Aljaafari et al. | 2024 | `2410.12924_token_compositionality.pdf` | CAP methodology; no single layer integrates tokens compositionally |\n    22→| 10 | Probing for idiomaticity in vector space models | Garcia et al. | 2021 | `garcia2021_probing_idiomaticity.pdf` | BERT fails to capture idiomaticity; NCS dataset |\n    23→| 11 | Language Models Implement Word2Vec-style Arithmetic | Merullo et al. | 2023 | `2305.16130_lm_word2vec_arithmetic.pdf` | Vector arithmetic for relational tasks in LLMs |\n    24→| 12 | Linear Algebraic Structure of Word Senses | Arora et al. | 2016 | `1601.03764_linear_structure_word_senses.pdf` | Polysemous senses in linear superposition |\n    25→| 13 | Language Models Represent Space and Time | Gurnee & Tegmark | 2023 | `2310.02207_lm_represent_space_time.pdf` | Linear representations of spatial/temporal concepts |\n    26→| 14 | Linearity of Relation Decoding | Hernandez et al. | 2023 | `2308.09124_linearity_relation_decoding.pdf` | Relations decoded via single linear transformation |\n    27→| 15 | Steering Language Models With Activation Engineering | Turner et al. | 2023 | `2308.10248_activation_engineering.pdf` | Concept steering via activation vectors |\n    28→| 16 | Gemma Scope | Lieberum et al. | 2024 | `2408.05147_gemma_scope.pdf` | Open SAE suite for Gemma-2 models |\n    29→| 17 | Improving Dictionary Learning with Gated SAEs | Rajamanoharan et al. | 2024 | `2404.16014_gated_sae.pdf` | Gated SAE architecture |\n    30→| 18 | Llama Scope | He et al. | 2024 | `2410.20526_llama_scope.pdf` | 256 SAEs for Llama-3.1-8B |\n    31→| 19 | BatchTopK Sparse Autoencoders | Bussmann et al. | 2024 | `2409.06981_batchtopk_sae.pdf` | TopK SAE training approach |\n    32→| 20 | Polysemanticity and Capacity | Scherlis et al. | 2022 | `2210.01892_polysemanticity_capacity.pdf` | Why neurons become polysemantic |\n    33→| 21 | Can Transformer be Too Compositional? | Dankers et al. | 2022 | `2205.15301_transformer_compositional_idioms.pdf` | Idiom processing in NMT; over-composition bias |\n    34→| 22 | A Psycholinguistic Analysis of BERT's Compounds | Buijtelaar et al. | 2023 | `2302.07788_bert_compounds.pdf` | BERT's compound noun representations |\n    35→| 23 | Probing BERT for German Compound Semantics | Miletić et al. | 2025 | `2501.16927_probing_bert_german_compounds.pdf` | German compound probing |\n    36→| 24 | Decomposing The Dark Matter of SAEs | Engels et al. | 2024 | `2410.14670_dark_matter_sae.pdf` | Unexplained variance in SAE reconstructions |\n    37→| 25 | Feature Hedging | Chanin et al. | 2025 | `2503.01370_feature_hedging.pdf` | Correlated features break narrow SAEs |\n    38→| 26 | Temporal Sparse Autoencoders | Bhalla et al. | 2025 | `2501.14404_temporal_sae.pdf` | Sequential structure in SAE features |\n    39→| 27 | Sparse Feature Circuits | Marks et al. | 2024 | `2403.19647_sparse_feature_circuits.pdf` | Causal feature circuits in LLMs |\n    40→| 28 | Mechanistic Interpretability for AI Safety | Bereska et al. | 2024 | `2404.14082_mechanistic_interpretability_safety.pdf` | Comprehensive MI review |\n    41→| 29 | Rethinking SAE Evaluation via Polysemous Words | Minegishi et al. | 2025 | `2501.07096_rethinking_sae_polysemous.pdf` | SAE evaluation through polysemy |\n    42→| 30 | Origins of Representation Manifolds | Modell et al. | 2025 | `2501.15832_origins_representation_manifolds.pdf` | Theory of representation manifolds |\n    43→| 31 | Emergent Linguistic Structure | Manning et al. | 2020 | `2004.14601_emergent_linguistic_structure.pdf` | Self-supervised linguistic learning |\n    44→| 32 | From Tokens to Words: Inner Lexicon of LLMs | — | 2024 | `2410.05864_tokens_to_words_inner_lexicon.pdf` | Inner lexicon formation |\n    45→| 33 | Syntax-guided Neural Module Distillation | Pandey | 2023 | `2301.08998_syntax_compositionality.pdf` | Compositional probing via syntax |\n    46→| 34 | Linear Spaces of Meanings | Trager et al. | 2023 | `2302.14383_linear_spaces_meanings.pdf` | Compositional structures in VLMs |\n    47→| 35 | I Predict Therefore I Am | Liu et al. | 2025 | `2503.08980_next_token_prediction_concepts.pdf` | NTP and concept learning theory |\n    48→| 36 | Transformer Dictionary Learning | Yun et al. | 2021 | `2103.15949_transformer_dictionary_learning.pdf` | Early dictionary learning for transformers |\n    49→\n    50→See `papers/notes/` for detailed reading notes on key papers.\n    51→\n    52→---\n    53→\n    54→## Datasets\n    55→**Total datasets downloaded: 4**\n    56→\n    57→| Name | Source | Size | Task | Location | Notes |\n    58→|------|--------|------|------|----------|-------|\n    59→| Noun Compound Senses (NCS) | github.com/marcospln/noun_compound_senses | 280 EN + 180 PT compounds | Compositionality probing | `datasets/noun_compound_senses/` | Includes compositionality ratings and sentence variants |\n    60→| MAGPIE Idiom Corpus | github.com/hslh/magpie-corpus | 56,622 instances | Idiomaticity detection | `datasets/magpie/` | Binary and 5-way idiom labels with context |\n    61→| Custom Compound Nouns Test Set | Created for this project | 35 compounds | Compositionality spectrum | `datasets/compound_nouns_test.jsonl` | Covers compositionality range 1-5 |\n    62→| Gagné (2001) Compounds | Embedded in NCS | 300 compounds, 16 relations | Compound relation classification | In NCS dataset | Groups of 5 compounds with controlled conditions |\n    63→\n    64→See `datasets/README.md` for detailed descriptions and download instructions.\n    65→\n    66→---\n    67→\n    68→## Code Repositories\n    69→**Total repositories cloned: 7**\n    70→\n    71→| Name | URL | Purpose | Location | Notes |\n    72→|------|-----|---------|----------|-------|\n    73→| **Footprints** | github.com/sfeucht/footprints | Token erasure analysis for multi-token concepts | `code/footprints/` | **Primary tool** — includes pre-trained probes, erasure scoring |\n    74→| **SAELens** | github.com/jbloomAus/SAELens | SAE training and analysis library | `code/SAELens/` | Supports pre-trained SAEs, Neuronpedia integration |\n    75→| **TransformerLens** | github.com/TransformerLensOrg/TransformerLens | Hook-based LLM interpretability toolkit | `code/TransformerLens/` | 50+ model support, activation caching |\n    76→| **Linear Rep Geometry** | github.com/KihoPark/linear_rep_geometry | Linear representation hypothesis tools | `code/linear_rep_geometry/` | Causal inner product, concept direction analysis |\n    77→| **SAE Spelling** | github.com/lasr-spelling/sae-spelling | Feature absorption analysis | `code/sae-spelling/` | Attribution, ablation, probing tools |\n    78→| **Neuronpedia** | github.com/hijohnnylin/neuronpedia | SAE feature browser platform | `code/neuronpedia/` | Browse 4+ TB of activations |\n    79→| **SAEDashboard** | github.com/jbloomAus/SAEDashboard | Feature visualization dashboards | `code/SAEDashboard/` | Anthropic-style feature dashboards |\n    80→\n    81→See `code/README.md` for detailed descriptions of each repository.\n    82→\n    83→---\n    84→\n    85→## Resource Gathering Notes\n    86→\n    87→### Search Strategy\n    88→1. **Paper search**: Used paper-finder with 7 targeted queries covering: compound concepts in LLMs, superposition/polysemanticity, linear representation hypothesis, sparse autoencoders, compositional semantics, next-token prediction, and feature absorption\n    89→2. **Dataset search**: Searched HuggingFace, Papers with Code, GitHub, and academic sources\n    90→3. **Code search**: Identified tools from paper references, GitHub search, and community recommendations\n    91→\n    92→### Selection Criteria\n    93→- **Papers**: Prioritized work on (a) multi-token/compound concept representation, (b) linear representation theory, (c) SAE feature discovery, (d) compositional semantics probing\n    94→- **Datasets**: Selected datasets with compound noun compositionality annotations and controlled experimental conditions\n    95→- **Code**: Focused on tools that enable residual stream analysis, SAE feature extraction, and multi-token concept probing\n    96→\n    97→### Challenges Encountered\n    98→- Several arxiv IDs from paper-finder search results pointed to wrong papers (different papers with same ID); required manual verification and re-downloading\n    99→- The Gagné (2001) compound dataset is not freely available as standalone but is embedded in the NCS dataset\n   100→- No dataset exists specifically designed for probing compound concept directions in modern autoregressive LLMs — this is a gap our research can fill\n   101→\n   102→### Gaps and Workarounds\n   103→- **No autoregressive compound probing dataset**: Created custom test set (`compound_nouns_test.jsonl`) and can generate more from Wikipedia\n   104→- **Pre-trained SAEs may not cover all models we want**: SAELens supports training custom SAEs; Gemma Scope and Llama Scope provide pre-trained options\n   105→- **Token erasure probes are only available for Llama-2-7B and Llama-3-8B**: Can retrain for other models using the footprints codebase\n   106→\n   107→---\n   108→\n   109→## Recommendations for Experiment Design\n   110→\n   111→### 1. Primary Dataset(s)\n   112→- **Custom compound noun test set** (`compound_nouns_test.jsonl`) — 35 compounds across compositionality spectrum, expandable\n   113→- **NCS dataset** — 280 English compounds with compositionality ratings and context sentences\n   114→- **Wikipedia contexts** — Extract sentences containing target compounds for erasure analysis\n   115→\n   116→### 2. Baseline Methods\n   117→- **Token erasure score** (Feucht et al.): Measures whether compound is treated as lexical unit\n   118→- **Compositional control baseline**: Compare compound nouns to clearly compositional phrases (e.g., \"washing machine\" vs. \"red machine\")\n   119→- **Separate processing baseline** (Ormerod et al.): Process constituent words in separate contexts\n   120→- **Random/shuffled baseline**: Permuted labels for probe accuracy\n   121→\n   122→### 3. Evaluation Metrics\n   123→- **Erasure score (ψ)**: Quantifies token-level information loss at last compound token\n   124→- **Probe accuracy across layers**: Maps where compound representation forms\n   125→- **SAE feature F1**: Tests whether SAE features reliably track compound concepts\n   126→- **Cosine similarity**: Between compound direction and constituent directions\n   127→- **Steering effect size**: Causal validation via activation addition\n   128→\n   129→### 4. Code to Adapt/Reuse\n   130→- **footprints**: Primary tool for erasure analysis — train probes, compute scores, extract vocabulary\n   131→- **TransformerLens + SAELens**: For hooking into model internals and analyzing SAE features\n   132→- **linear_rep_geometry**: For computing concept directions with causal inner products\n   133→- **sae-spelling**: For testing feature absorption in compound concept features\n   134→\n   135→### 5. Recommended Experimental Workflow\n   136→1. **Phase 1**: Compute erasure scores for compound nouns using footprints\n   137→2. **Phase 2**: Analyze SAE features for compound concepts using SAELens + Gemma Scope\n   138→3. **Phase 3**: Estimate concept directions using linear_rep_geometry framework\n   139→4. **Phase 4**: Perform causal interventions (steering, ablation) to validate findings\n   140→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"b12cc7fe-f334-4641-a60a-a6e454d2de22","tool_use_result":{"type":"text","file":{"filePath":"/data/hypogenicai/workspaces/llm-washing-machine-claude/resources.md","content":"# Resources Catalog\n\n## Summary\nThis document catalogs all resources gathered for the research project \"Where is Washing Machine Stored in LLMs?\", including papers, datasets, and code repositories.\n\n---\n\n## Papers\n**Total papers downloaded: 36**\n\n| # | Title | Authors | Year | File | Key Info |\n|---|-------|---------|------|------|----------|\n| 1 | Token Erasure as a Footprint of Implicit Vocabulary Items in LLMs | Feucht et al. | 2024 | `2406.20086_token_erasure_implicit_vocabulary.pdf` | **Most relevant** — studies how multi-token concepts are assembled in early layers via \"token erasure\" |\n| 2 | How Is a \"Kitchen Chair\" like a \"Farm Horse\"? | Ormerod et al. | 2024 | `ormerod2024_kitchen_chair_compound_semantics.pdf` | **Directly relevant** — probes compound noun semantics in transformers using RSA |\n| 3 | The Linear Representation Hypothesis | Park et al. | 2024 | `2311.03658_linear_representation_hypothesis.pdf` | Formalizes concept directions; tested 27 concepts on LLaMA-2-7B |\n| 4 | Toy Models of Superposition | Elhage et al. | 2022 | `2209.10652_toy_models_superposition.pdf` | Theoretical foundation for feature superposition in neural networks |\n| 5 | A is for Absorption | Chanin et al. | 2024 | `2409.14507_absorption_feature_splitting.pdf` | Feature absorption problem in SAEs — hierarchical features are unreliable |\n| 6 | Sparse Autoencoders Find Highly Interpretable Features | Cunningham et al. | 2023 | `2309.08600_sparse_autoencoders_interpretable.pdf` | Foundational SAE interpretability paper (838 citations) |\n| 7 | Scaling and evaluating sparse autoencoders | Gao et al. | 2024 | `2406.04093_scaling_evaluating_sae.pdf` | Large-scale SAE training and evaluation (313 citations) |\n| 8 | Transformer FF Layers Build Predictions by Promoting Concepts | Geva et al. | 2022 | `2203.14680_ff_layers_promoting_concepts.pdf` | How FFN layers promote next-token predictions (475 citations) |\n| 9 | Interpreting token compositionality in LLMs | Aljaafari et al. | 2024 | `2410.12924_token_compositionality.pdf` | CAP methodology; no single layer integrates tokens compositionally |\n| 10 | Probing for idiomaticity in vector space models | Garcia et al. | 2021 | `garcia2021_probing_idiomaticity.pdf` | BERT fails to capture idiomaticity; NCS dataset |\n| 11 | Language Models Implement Word2Vec-style Arithmetic | Merullo et al. | 2023 | `2305.16130_lm_word2vec_arithmetic.pdf` | Vector arithmetic for relational tasks in LLMs |\n| 12 | Linear Algebraic Structure of Word Senses | Arora et al. | 2016 | `1601.03764_linear_structure_word_senses.pdf` | Polysemous senses in linear superposition |\n| 13 | Language Models Represent Space and Time | Gurnee & Tegmark | 2023 | `2310.02207_lm_represent_space_time.pdf` | Linear representations of spatial/temporal concepts |\n| 14 | Linearity of Relation Decoding | Hernandez et al. | 2023 | `2308.09124_linearity_relation_decoding.pdf` | Relations decoded via single linear transformation |\n| 15 | Steering Language Models With Activation Engineering | Turner et al. | 2023 | `2308.10248_activation_engineering.pdf` | Concept steering via activation vectors |\n| 16 | Gemma Scope | Lieberum et al. | 2024 | `2408.05147_gemma_scope.pdf` | Open SAE suite for Gemma-2 models |\n| 17 | Improving Dictionary Learning with Gated SAEs | Rajamanoharan et al. | 2024 | `2404.16014_gated_sae.pdf` | Gated SAE architecture |\n| 18 | Llama Scope | He et al. | 2024 | `2410.20526_llama_scope.pdf` | 256 SAEs for Llama-3.1-8B |\n| 19 | BatchTopK Sparse Autoencoders | Bussmann et al. | 2024 | `2409.06981_batchtopk_sae.pdf` | TopK SAE training approach |\n| 20 | Polysemanticity and Capacity | Scherlis et al. | 2022 | `2210.01892_polysemanticity_capacity.pdf` | Why neurons become polysemantic |\n| 21 | Can Transformer be Too Compositional? | Dankers et al. | 2022 | `2205.15301_transformer_compositional_idioms.pdf` | Idiom processing in NMT; over-composition bias |\n| 22 | A Psycholinguistic Analysis of BERT's Compounds | Buijtelaar et al. | 2023 | `2302.07788_bert_compounds.pdf` | BERT's compound noun representations |\n| 23 | Probing BERT for German Compound Semantics | Miletić et al. | 2025 | `2501.16927_probing_bert_german_compounds.pdf` | German compound probing |\n| 24 | Decomposing The Dark Matter of SAEs | Engels et al. | 2024 | `2410.14670_dark_matter_sae.pdf` | Unexplained variance in SAE reconstructions |\n| 25 | Feature Hedging | Chanin et al. | 2025 | `2503.01370_feature_hedging.pdf` | Correlated features break narrow SAEs |\n| 26 | Temporal Sparse Autoencoders | Bhalla et al. | 2025 | `2501.14404_temporal_sae.pdf` | Sequential structure in SAE features |\n| 27 | Sparse Feature Circuits | Marks et al. | 2024 | `2403.19647_sparse_feature_circuits.pdf` | Causal feature circuits in LLMs |\n| 28 | Mechanistic Interpretability for AI Safety | Bereska et al. | 2024 | `2404.14082_mechanistic_interpretability_safety.pdf` | Comprehensive MI review |\n| 29 | Rethinking SAE Evaluation via Polysemous Words | Minegishi et al. | 2025 | `2501.07096_rethinking_sae_polysemous.pdf` | SAE evaluation through polysemy |\n| 30 | Origins of Representation Manifolds | Modell et al. | 2025 | `2501.15832_origins_representation_manifolds.pdf` | Theory of representation manifolds |\n| 31 | Emergent Linguistic Structure | Manning et al. | 2020 | `2004.14601_emergent_linguistic_structure.pdf` | Self-supervised linguistic learning |\n| 32 | From Tokens to Words: Inner Lexicon of LLMs | — | 2024 | `2410.05864_tokens_to_words_inner_lexicon.pdf` | Inner lexicon formation |\n| 33 | Syntax-guided Neural Module Distillation | Pandey | 2023 | `2301.08998_syntax_compositionality.pdf` | Compositional probing via syntax |\n| 34 | Linear Spaces of Meanings | Trager et al. | 2023 | `2302.14383_linear_spaces_meanings.pdf` | Compositional structures in VLMs |\n| 35 | I Predict Therefore I Am | Liu et al. | 2025 | `2503.08980_next_token_prediction_concepts.pdf` | NTP and concept learning theory |\n| 36 | Transformer Dictionary Learning | Yun et al. | 2021 | `2103.15949_transformer_dictionary_learning.pdf` | Early dictionary learning for transformers |\n\nSee `papers/notes/` for detailed reading notes on key papers.\n\n---\n\n## Datasets\n**Total datasets downloaded: 4**\n\n| Name | Source | Size | Task | Location | Notes |\n|------|--------|------|------|----------|-------|\n| Noun Compound Senses (NCS) | github.com/marcospln/noun_compound_senses | 280 EN + 180 PT compounds | Compositionality probing | `datasets/noun_compound_senses/` | Includes compositionality ratings and sentence variants |\n| MAGPIE Idiom Corpus | github.com/hslh/magpie-corpus | 56,622 instances | Idiomaticity detection | `datasets/magpie/` | Binary and 5-way idiom labels with context |\n| Custom Compound Nouns Test Set | Created for this project | 35 compounds | Compositionality spectrum | `datasets/compound_nouns_test.jsonl` | Covers compositionality range 1-5 |\n| Gagné (2001) Compounds | Embedded in NCS | 300 compounds, 16 relations | Compound relation classification | In NCS dataset | Groups of 5 compounds with controlled conditions |\n\nSee `datasets/README.md` for detailed descriptions and download instructions.\n\n---\n\n## Code Repositories\n**Total repositories cloned: 7**\n\n| Name | URL | Purpose | Location | Notes |\n|------|-----|---------|----------|-------|\n| **Footprints** | github.com/sfeucht/footprints | Token erasure analysis for multi-token concepts | `code/footprints/` | **Primary tool** — includes pre-trained probes, erasure scoring |\n| **SAELens** | github.com/jbloomAus/SAELens | SAE training and analysis library | `code/SAELens/` | Supports pre-trained SAEs, Neuronpedia integration |\n| **TransformerLens** | github.com/TransformerLensOrg/TransformerLens | Hook-based LLM interpretability toolkit | `code/TransformerLens/` | 50+ model support, activation caching |\n| **Linear Rep Geometry** | github.com/KihoPark/linear_rep_geometry | Linear representation hypothesis tools | `code/linear_rep_geometry/` | Causal inner product, concept direction analysis |\n| **SAE Spelling** | github.com/lasr-spelling/sae-spelling | Feature absorption analysis | `code/sae-spelling/` | Attribution, ablation, probing tools |\n| **Neuronpedia** | github.com/hijohnnylin/neuronpedia | SAE feature browser platform | `code/neuronpedia/` | Browse 4+ TB of activations |\n| **SAEDashboard** | github.com/jbloomAus/SAEDashboard | Feature visualization dashboards | `code/SAEDashboard/` | Anthropic-style feature dashboards |\n\nSee `code/README.md` for detailed descriptions of each repository.\n\n---\n\n## Resource Gathering Notes\n\n### Search Strategy\n1. **Paper search**: Used paper-finder with 7 targeted queries covering: compound concepts in LLMs, superposition/polysemanticity, linear representation hypothesis, sparse autoencoders, compositional semantics, next-token prediction, and feature absorption\n2. **Dataset search**: Searched HuggingFace, Papers with Code, GitHub, and academic sources\n3. **Code search**: Identified tools from paper references, GitHub search, and community recommendations\n\n### Selection Criteria\n- **Papers**: Prioritized work on (a) multi-token/compound concept representation, (b) linear representation theory, (c) SAE feature discovery, (d) compositional semantics probing\n- **Datasets**: Selected datasets with compound noun compositionality annotations and controlled experimental conditions\n- **Code**: Focused on tools that enable residual stream analysis, SAE feature extraction, and multi-token concept probing\n\n### Challenges Encountered\n- Several arxiv IDs from paper-finder search results pointed to wrong papers (different papers with same ID); required manual verification and re-downloading\n- The Gagné (2001) compound dataset is not freely available as standalone but is embedded in the NCS dataset\n- No dataset exists specifically designed for probing compound concept directions in modern autoregressive LLMs — this is a gap our research can fill\n\n### Gaps and Workarounds\n- **No autoregressive compound probing dataset**: Created custom test set (`compound_nouns_test.jsonl`) and can generate more from Wikipedia\n- **Pre-trained SAEs may not cover all models we want**: SAELens supports training custom SAEs; Gemma Scope and Llama Scope provide pre-trained options\n- **Token erasure probes are only available for Llama-2-7B and Llama-3-8B**: Can retrain for other models using the footprints codebase\n\n---\n\n## Recommendations for Experiment Design\n\n### 1. Primary Dataset(s)\n- **Custom compound noun test set** (`compound_nouns_test.jsonl`) — 35 compounds across compositionality spectrum, expandable\n- **NCS dataset** — 280 English compounds with compositionality ratings and context sentences\n- **Wikipedia contexts** — Extract sentences containing target compounds for erasure analysis\n\n### 2. Baseline Methods\n- **Token erasure score** (Feucht et al.): Measures whether compound is treated as lexical unit\n- **Compositional control baseline**: Compare compound nouns to clearly compositional phrases (e.g., \"washing machine\" vs. \"red machine\")\n- **Separate processing baseline** (Ormerod et al.): Process constituent words in separate contexts\n- **Random/shuffled baseline**: Permuted labels for probe accuracy\n\n### 3. Evaluation Metrics\n- **Erasure score (ψ)**: Quantifies token-level information loss at last compound token\n- **Probe accuracy across layers**: Maps where compound representation forms\n- **SAE feature F1**: Tests whether SAE features reliably track compound concepts\n- **Cosine similarity**: Between compound direction and constituent directions\n- **Steering effect size**: Causal validation via activation addition\n\n### 4. Code to Adapt/Reuse\n- **footprints**: Primary tool for erasure analysis — train probes, compute scores, extract vocabulary\n- **TransformerLens + SAELens**: For hooking into model internals and analyzing SAE features\n- **linear_rep_geometry**: For computing concept directions with causal inner products\n- **sae-spelling**: For testing feature absorption in compound concept features\n\n### 5. Recommended Experimental Workflow\n1. **Phase 1**: Compute erasure scores for compound nouns using footprints\n2. **Phase 2**: Analyze SAE features for compound concepts using SAELens + Gemma Scope\n3. **Phase 3**: Estimate concept directions using linear_rep_geometry framework\n4. **Phase 4**: Perform causal interventions (steering, ablation) to validate findings\n","numLines":140,"startLine":1,"totalLines":140}}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01D4JQDWJQHz3q5jfMJUffD8","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_012J8QE9nxHLQiPDCXGjU6qz","name":"Bash","input":{"command":"ls /data/hypogenicai/workspaces/llm-washing-machine-claude/papers/ 2>/dev/null; echo \"---\"; ls /data/hypogenicai/workspaces/llm-washing-machine-claude/datasets/ 2>/dev/null; echo \"---\"; ls /data/hypogenicai/workspaces/llm-washing-machine-claude/code/ 2>/dev/null","description":"List papers, datasets, and code directories"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":405,"cache_read_input_tokens":34900,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":405},"output_tokens":25,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"eb517424-0078-46ea-8d5e-393f1af4df05"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_012J8QE9nxHLQiPDCXGjU6qz","type":"tool_result","content":"1601.03764_linear_structure_word_senses.pdf\n2004.14601_emergent_linguistic_structure.pdf\n2103.15949_transformer_dictionary_learning.pdf\n2203.14680_ff_layers_promoting_concepts.pdf\n2205.15301_transformer_compositional_idioms.pdf\n2209.10652_toy_models_superposition.pdf\n2210.01892_polysemanticity_capacity.pdf\n2301.08998_syntax_compositionality.pdf\n2302.07788_bert_compounds.pdf\n2302.14383_linear_spaces_meanings.pdf\n2305.16130_lm_word2vec_arithmetic.pdf\n2308.09124_linearity_relation_decoding.pdf\n2308.10248_activation_engineering.pdf\n2309.08600_sparse_autoencoders_interpretable.pdf\n2310.02207_lm_represent_space_time.pdf\n2311.03658_linear_representation_hypothesis.pdf\n2403.19647_sparse_feature_circuits.pdf\n2404.14082_mechanistic_interpretability_safety.pdf\n2404.16014_gated_sae.pdf\n2406.04093_scaling_evaluating_sae.pdf\n2406.20086_token_erasure_implicit_vocabulary.pdf\n2408.05147_gemma_scope.pdf\n2409.06981_batchtopk_sae.pdf\n2409.14507_absorption_feature_splitting.pdf\n2410.05864_tokens_to_words_inner_lexicon.pdf\n2410.12924_token_compositionality.pdf\n2410.14670_dark_matter_sae.pdf\n2410.20526_llama_scope.pdf\n2501.07096_rethinking_sae_polysemous.pdf\n2501.14404_temporal_sae.pdf\n2501.15832_origins_representation_manifolds.pdf\n2501.16927_probing_bert_german_compounds.pdf\n2503.01370_feature_hedging.pdf\n2503.08980_next_token_prediction_concepts.pdf\ngarcia2021_probing_idiomaticity.pdf\nnotes\normerod2024_kitchen_chair_compound_semantics.pdf\npages\nREADME.md\n---\ncompound_nouns_test.jsonl\ndataset_search_results.md\nDOWNLOAD_SUMMARY.md\nmagpie\nnoun_compound_senses\nREADME.md\n---\nfootprints\nlinear_rep_geometry\nneuronpedia\nREADME.md\nSAEDashboard\nSAELens\nsae-spelling\nTransformerLens","is_error":false}]},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"7dd1ddc9-3ba7-4bb6-9b24-e95f7153cebc","tool_use_result":{"stdout":"1601.03764_linear_structure_word_senses.pdf\n2004.14601_emergent_linguistic_structure.pdf\n2103.15949_transformer_dictionary_learning.pdf\n2203.14680_ff_layers_promoting_concepts.pdf\n2205.15301_transformer_compositional_idioms.pdf\n2209.10652_toy_models_superposition.pdf\n2210.01892_polysemanticity_capacity.pdf\n2301.08998_syntax_compositionality.pdf\n2302.07788_bert_compounds.pdf\n2302.14383_linear_spaces_meanings.pdf\n2305.16130_lm_word2vec_arithmetic.pdf\n2308.09124_linearity_relation_decoding.pdf\n2308.10248_activation_engineering.pdf\n2309.08600_sparse_autoencoders_interpretable.pdf\n2310.02207_lm_represent_space_time.pdf\n2311.03658_linear_representation_hypothesis.pdf\n2403.19647_sparse_feature_circuits.pdf\n2404.14082_mechanistic_interpretability_safety.pdf\n2404.16014_gated_sae.pdf\n2406.04093_scaling_evaluating_sae.pdf\n2406.20086_token_erasure_implicit_vocabulary.pdf\n2408.05147_gemma_scope.pdf\n2409.06981_batchtopk_sae.pdf\n2409.14507_absorption_feature_splitting.pdf\n2410.05864_tokens_to_words_inner_lexicon.pdf\n2410.12924_token_compositionality.pdf\n2410.14670_dark_matter_sae.pdf\n2410.20526_llama_scope.pdf\n2501.07096_rethinking_sae_polysemous.pdf\n2501.14404_temporal_sae.pdf\n2501.15832_origins_representation_manifolds.pdf\n2501.16927_probing_bert_german_compounds.pdf\n2503.01370_feature_hedging.pdf\n2503.08980_next_token_prediction_concepts.pdf\ngarcia2021_probing_idiomaticity.pdf\nnotes\normerod2024_kitchen_chair_compound_semantics.pdf\npages\nREADME.md\n---\ncompound_nouns_test.jsonl\ndataset_search_results.md\nDOWNLOAD_SUMMARY.md\nmagpie\nnoun_compound_senses\nREADME.md\n---\nfootprints\nlinear_rep_geometry\nneuronpedia\nREADME.md\nSAEDashboard\nSAELens\nsae-spelling\nTransformerLens","stderr":"","interrupted":false,"isImage":false}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01D4JQDWJQHz3q5jfMJUffD8","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01SyyVZvGCd3GP7P5MtXGeRF","name":"Bash","input":{"command":"nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv 2>/dev/null || echo \"NO_GPU\"","description":"Check GPU availability"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":405,"cache_read_input_tokens":34900,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":405},"output_tokens":25,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"59683f49-5a2b-40f9-9ced-ec6b1992d643"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01D4JQDWJQHz3q5jfMJUffD8","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01FFSMhuJMD6CntjXSEagWYF","name":"Bash","input":{"command":"ls /data/hypogenicai/workspaces/llm-washing-machine-claude/.venv/ 2>/dev/null && echo \"VENV_EXISTS\" || echo \"NO_VENV\"","description":"Check if virtual environment exists"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":405,"cache_read_input_tokens":34900,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":405},"output_tokens":25,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"10fc8a1b-26d6-46e8-b6a2-0f53237ea702"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01SyyVZvGCd3GP7P5MtXGeRF","type":"tool_result","content":"name, memory.total [MiB], memory.free [MiB]\nNVIDIA GeForce RTX 3090, 24576 MiB, 24161 MiB\nNVIDIA GeForce RTX 3090, 24576 MiB, 24161 MiB","is_error":false}]},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"9e695c0f-5a84-4412-bd78-e9af4be3fe81","tool_use_result":{"stdout":"name, memory.total [MiB], memory.free [MiB]\nNVIDIA GeForce RTX 3090, 24576 MiB, 24161 MiB\nNVIDIA GeForce RTX 3090, 24576 MiB, 24161 MiB","stderr":"","interrupted":false,"isImage":false}}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01FFSMhuJMD6CntjXSEagWYF","type":"tool_result","content":"bin\nCACHEDIR.TAG\nlib\nlib64\npyvenv.cfg\nVENV_EXISTS","is_error":false}]},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"8b17ae05-5053-4332-874c-4e198356188d","tool_use_result":{"stdout":"bin\nCACHEDIR.TAG\nlib\nlib64\npyvenv.cfg\nVENV_EXISTS","stderr":"","interrupted":false,"isImage":false}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01Xs9jE4zgjR5rkVvH19JqRM","type":"message","role":"assistant","content":[{"type":"text","text":"Excellent! I have 2x RTX 3090 GPUs (24GB each), a virtual environment already exists, and rich pre-gathered resources. Let me now check the custom dataset and environment details."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":11775,"cache_read_input_tokens":35305,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":11775},"output_tokens":5,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"253eb207-c57b-4464-af74-6d87003239d0"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01Xs9jE4zgjR5rkVvH19JqRM","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01VjtCQQKhcpq5sGorkoR3yc","name":"Read","input":{"file_path":"/data/hypogenicai/workspaces/llm-washing-machine-claude/datasets/compound_nouns_test.jsonl"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":11775,"cache_read_input_tokens":35305,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":11775},"output_tokens":5,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"b2fd8fde-6067-42a6-ada4-d9e7f1ddf13d"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01VjtCQQKhcpq5sGorkoR3yc","type":"tool_result","content":"     1→{\"compound\": \"coffee table\", \"word1\": \"coffee\", \"word2\": \"table\", \"compositionality_rating\": 5, \"notes\": \"Fully compositional - a table for placing coffee\"}\n     2→{\"compound\": \"brick house\", \"word1\": \"brick\", \"word2\": \"house\", \"compositionality_rating\": 5, \"notes\": \"Fully compositional - a house made of bricks\"}\n     3→{\"compound\": \"mountain cabin\", \"word1\": \"mountain\", \"word2\": \"cabin\", \"compositionality_rating\": 5, \"notes\": \"Fully compositional - a cabin in the mountains\"}\n     4→{\"compound\": \"garden hose\", \"word1\": \"garden\", \"word2\": \"hose\", \"compositionality_rating\": 5, \"notes\": \"Fully compositional - a hose for the garden\"}\n     5→{\"compound\": \"door handle\", \"word1\": \"door\", \"word2\": \"handle\", \"compositionality_rating\": 5, \"notes\": \"Fully compositional - a handle on a door\"}\n     6→{\"compound\": \"water bottle\", \"word1\": \"water\", \"word2\": \"bottle\", \"compositionality_rating\": 5, \"notes\": \"Fully compositional - a bottle for water\"}\n     7→{\"compound\": \"steel bridge\", \"word1\": \"steel\", \"word2\": \"bridge\", \"compositionality_rating\": 5, \"notes\": \"Fully compositional - a bridge made of steel\"}\n     8→{\"compound\": \"chocolate cake\", \"word1\": \"chocolate\", \"word2\": \"cake\", \"compositionality_rating\": 5, \"notes\": \"Fully compositional - a cake with chocolate\"}\n     9→{\"compound\": \"washing machine\", \"word1\": \"washing\", \"word2\": \"machine\", \"compositionality_rating\": 4, \"notes\": \"Partially compositional - a machine for washing, but 'washing' is typically clothing-specific\"}\n    10→{\"compound\": \"swimming pool\", \"word1\": \"swimming\", \"word2\": \"pool\", \"compositionality_rating\": 4, \"notes\": \"Partially compositional - a pool for swimming, but the compound has a specific conventional meaning\"}\n    11→{\"compound\": \"parking lot\", \"word1\": \"parking\", \"word2\": \"lot\", \"compositionality_rating\": 4, \"notes\": \"Partially compositional - a lot for parking, but 'lot' has a specialized meaning here\"}\n    12→{\"compound\": \"driving license\", \"word1\": \"driving\", \"word2\": \"license\", \"compositionality_rating\": 4, \"notes\": \"Partially compositional - a license for driving, institutionalized term\"}\n    13→{\"compound\": \"living room\", \"word1\": \"living\", \"word2\": \"room\", \"compositionality_rating\": 3, \"notes\": \"Partially compositional - a room for living, but 'living' has become abstract\"}\n    14→{\"compound\": \"shooting star\", \"word1\": \"shooting\", \"word2\": \"star\", \"compositionality_rating\": 2, \"notes\": \"Weakly compositional - not actually a star that shoots, but a meteor\"}\n    15→{\"compound\": \"guinea pig\", \"word1\": \"guinea\", \"word2\": \"pig\", \"compositionality_rating\": 2, \"notes\": \"Weakly compositional - neither from Guinea nor a pig, but resembles a pig\"}\n    16→{\"compound\": \"strawberry\", \"word1\": \"straw\", \"word2\": \"berry\", \"compositionality_rating\": 2, \"notes\": \"Weakly compositional - etymology involves straw but modern meaning opaque\"}\n    17→{\"compound\": \"blackboard\", \"word1\": \"black\", \"word2\": \"board\", \"compositionality_rating\": 3, \"notes\": \"Partially compositional - originally black, but now refers to any writing board\"}\n    18→{\"compound\": \"greenhouse\", \"word1\": \"green\", \"word2\": \"house\", \"compositionality_rating\": 3, \"notes\": \"Partially compositional - not necessarily green, but for growing green plants\"}\n    19→{\"compound\": \"hotdog\", \"word1\": \"hot\", \"word2\": \"dog\", \"compositionality_rating\": 1, \"notes\": \"Non-compositional (idiomatic) - not a hot dog animal, sausage in a bun\"}\n    20→{\"compound\": \"butterfly\", \"word1\": \"butter\", \"word2\": \"fly\", \"compositionality_rating\": 1, \"notes\": \"Non-compositional (idiomatic) - no relation to butter or flying\"}\n    21→{\"compound\": \"deadline\", \"word1\": \"dead\", \"word2\": \"line\", \"compositionality_rating\": 1, \"notes\": \"Non-compositional (idiomatic) - metaphorical time limit, historical origin obscured\"}\n    22→{\"compound\": \"hot dog\", \"word1\": \"hot\", \"word2\": \"dog\", \"compositionality_rating\": 1, \"notes\": \"Non-compositional (idiomatic) - sausage in a bun, not a warm canine\"}\n    23→{\"compound\": \"redhead\", \"word1\": \"red\", \"word2\": \"head\", \"compositionality_rating\": 3, \"notes\": \"Partially compositional - head isn't red, but hair is\"}\n    24→{\"compound\": \"blueberry\", \"word1\": \"blue\", \"word2\": \"berry\", \"compositionality_rating\": 4, \"notes\": \"Partially compositional - berries that are blue, but specific variety\"}\n    25→{\"compound\": \"firefly\", \"word1\": \"fire\", \"word2\": \"fly\", \"compositionality_rating\": 3, \"notes\": \"Partially compositional - fly that produces light like fire\"}\n    26→{\"compound\": \"snowman\", \"word1\": \"snow\", \"word2\": \"man\", \"compositionality_rating\": 4, \"notes\": \"Partially compositional - man-shaped figure made of snow\"}\n    27→{\"compound\": \"sunflower\", \"word1\": \"sun\", \"word2\": \"flower\", \"compositionality_rating\": 4, \"notes\": \"Partially compositional - flower that follows the sun\"}\n    28→{\"compound\": \"bookworm\", \"word1\": \"book\", \"word2\": \"worm\", \"compositionality_rating\": 1, \"notes\": \"Non-compositional (idiomatic) - person who reads a lot, not an actual worm\"}\n    29→{\"compound\": \"ladybug\", \"word1\": \"lady\", \"word2\": \"bug\", \"compositionality_rating\": 1, \"notes\": \"Non-compositional (idiomatic) - type of beetle, no relation to ladies\"}\n    30→{\"compound\": \"eggplant\", \"word1\": \"egg\", \"word2\": \"plant\", \"compositionality_rating\": 2, \"notes\": \"Weakly compositional - plant whose fruit resembles eggs in some varieties\"}\n    31→{\"compound\": \"popcorn\", \"word1\": \"pop\", \"word2\": \"corn\", \"compositionality_rating\": 4, \"notes\": \"Partially compositional - corn that pops when heated\"}\n    32→{\"compound\": \"keyboard\", \"word1\": \"key\", \"word2\": \"board\", \"compositionality_rating\": 4, \"notes\": \"Partially compositional - board with keys, but 'key' has specialized meaning\"}\n    33→{\"compound\": \"football\", \"word1\": \"foot\", \"word2\": \"ball\", \"compositionality_rating\": 4, \"notes\": \"Partially compositional - ball kicked with foot, but refers to specific game\"}\n    34→{\"compound\": \"breakfast\", \"word1\": \"break\", \"word2\": \"fast\", \"compositionality_rating\": 2, \"notes\": \"Weakly compositional - etymologically 'breaking fast' but opaque to most speakers\"}\n    35→{\"compound\": \"rainbow\", \"word1\": \"rain\", \"word2\": \"bow\", \"compositionality_rating\": 3, \"notes\": \"Partially compositional - bow-shaped arc seen in rain, but 'bow' meaning is archaic\"}\n    36→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"9353399b-38c6-4207-8a3a-743c8999712b","tool_use_result":{"type":"text","file":{"filePath":"/data/hypogenicai/workspaces/llm-washing-machine-claude/datasets/compound_nouns_test.jsonl","content":"{\"compound\": \"coffee table\", \"word1\": \"coffee\", \"word2\": \"table\", \"compositionality_rating\": 5, \"notes\": \"Fully compositional - a table for placing coffee\"}\n{\"compound\": \"brick house\", \"word1\": \"brick\", \"word2\": \"house\", \"compositionality_rating\": 5, \"notes\": \"Fully compositional - a house made of bricks\"}\n{\"compound\": \"mountain cabin\", \"word1\": \"mountain\", \"word2\": \"cabin\", \"compositionality_rating\": 5, \"notes\": \"Fully compositional - a cabin in the mountains\"}\n{\"compound\": \"garden hose\", \"word1\": \"garden\", \"word2\": \"hose\", \"compositionality_rating\": 5, \"notes\": \"Fully compositional - a hose for the garden\"}\n{\"compound\": \"door handle\", \"word1\": \"door\", \"word2\": \"handle\", \"compositionality_rating\": 5, \"notes\": \"Fully compositional - a handle on a door\"}\n{\"compound\": \"water bottle\", \"word1\": \"water\", \"word2\": \"bottle\", \"compositionality_rating\": 5, \"notes\": \"Fully compositional - a bottle for water\"}\n{\"compound\": \"steel bridge\", \"word1\": \"steel\", \"word2\": \"bridge\", \"compositionality_rating\": 5, \"notes\": \"Fully compositional - a bridge made of steel\"}\n{\"compound\": \"chocolate cake\", \"word1\": \"chocolate\", \"word2\": \"cake\", \"compositionality_rating\": 5, \"notes\": \"Fully compositional - a cake with chocolate\"}\n{\"compound\": \"washing machine\", \"word1\": \"washing\", \"word2\": \"machine\", \"compositionality_rating\": 4, \"notes\": \"Partially compositional - a machine for washing, but 'washing' is typically clothing-specific\"}\n{\"compound\": \"swimming pool\", \"word1\": \"swimming\", \"word2\": \"pool\", \"compositionality_rating\": 4, \"notes\": \"Partially compositional - a pool for swimming, but the compound has a specific conventional meaning\"}\n{\"compound\": \"parking lot\", \"word1\": \"parking\", \"word2\": \"lot\", \"compositionality_rating\": 4, \"notes\": \"Partially compositional - a lot for parking, but 'lot' has a specialized meaning here\"}\n{\"compound\": \"driving license\", \"word1\": \"driving\", \"word2\": \"license\", \"compositionality_rating\": 4, \"notes\": \"Partially compositional - a license for driving, institutionalized term\"}\n{\"compound\": \"living room\", \"word1\": \"living\", \"word2\": \"room\", \"compositionality_rating\": 3, \"notes\": \"Partially compositional - a room for living, but 'living' has become abstract\"}\n{\"compound\": \"shooting star\", \"word1\": \"shooting\", \"word2\": \"star\", \"compositionality_rating\": 2, \"notes\": \"Weakly compositional - not actually a star that shoots, but a meteor\"}\n{\"compound\": \"guinea pig\", \"word1\": \"guinea\", \"word2\": \"pig\", \"compositionality_rating\": 2, \"notes\": \"Weakly compositional - neither from Guinea nor a pig, but resembles a pig\"}\n{\"compound\": \"strawberry\", \"word1\": \"straw\", \"word2\": \"berry\", \"compositionality_rating\": 2, \"notes\": \"Weakly compositional - etymology involves straw but modern meaning opaque\"}\n{\"compound\": \"blackboard\", \"word1\": \"black\", \"word2\": \"board\", \"compositionality_rating\": 3, \"notes\": \"Partially compositional - originally black, but now refers to any writing board\"}\n{\"compound\": \"greenhouse\", \"word1\": \"green\", \"word2\": \"house\", \"compositionality_rating\": 3, \"notes\": \"Partially compositional - not necessarily green, but for growing green plants\"}\n{\"compound\": \"hotdog\", \"word1\": \"hot\", \"word2\": \"dog\", \"compositionality_rating\": 1, \"notes\": \"Non-compositional (idiomatic) - not a hot dog animal, sausage in a bun\"}\n{\"compound\": \"butterfly\", \"word1\": \"butter\", \"word2\": \"fly\", \"compositionality_rating\": 1, \"notes\": \"Non-compositional (idiomatic) - no relation to butter or flying\"}\n{\"compound\": \"deadline\", \"word1\": \"dead\", \"word2\": \"line\", \"compositionality_rating\": 1, \"notes\": \"Non-compositional (idiomatic) - metaphorical time limit, historical origin obscured\"}\n{\"compound\": \"hot dog\", \"word1\": \"hot\", \"word2\": \"dog\", \"compositionality_rating\": 1, \"notes\": \"Non-compositional (idiomatic) - sausage in a bun, not a warm canine\"}\n{\"compound\": \"redhead\", \"word1\": \"red\", \"word2\": \"head\", \"compositionality_rating\": 3, \"notes\": \"Partially compositional - head isn't red, but hair is\"}\n{\"compound\": \"blueberry\", \"word1\": \"blue\", \"word2\": \"berry\", \"compositionality_rating\": 4, \"notes\": \"Partially compositional - berries that are blue, but specific variety\"}\n{\"compound\": \"firefly\", \"word1\": \"fire\", \"word2\": \"fly\", \"compositionality_rating\": 3, \"notes\": \"Partially compositional - fly that produces light like fire\"}\n{\"compound\": \"snowman\", \"word1\": \"snow\", \"word2\": \"man\", \"compositionality_rating\": 4, \"notes\": \"Partially compositional - man-shaped figure made of snow\"}\n{\"compound\": \"sunflower\", \"word1\": \"sun\", \"word2\": \"flower\", \"compositionality_rating\": 4, \"notes\": \"Partially compositional - flower that follows the sun\"}\n{\"compound\": \"bookworm\", \"word1\": \"book\", \"word2\": \"worm\", \"compositionality_rating\": 1, \"notes\": \"Non-compositional (idiomatic) - person who reads a lot, not an actual worm\"}\n{\"compound\": \"ladybug\", \"word1\": \"lady\", \"word2\": \"bug\", \"compositionality_rating\": 1, \"notes\": \"Non-compositional (idiomatic) - type of beetle, no relation to ladies\"}\n{\"compound\": \"eggplant\", \"word1\": \"egg\", \"word2\": \"plant\", \"compositionality_rating\": 2, \"notes\": \"Weakly compositional - plant whose fruit resembles eggs in some varieties\"}\n{\"compound\": \"popcorn\", \"word1\": \"pop\", \"word2\": \"corn\", \"compositionality_rating\": 4, \"notes\": \"Partially compositional - corn that pops when heated\"}\n{\"compound\": \"keyboard\", \"word1\": \"key\", \"word2\": \"board\", \"compositionality_rating\": 4, \"notes\": \"Partially compositional - board with keys, but 'key' has specialized meaning\"}\n{\"compound\": \"football\", \"word1\": \"foot\", \"word2\": \"ball\", \"compositionality_rating\": 4, \"notes\": \"Partially compositional - ball kicked with foot, but refers to specific game\"}\n{\"compound\": \"breakfast\", \"word1\": \"break\", \"word2\": \"fast\", \"compositionality_rating\": 2, \"notes\": \"Weakly compositional - etymologically 'breaking fast' but opaque to most speakers\"}\n{\"compound\": \"rainbow\", \"word1\": \"rain\", \"word2\": \"bow\", \"compositionality_rating\": 3, \"notes\": \"Partially compositional - bow-shaped arc seen in rain, but 'bow' meaning is archaic\"}\n","numLines":36,"startLine":1,"totalLines":36}}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01Xs9jE4zgjR5rkVvH19JqRM","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01YLjxK5m3fCAoG4JSByZEa2","name":"Read","input":{"file_path":"/data/hypogenicai/workspaces/llm-washing-machine-claude/pyproject.toml"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":11775,"cache_read_input_tokens":35305,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":11775},"output_tokens":5,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"f35491d1-dbdc-4e2d-b039-72336bc87cf5"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01YLjxK5m3fCAoG4JSByZEa2","type":"tool_result","content":"     1→[project]\n     2→name = \"research-workspace\"\n     3→version = \"0.1.0\"\n     4→description = \"Research workspace for experiments\"\n     5→requires-python = \">=3.10\"\n     6→dependencies = [\n     7→    \"httpx>=0.28.1\",\n     8→    \"pypdf>=6.6.2\",\n     9→    \"requests>=2.32.5\",\n    10→]\n    11→\n    12→[build-system]\n    13→requires = [\"setuptools\"]\n    14→build-backend = \"setuptools.build_meta\"\n    15→\n    16→[tool.setuptools]\n    17→py-modules = []\n    18→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"a5f0726e-3be9-49c3-b52b-8e02360be424","tool_use_result":{"type":"text","file":{"filePath":"/data/hypogenicai/workspaces/llm-washing-machine-claude/pyproject.toml","content":"[project]\nname = \"research-workspace\"\nversion = \"0.1.0\"\ndescription = \"Research workspace for experiments\"\nrequires-python = \">=3.10\"\ndependencies = [\n    \"httpx>=0.28.1\",\n    \"pypdf>=6.6.2\",\n    \"requests>=2.32.5\",\n]\n\n[build-system]\nrequires = [\"setuptools\"]\nbuild-backend = \"setuptools.build_meta\"\n\n[tool.setuptools]\npy-modules = []\n","numLines":18,"startLine":1,"totalLines":18}}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01Xs9jE4zgjR5rkVvH19JqRM","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_017T3S3PbnHB9vY1MxvnmvG4","name":"Bash","input":{"command":"source /data/hypogenicai/workspaces/llm-washing-machine-claude/.venv/bin/activate && python --version && pip list 2>/dev/null | head -30","description":"Check Python version and installed packages"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":11775,"cache_read_input_tokens":35305,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":11775},"output_tokens":5,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"c0a1ac5a-c11e-4276-b5c1-2723e4386c26"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01Xs9jE4zgjR5rkVvH19JqRM","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_014YyNxNBapkXNu1brhda2F7","name":"Bash","input":{"command":"echo \"OPENAI_API_KEY=[REDACTED]" && echo \"ANTHROPIC_API_KEY=[REDACTED]" && echo \"OPENROUTER_API_KEY=${OPENROUTER_API_KEY:+SET}\"","description":"Check which API keys are available"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":11775,"cache_read_input_tokens":35305,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":11775},"output_tokens":5,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"4db8db40-2e41-4fbb-b500-36b6dea40652"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_017T3S3PbnHB9vY1MxvnmvG4","type":"tool_result","content":"Python 3.12.2\nPackage                        Version\n------------------------------ -------------\nabsl-py                        2.3.1\naiohappyeyeballs               2.6.1\naiohttp                        3.13.2\naiosignal                      1.4.0\nanaconda-anon-usage            0.4.4\nannotated-types                0.7.0\nanthropic                      0.72.0\nantlr4-python3-runtime         4.9.3\nanyio                          4.10.0\nappdirs                        1.4.4\narchspec                       0.2.3\nargcomplete                    3.6.2\nargon2-cffi                    25.1.0\nargon2-cffi-bindings           25.1.0\narrow                          1.4.0\nasgiref                        3.9.1\nasttokens                      3.0.1\nasync-lru                      2.0.5\nattr                           0.3.1\nattrs                          25.3.0\nazure-core                     1.35.1\nazure-storage-blob             12.26.0\nbabel                          2.17.0\nbeautifulsoup4                 4.14.3\nbert-score                     0.3.13\nblack                          25.1.0\nbleach                         5.0.1\nboltons                        23.0.0","is_error":false}]},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"07553777-80dd-46ee-84f2-3d99eac2a9ff","tool_use_result":{"stdout":"Python 3.12.2\nPackage                        Version\n------------------------------ -------------\nabsl-py                        2.3.1\naiohappyeyeballs               2.6.1\naiohttp                        3.13.2\naiosignal                      1.4.0\nanaconda-anon-usage            0.4.4\nannotated-types                0.7.0\nanthropic                      0.72.0\nantlr4-python3-runtime         4.9.3\nanyio                          4.10.0\nappdirs                        1.4.4\narchspec                       0.2.3\nargcomplete                    3.6.2\nargon2-cffi                    25.1.0\nargon2-cffi-bindings           25.1.0\narrow                          1.4.0\nasgiref                        3.9.1\nasttokens                      3.0.1\nasync-lru                      2.0.5\nattr                           0.3.1\nattrs                          25.3.0\nazure-core                     1.35.1\nazure-storage-blob             12.26.0\nbabel                          2.17.0\nbeautifulsoup4                 4.14.3\nbert-score                     0.3.13\nblack                          25.1.0\nbleach                         5.0.1\nboltons                        23.0.0","stderr":"","interrupted":false,"isImage":false}}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_014YyNxNBapkXNu1brhda2F7","type":"tool_result","content":"OPENAI_API_KEY=[REDACTED]","is_error":false}]},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"10dbb0ea-5fcf-49f0-a398-cf134894d450","tool_use_result":{"stdout":"OPENAI_API_KEY=[REDACTED]","stderr":"","interrupted":false,"isImage":false}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_019cCPvx4vXrQLncozLF5SV9","type":"message","role":"assistant","content":[{"type":"text","text":"I have a solid foundation: 2x RTX 3090 (24GB each), Python 3.12, rich resources, OpenAI and OpenRouter API keys, and a well-curated dataset of 35 compound nouns across the compositionality spectrum. The literature review is excellent and points directly to the methodology I need.\n\nLet me now proceed with Phase 0 (Motivation) and Phase 1 (Planning) together, then immediately move to implementation."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":3421,"cache_read_input_tokens":47080,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":3421},"output_tokens":2,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"02073298-1aec-4721-b669-9bcac0ac5264"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_019cCPvx4vXrQLncozLF5SV9","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01YUBFaWYqdzFf9S9SpDwbhC","name":"TodoWrite","input":{"todos":[{"content":"Review pre-gathered resources (literature_review.md, resources.md, papers/, datasets/, code/)","status":"completed","activeForm":"Reviewing pre-gathered resources"},{"content":"Phase 0 & 1: Motivation, novelty assessment, and research plan (planning.md)","status":"in_progress","activeForm":"Writing motivation assessment and research plan"},{"content":"Phase 2: Environment & data setup","status":"pending","activeForm":"Setting up environment and data"},{"content":"Phase 3: Implementation - write experiment code","status":"pending","activeForm":"Implementing experiment code"},{"content":"Phase 4: Run experiments","status":"pending","activeForm":"Running experiments"},{"content":"Phase 5: Analysis - statistical analysis and visualizations","status":"pending","activeForm":"Analyzing results"},{"content":"Phase 6: Final documentation (REPORT.md, README.md)","status":"pending","activeForm":"Writing final documentation"}]}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":3421,"cache_read_input_tokens":47080,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":3421},"output_tokens":2,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"3cda8a26-ce8a-448e-bc84-116a65ff7fcf"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01YUBFaWYqdzFf9S9SpDwbhC","type":"tool_result","content":"Todos have been modified successfully. Ensure that you continue to use the todo list to track your progress. Please proceed with the current tasks if applicable"}]},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"39673927-10c2-4559-9d7d-e695a6c89054","tool_use_result":{"oldTodos":[{"content":"Review pre-gathered resources (literature_review.md, resources.md, papers/, datasets/, code/)","status":"in_progress","activeForm":"Reviewing pre-gathered resources"},{"content":"Phase 0: Motivation & Novelty Assessment","status":"pending","activeForm":"Writing motivation and novelty assessment"},{"content":"Phase 1: Create detailed research plan (planning.md)","status":"pending","activeForm":"Creating research plan"},{"content":"Phase 2: Environment & data setup","status":"pending","activeForm":"Setting up environment and data"},{"content":"Phase 3: Implementation - write experiment code","status":"pending","activeForm":"Implementing experiment code"},{"content":"Phase 4: Run experiments","status":"pending","activeForm":"Running experiments"},{"content":"Phase 5: Analysis - statistical analysis and visualizations","status":"pending","activeForm":"Analyzing results"},{"content":"Phase 6: Final documentation (REPORT.md, README.md)","status":"pending","activeForm":"Writing final documentation"}],"newTodos":[{"content":"Review pre-gathered resources (literature_review.md, resources.md, papers/, datasets/, code/)","status":"completed","activeForm":"Reviewing pre-gathered resources"},{"content":"Phase 0 & 1: Motivation, novelty assessment, and research plan (planning.md)","status":"in_progress","activeForm":"Writing motivation assessment and research plan"},{"content":"Phase 2: Environment & data setup","status":"pending","activeForm":"Setting up environment and data"},{"content":"Phase 3: Implementation - write experiment code","status":"pending","activeForm":"Implementing experiment code"},{"content":"Phase 4: Run experiments","status":"pending","activeForm":"Running experiments"},{"content":"Phase 5: Analysis - statistical analysis and visualizations","status":"pending","activeForm":"Analyzing results"},{"content":"Phase 6: Final documentation (REPORT.md, README.md)","status":"pending","activeForm":"Writing final documentation"}]}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01GaHapbH8gPvXrCFcUbGvrQ","type":"message","role":"assistant","content":[{"type":"text","text":"Now let me design the research plan. Based on the literature review, I'll focus on three complementary experiments that directly address the question \"Where is washing machine stored in LLMs?\":\n\n1. **Next-token prediction analysis**: Does \"washing\" alone boost \"machine\" probability? Compare across compositionality levels.\n2. **Residual stream probing**: Can we find dedicated directions for compound concepts vs. just constituent words?\n3. **Token erasure analysis**: Do compound nouns show token erasure patterns (indicating unified representation)?"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":448,"cache_read_input_tokens":50501,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":448},"output_tokens":4,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"36a6532e-143f-4d24-9048-9cb3b43a70f5"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01GaHapbH8gPvXrCFcUbGvrQ","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01B4m3u2va8qcTziAjWX3xQi","name":"Write","input":{"file_path":"/data/hypogenicai/workspaces/llm-washing-machine-claude/planning.md","content":"# Research Plan: Where is \"Washing Machine\" Stored in LLMs?\n\n## Motivation & Novelty Assessment\n\n### Why This Research Matters\nLarge language models must represent millions of compound concepts (\"washing machine\", \"hot dog\", \"coffee table\"), but the residual stream has limited dimensionality (~4096 for 7B models). The superposition hypothesis (Elhage et al., 2022) suggests that sparse concepts share directions, but no study has directly investigated how multi-token compound nouns — as opposed to single-token concepts — are represented. Understanding this is crucial for mechanistic interpretability, concept editing, and understanding the limits of linear representation theory.\n\n### Gap in Existing Work\n- Park et al. (2024) tested 27 single-token concepts but never multi-token compounds\n- Feucht et al. (2024) showed token erasure for named entities but not common compound nouns\n- Ormerod et al. (2024) probed compound semantics in BERT (masked LM), not autoregressive models\n- No study has directly compared compound concept directions vs. constituent word directions in the residual stream\n- The core question — does \"washing machine\" have its own direction or is it derived from \"washing\" + context — remains unanswered\n\n### Our Novel Contribution\nWe conduct three complementary experiments on GPT-2 (small, accessible, well-studied) to test whether compound concepts are stored holistically or compositionally:\n1. **Next-token probability analysis**: Measure how strongly \"washing\" predicts \"machine\" vs. alternative contexts\n2. **Residual stream direction analysis**: Extract and compare concept directions for compounds vs. constituents across layers\n3. **Compositional vs. holistic representation probing**: Test whether compound representations are linearly separable from constituent representations\n\n### Experiment Justification\n- **Experiment 1** (Next-Token Prediction): Directly tests the hypothesis that LLMs \"store washing and then machine becomes more likely.\" If P(machine|\"The washing\") >> P(machine|baseline), this supports the compositional hypothesis.\n- **Experiment 2** (Residual Stream Directions): Tests whether compound concepts have unique directions in the residual stream. If compound directions are well-predicted by constituent directions, compounds are compositionally derived.\n- **Experiment 3** (Layer-wise Probing): Tests where in the network compound concepts emerge. If compound representations only appear at the last token position after several layers, this supports the token erasure / implicit vocabulary hypothesis.\n\n## Research Question\nIn large language models, are compound concepts like \"washing machine\" represented as unique directions in the residual stream, or are they derived compositionally from constituent words plus context?\n\n## Background and Motivation\nThere are far more referenceable concepts than available dimensions in an LLM's residual stream. For single-token concepts, superposition allows nearly-orthogonal storage. But multi-token compounds raise a unique challenge: the model must somehow represent \"washing machine\" as a unified concept despite processing it as two separate tokens. Three possibilities exist:\n1. **Holistic**: The model develops a unique direction for \"washing machine\" as a compound (assembled at the second token position)\n2. **Compositional**: \"Washing\" has a direction that activates contextual circuits, making \"machine\" more likely; no unified compound direction exists\n3. **Hybrid**: Some blend — early layers are compositional, but later layers develop a holistic compound representation\n\n## Hypothesis Decomposition\n\n### H1: Next-token prediction drives compound assembly\n- **Testable prediction**: P(machine | \"The washing\") >> P(machine | \"The red\") >> P(machine | baseline)\n- **Metric**: Next-token probability and rank of \"machine\" after \"washing\" vs. controls\n- **Null hypothesis**: Context does not significantly affect P(machine)\n\n### H2: Compound concepts lack unique residual stream directions\n- **Testable prediction**: The direction for \"washing machine\" (at the second token) is well-predicted by a linear combination of \"washing\" direction + \"machine\" direction\n- **Metric**: Cosine similarity between compound direction and span of constituent directions; reconstruction R²\n- **Null hypothesis**: Compound directions are linearly independent of constituent directions\n\n### H3: Compound representations emerge through token erasure\n- **Testable prediction**: Information about preceding tokens is erased/transformed at the last compound token in early-to-mid layers, more so for conventional compounds than compositional phrases\n- **Metric**: Linear probe accuracy for preceding token across layers; erasure score\n- **Null hypothesis**: No differential erasure between compounds and compositional controls\n\n## Proposed Methodology\n\n### Approach\nWe use GPT-2 (124M parameters, 12 layers, d_model=768) as our primary model because:\n- Well-studied in interpretability (TransformerLens support)\n- Small enough to run multiple experiments on available GPUs\n- 12 layers provide sufficient depth for layer-wise analysis\n- Represents the architecture class (decoder-only transformer) used by modern LLMs\n\nWe'll also validate key findings on GPT-2-medium (355M, 24 layers) to check for scale effects.\n\n### Experimental Steps\n\n#### Experiment 1: Next-Token Prediction Analysis\n1. Construct prompt templates: \"The [word1]\", \"A [word1]\", \"This [word1]\"\n2. For each compound in our dataset, measure P(word2 | context + word1)\n3. Compare against baselines:\n   - P(word2 | random context word)\n   - P(word2 | unconditional)\n   - P(word2 | semantically related but non-compound word)\n4. Analyze how compositionality rating correlates with P(word2)\n\n#### Experiment 2: Residual Stream Direction Analysis\n1. Collect hidden states from 100+ contexts containing each compound/constituent\n2. Compute mean activation vectors for:\n   - \"washing machine\" at the \"machine\" position (compound direction)\n   - \"washing\" in isolation (word1 direction)\n   - \"machine\" in isolation (word2 direction)\n3. Compute cosine similarity between compound and constituent directions\n4. Test linear reconstruction: can compound = α·word1 + β·word2 + bias?\n5. Compare reconstruction quality across compositionality levels\n\n#### Experiment 3: Layer-wise Probing / Token Erasure\n1. For each compound, extract hidden states at the last token position across all layers\n2. Train linear probes to predict:\n   - Identity of the preceding token (word1)\n   - Whether the context is compound vs. non-compound\n3. Track probe accuracy across layers\n4. Compare erasure patterns between:\n   - Conventional compounds (\"washing machine\")\n   - Compositional phrases (\"red machine\")\n   - Idiomatic compounds (\"hot dog\")\n\n### Baselines\n- Random baseline: shuffled labels for probing\n- Compositional control: \"adj + noun\" phrases (e.g., \"red machine\", \"blue car\")\n- Separate word baseline: constituents in non-compound contexts\n- Prior layer baseline: compare early vs. late layer representations\n\n### Evaluation Metrics\n- Next-token probability P(word2 | context)\n- Next-token rank of word2\n- Cosine similarity between direction vectors\n- Linear reconstruction R² (how well compound = f(constituents))\n- Probe accuracy (%) across layers\n- Erasure score: change in probe accuracy from layer 0 to layer N\n- Pearson/Spearman correlation between compositionality rating and metrics\n\n### Statistical Analysis Plan\n- Paired t-tests or Wilcoxon signed-rank tests for comparing conditions\n- Spearman rank correlation for compositionality effects\n- Bootstrap confidence intervals (1000 resamples) for key metrics\n- Multiple comparison correction (Bonferroni) when testing multiple compounds\n- Significance level: α = 0.05\n\n## Expected Outcomes\n\n### If compounds are stored holistically:\n- Compound directions will be linearly independent of constituent directions\n- Token erasure will be strong for compounds (high erasure score)\n- P(word2|word1) will be high but compounds will have representations beyond just word prediction\n\n### If compounds are stored compositionally:\n- Compound directions will be well-reconstructed from constituent directions (high R²)\n- P(word2|word1) will be the primary mechanism\n- No significant token erasure beyond what's needed for prediction\n\n### If hybrid:\n- Early layers show compositional processing (high R² for reconstruction)\n- Late layers show unique compound directions (low R², high cosine distance from constituents)\n- Token erasure occurs in middle layers\n\n## Timeline and Milestones\n1. Environment setup & data prep: 15 min\n2. Experiment 1 (next-token prediction): 30 min\n3. Experiment 2 (residual stream directions): 45 min\n4. Experiment 3 (layer-wise probing): 45 min\n5. Analysis & visualization: 30 min\n6. Documentation: 30 min\n\n## Potential Challenges\n- GPT-2's tokenizer may split compound words unexpectedly → verify tokenization first\n- Context effects: need diverse contexts to avoid overfitting to specific prompts\n- Small model may not develop compound representations that larger models do → validate on GPT-2-medium\n- Some compounds in dataset are single tokens (e.g., \"butterfly\") → filter to multi-token only\n\n## Success Criteria\n1. Clear evidence for/against each of the three hypotheses (H1, H2, H3)\n2. Quantitative metrics showing relationship between compositionality and representation\n3. Layer-wise analysis showing where compound representations emerge\n4. Statistical significance for key comparisons\n5. Reproducible results with documented methodology\n"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":448,"cache_read_input_tokens":50501,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":448},"output_tokens":4,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"9be36161-fa59-44c4-b713-113dd193a556"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01B4m3u2va8qcTziAjWX3xQi","type":"tool_result","content":"File created successfully at: /data/hypogenicai/workspaces/llm-washing-machine-claude/planning.md"}]},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"2a966fbc-0e20-48ac-a0da-632bd63fdd7e","tool_use_result":{"type":"create","filePath":"/data/hypogenicai/workspaces/llm-washing-machine-claude/planning.md","content":"# Research Plan: Where is \"Washing Machine\" Stored in LLMs?\n\n## Motivation & Novelty Assessment\n\n### Why This Research Matters\nLarge language models must represent millions of compound concepts (\"washing machine\", \"hot dog\", \"coffee table\"), but the residual stream has limited dimensionality (~4096 for 7B models). The superposition hypothesis (Elhage et al., 2022) suggests that sparse concepts share directions, but no study has directly investigated how multi-token compound nouns — as opposed to single-token concepts — are represented. Understanding this is crucial for mechanistic interpretability, concept editing, and understanding the limits of linear representation theory.\n\n### Gap in Existing Work\n- Park et al. (2024) tested 27 single-token concepts but never multi-token compounds\n- Feucht et al. (2024) showed token erasure for named entities but not common compound nouns\n- Ormerod et al. (2024) probed compound semantics in BERT (masked LM), not autoregressive models\n- No study has directly compared compound concept directions vs. constituent word directions in the residual stream\n- The core question — does \"washing machine\" have its own direction or is it derived from \"washing\" + context — remains unanswered\n\n### Our Novel Contribution\nWe conduct three complementary experiments on GPT-2 (small, accessible, well-studied) to test whether compound concepts are stored holistically or compositionally:\n1. **Next-token probability analysis**: Measure how strongly \"washing\" predicts \"machine\" vs. alternative contexts\n2. **Residual stream direction analysis**: Extract and compare concept directions for compounds vs. constituents across layers\n3. **Compositional vs. holistic representation probing**: Test whether compound representations are linearly separable from constituent representations\n\n### Experiment Justification\n- **Experiment 1** (Next-Token Prediction): Directly tests the hypothesis that LLMs \"store washing and then machine becomes more likely.\" If P(machine|\"The washing\") >> P(machine|baseline), this supports the compositional hypothesis.\n- **Experiment 2** (Residual Stream Directions): Tests whether compound concepts have unique directions in the residual stream. If compound directions are well-predicted by constituent directions, compounds are compositionally derived.\n- **Experiment 3** (Layer-wise Probing): Tests where in the network compound concepts emerge. If compound representations only appear at the last token position after several layers, this supports the token erasure / implicit vocabulary hypothesis.\n\n## Research Question\nIn large language models, are compound concepts like \"washing machine\" represented as unique directions in the residual stream, or are they derived compositionally from constituent words plus context?\n\n## Background and Motivation\nThere are far more referenceable concepts than available dimensions in an LLM's residual stream. For single-token concepts, superposition allows nearly-orthogonal storage. But multi-token compounds raise a unique challenge: the model must somehow represent \"washing machine\" as a unified concept despite processing it as two separate tokens. Three possibilities exist:\n1. **Holistic**: The model develops a unique direction for \"washing machine\" as a compound (assembled at the second token position)\n2. **Compositional**: \"Washing\" has a direction that activates contextual circuits, making \"machine\" more likely; no unified compound direction exists\n3. **Hybrid**: Some blend — early layers are compositional, but later layers develop a holistic compound representation\n\n## Hypothesis Decomposition\n\n### H1: Next-token prediction drives compound assembly\n- **Testable prediction**: P(machine | \"The washing\") >> P(machine | \"The red\") >> P(machine | baseline)\n- **Metric**: Next-token probability and rank of \"machine\" after \"washing\" vs. controls\n- **Null hypothesis**: Context does not significantly affect P(machine)\n\n### H2: Compound concepts lack unique residual stream directions\n- **Testable prediction**: The direction for \"washing machine\" (at the second token) is well-predicted by a linear combination of \"washing\" direction + \"machine\" direction\n- **Metric**: Cosine similarity between compound direction and span of constituent directions; reconstruction R²\n- **Null hypothesis**: Compound directions are linearly independent of constituent directions\n\n### H3: Compound representations emerge through token erasure\n- **Testable prediction**: Information about preceding tokens is erased/transformed at the last compound token in early-to-mid layers, more so for conventional compounds than compositional phrases\n- **Metric**: Linear probe accuracy for preceding token across layers; erasure score\n- **Null hypothesis**: No differential erasure between compounds and compositional controls\n\n## Proposed Methodology\n\n### Approach\nWe use GPT-2 (124M parameters, 12 layers, d_model=768) as our primary model because:\n- Well-studied in interpretability (TransformerLens support)\n- Small enough to run multiple experiments on available GPUs\n- 12 layers provide sufficient depth for layer-wise analysis\n- Represents the architecture class (decoder-only transformer) used by modern LLMs\n\nWe'll also validate key findings on GPT-2-medium (355M, 24 layers) to check for scale effects.\n\n### Experimental Steps\n\n#### Experiment 1: Next-Token Prediction Analysis\n1. Construct prompt templates: \"The [word1]\", \"A [word1]\", \"This [word1]\"\n2. For each compound in our dataset, measure P(word2 | context + word1)\n3. Compare against baselines:\n   - P(word2 | random context word)\n   - P(word2 | unconditional)\n   - P(word2 | semantically related but non-compound word)\n4. Analyze how compositionality rating correlates with P(word2)\n\n#### Experiment 2: Residual Stream Direction Analysis\n1. Collect hidden states from 100+ contexts containing each compound/constituent\n2. Compute mean activation vectors for:\n   - \"washing machine\" at the \"machine\" position (compound direction)\n   - \"washing\" in isolation (word1 direction)\n   - \"machine\" in isolation (word2 direction)\n3. Compute cosine similarity between compound and constituent directions\n4. Test linear reconstruction: can compound = α·word1 + β·word2 + bias?\n5. Compare reconstruction quality across compositionality levels\n\n#### Experiment 3: Layer-wise Probing / Token Erasure\n1. For each compound, extract hidden states at the last token position across all layers\n2. Train linear probes to predict:\n   - Identity of the preceding token (word1)\n   - Whether the context is compound vs. non-compound\n3. Track probe accuracy across layers\n4. Compare erasure patterns between:\n   - Conventional compounds (\"washing machine\")\n   - Compositional phrases (\"red machine\")\n   - Idiomatic compounds (\"hot dog\")\n\n### Baselines\n- Random baseline: shuffled labels for probing\n- Compositional control: \"adj + noun\" phrases (e.g., \"red machine\", \"blue car\")\n- Separate word baseline: constituents in non-compound contexts\n- Prior layer baseline: compare early vs. late layer representations\n\n### Evaluation Metrics\n- Next-token probability P(word2 | context)\n- Next-token rank of word2\n- Cosine similarity between direction vectors\n- Linear reconstruction R² (how well compound = f(constituents))\n- Probe accuracy (%) across layers\n- Erasure score: change in probe accuracy from layer 0 to layer N\n- Pearson/Spearman correlation between compositionality rating and metrics\n\n### Statistical Analysis Plan\n- Paired t-tests or Wilcoxon signed-rank tests for comparing conditions\n- Spearman rank correlation for compositionality effects\n- Bootstrap confidence intervals (1000 resamples) for key metrics\n- Multiple comparison correction (Bonferroni) when testing multiple compounds\n- Significance level: α = 0.05\n\n## Expected Outcomes\n\n### If compounds are stored holistically:\n- Compound directions will be linearly independent of constituent directions\n- Token erasure will be strong for compounds (high erasure score)\n- P(word2|word1) will be high but compounds will have representations beyond just word prediction\n\n### If compounds are stored compositionally:\n- Compound directions will be well-reconstructed from constituent directions (high R²)\n- P(word2|word1) will be the primary mechanism\n- No significant token erasure beyond what's needed for prediction\n\n### If hybrid:\n- Early layers show compositional processing (high R² for reconstruction)\n- Late layers show unique compound directions (low R², high cosine distance from constituents)\n- Token erasure occurs in middle layers\n\n## Timeline and Milestones\n1. Environment setup & data prep: 15 min\n2. Experiment 1 (next-token prediction): 30 min\n3. Experiment 2 (residual stream directions): 45 min\n4. Experiment 3 (layer-wise probing): 45 min\n5. Analysis & visualization: 30 min\n6. Documentation: 30 min\n\n## Potential Challenges\n- GPT-2's tokenizer may split compound words unexpectedly → verify tokenization first\n- Context effects: need diverse contexts to avoid overfitting to specific prompts\n- Small model may not develop compound representations that larger models do → validate on GPT-2-medium\n- Some compounds in dataset are single tokens (e.g., \"butterfly\") → filter to multi-token only\n\n## Success Criteria\n1. Clear evidence for/against each of the three hypotheses (H1, H2, H3)\n2. Quantitative metrics showing relationship between compositionality and representation\n3. Layer-wise analysis showing where compound representations emerge\n4. Statistical significance for key comparisons\n5. Reproducible results with documented methodology\n","structuredPatch":[],"originalFile":null}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01J3sRgtvXPhki8tpecHSSQm","type":"message","role":"assistant","content":[{"type":"text","text":"Plan is complete. Now moving to Phase 2: Environment setup."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2495,"cache_read_input_tokens":50949,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":2495},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"ccf7f613-d155-465b-96e9-b241ffc1484c"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01J3sRgtvXPhki8tpecHSSQm","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01EpoHwNsreUoh8eGVvdkpom","name":"TodoWrite","input":{"todos":[{"content":"Review pre-gathered resources (literature_review.md, resources.md, papers/, datasets/, code/)","status":"completed","activeForm":"Reviewing pre-gathered resources"},{"content":"Phase 0 & 1: Motivation, novelty assessment, and research plan (planning.md)","status":"completed","activeForm":"Writing motivation assessment and research plan"},{"content":"Phase 2: Environment & data setup","status":"in_progress","activeForm":"Setting up environment and data"},{"content":"Phase 3: Implementation - write experiment code","status":"pending","activeForm":"Implementing experiment code"},{"content":"Phase 4: Run experiments","status":"pending","activeForm":"Running experiments"},{"content":"Phase 5: Analysis - statistical analysis and visualizations","status":"pending","activeForm":"Analyzing results"},{"content":"Phase 6: Final documentation (REPORT.md, README.md)","status":"pending","activeForm":"Writing final documentation"}]}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2495,"cache_read_input_tokens":50949,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":2495},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"27d9fd8a-7f9b-4327-a5e6-12a7964dac09"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01EpoHwNsreUoh8eGVvdkpom","type":"tool_result","content":"Todos have been modified successfully. Ensure that you continue to use the todo list to track your progress. Please proceed with the current tasks if applicable"}]},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"99e0dd23-9ff1-42d3-8802-4ded425a4ded","tool_use_result":{"oldTodos":[{"content":"Review pre-gathered resources (literature_review.md, resources.md, papers/, datasets/, code/)","status":"completed","activeForm":"Reviewing pre-gathered resources"},{"content":"Phase 0 & 1: Motivation, novelty assessment, and research plan (planning.md)","status":"in_progress","activeForm":"Writing motivation assessment and research plan"},{"content":"Phase 2: Environment & data setup","status":"pending","activeForm":"Setting up environment and data"},{"content":"Phase 3: Implementation - write experiment code","status":"pending","activeForm":"Implementing experiment code"},{"content":"Phase 4: Run experiments","status":"pending","activeForm":"Running experiments"},{"content":"Phase 5: Analysis - statistical analysis and visualizations","status":"pending","activeForm":"Analyzing results"},{"content":"Phase 6: Final documentation (REPORT.md, README.md)","status":"pending","activeForm":"Writing final documentation"}],"newTodos":[{"content":"Review pre-gathered resources (literature_review.md, resources.md, papers/, datasets/, code/)","status":"completed","activeForm":"Reviewing pre-gathered resources"},{"content":"Phase 0 & 1: Motivation, novelty assessment, and research plan (planning.md)","status":"completed","activeForm":"Writing motivation assessment and research plan"},{"content":"Phase 2: Environment & data setup","status":"in_progress","activeForm":"Setting up environment and data"},{"content":"Phase 3: Implementation - write experiment code","status":"pending","activeForm":"Implementing experiment code"},{"content":"Phase 4: Run experiments","status":"pending","activeForm":"Running experiments"},{"content":"Phase 5: Analysis - statistical analysis and visualizations","status":"pending","activeForm":"Analyzing results"},{"content":"Phase 6: Final documentation (REPORT.md, README.md)","status":"pending","activeForm":"Writing final documentation"}]}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_0136hWepqdTELT919GD5N1Yg","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01UiDe3oeQsoGHoDAL6qLFM1","name":"Bash","input":{"command":"source /data/hypogenicai/workspaces/llm-washing-machine-claude/.venv/bin/activate && uv add torch transformers transformer-lens matplotlib seaborn scipy scikit-learn pandas numpy tqdm einops 2>&1 | tail -20","description":"Install core dependencies for experiments","timeout":300000}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":359,"cache_read_input_tokens":53444,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":359},"output_tokens":26,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"ae956e05-09c0-4177-9786-6dcf6473933b"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01UiDe3oeQsoGHoDAL6qLFM1","type":"tool_result","content":" + sentencepiece==0.2.1\n + sentry-sdk==2.52.0\n + setuptools==81.0.0\n + six==1.17.0\n + smmap==5.0.2\n + sympy==1.14.0\n + threadpoolctl==3.6.0\n + tokenizers==0.22.2\n + torch==2.10.0\n + tqdm==4.67.3\n + transformer-lens==2.15.4\n + transformers==4.57.6\n + transformers-stream-generator==0.0.5\n + triton==3.6.0\n + typeguard==4.4.4\n + typing-inspection==0.4.2\n + wadler-lindig==0.1.7\n + wandb==0.24.2\n + xxhash==3.6.0\n + yarl==1.22.0","is_error":false}]},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"ba2b651a-bb3d-4dfc-a273-3cfff23c1bca","tool_use_result":{"stdout":" + sentencepiece==0.2.1\n + sentry-sdk==2.52.0\n + setuptools==81.0.0\n + six==1.17.0\n + smmap==5.0.2\n + sympy==1.14.0\n + threadpoolctl==3.6.0\n + tokenizers==0.22.2\n + torch==2.10.0\n + tqdm==4.67.3\n + transformer-lens==2.15.4\n + transformers==4.57.6\n + transformers-stream-generator==0.0.5\n + triton==3.6.0\n + typeguard==4.4.4\n + typing-inspection==0.4.2\n + wadler-lindig==0.1.7\n + wandb==0.24.2\n + xxhash==3.6.0\n + yarl==1.22.0","stderr":"","interrupted":false,"isImage":false}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01TbX4javtnJvR5mEJLqM1mu","type":"message","role":"assistant","content":[{"type":"text","text":"Dependencies installed. Now let me create the experiment code. I'll build the three experiments in a single well-structured Python script."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":396,"cache_read_input_tokens":53803,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":396},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"158c60ec-9ef7-49cc-9a6e-732b15d432ba"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01TbX4javtnJvR5mEJLqM1mu","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01V8ZDeRSMPMoLrqwvXczwEh","name":"Bash","input":{"command":"mkdir -p /data/hypogenicai/workspaces/llm-washing-machine-claude/src /data/hypogenicai/workspaces/llm-washing-machine-claude/results/plots","description":"Create src and results directories"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":396,"cache_read_input_tokens":53803,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":396},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"11df7ec7-ad41-4a39-9440-1e4cb147d0c4"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01V8ZDeRSMPMoLrqwvXczwEh","type":"tool_result","content":"","is_error":false}]},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"b448b72b-b5be-4fed-9a4c-624357b0151a","tool_use_result":{"stdout":"","stderr":"","interrupted":false,"isImage":false}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01F6pyHPRaVuBtkdbeyqFayk","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01Q9ZeZMwuckr4cRqDJWbAQ3","name":"TodoWrite","input":{"todos":[{"content":"Review pre-gathered resources (literature_review.md, resources.md, papers/, datasets/, code/)","status":"completed","activeForm":"Reviewing pre-gathered resources"},{"content":"Phase 0 & 1: Motivation, novelty assessment, and research plan (planning.md)","status":"completed","activeForm":"Writing motivation assessment and research plan"},{"content":"Phase 2: Environment & data setup","status":"completed","activeForm":"Setting up environment and data"},{"content":"Phase 3: Implementation - write experiment code","status":"in_progress","activeForm":"Implementing experiment code"},{"content":"Phase 4: Run experiments","status":"pending","activeForm":"Running experiments"},{"content":"Phase 5: Analysis - statistical analysis and visualizations","status":"pending","activeForm":"Analyzing results"},{"content":"Phase 6: Final documentation (REPORT.md, README.md)","status":"pending","activeForm":"Writing final documentation"}]}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":174,"cache_read_input_tokens":54199,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":174},"output_tokens":19,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"67015a96-af77-49e5-8b60-47eb2861d87a"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Q9ZeZMwuckr4cRqDJWbAQ3","type":"tool_result","content":"Todos have been modified successfully. Ensure that you continue to use the todo list to track your progress. Please proceed with the current tasks if applicable"}]},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"8ed3bd4b-9db5-46c3-98ad-580c35aa3007","tool_use_result":{"oldTodos":[{"content":"Review pre-gathered resources (literature_review.md, resources.md, papers/, datasets/, code/)","status":"completed","activeForm":"Reviewing pre-gathered resources"},{"content":"Phase 0 & 1: Motivation, novelty assessment, and research plan (planning.md)","status":"completed","activeForm":"Writing motivation assessment and research plan"},{"content":"Phase 2: Environment & data setup","status":"in_progress","activeForm":"Setting up environment and data"},{"content":"Phase 3: Implementation - write experiment code","status":"pending","activeForm":"Implementing experiment code"},{"content":"Phase 4: Run experiments","status":"pending","activeForm":"Running experiments"},{"content":"Phase 5: Analysis - statistical analysis and visualizations","status":"pending","activeForm":"Analyzing results"},{"content":"Phase 6: Final documentation (REPORT.md, README.md)","status":"pending","activeForm":"Writing final documentation"}],"newTodos":[{"content":"Review pre-gathered resources (literature_review.md, resources.md, papers/, datasets/, code/)","status":"completed","activeForm":"Reviewing pre-gathered resources"},{"content":"Phase 0 & 1: Motivation, novelty assessment, and research plan (planning.md)","status":"completed","activeForm":"Writing motivation assessment and research plan"},{"content":"Phase 2: Environment & data setup","status":"completed","activeForm":"Setting up environment and data"},{"content":"Phase 3: Implementation - write experiment code","status":"in_progress","activeForm":"Implementing experiment code"},{"content":"Phase 4: Run experiments","status":"pending","activeForm":"Running experiments"},{"content":"Phase 5: Analysis - statistical analysis and visualizations","status":"pending","activeForm":"Analyzing results"},{"content":"Phase 6: Final documentation (REPORT.md, README.md)","status":"pending","activeForm":"Writing final documentation"}]}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01BJzjMB3rtAMg9cxefUqixB","type":"message","role":"assistant","content":[{"type":"text","text":"Now I'll write the experiment code. First, let me verify GPT-2 tokenization for our target compounds so I can handle multi-token issues properly."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":344,"cache_read_input_tokens":54373,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":344},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"a489ad08-0bfe-4573-8091-949444cead43"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01BJzjMB3rtAMg9cxefUqixB","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01Gk3FsnW7WQ5UHYqeaU8SHu","name":"Bash","input":{"command":"source /data/hypogenicai/workspaces/llm-washing-machine-claude/.venv/bin/activate && python -c \"\nfrom transformers import GPT2Tokenizer\ntok = GPT2Tokenizer.from_pretrained('gpt2')\ncompounds = ['washing machine', 'coffee table', 'hot dog', 'butterfly', 'swimming pool', 'parking lot', 'greenhouse', 'keyboard', 'breakfast', 'rainbow', 'bookworm', 'ladybug', 'eggplant', 'popcorn', 'football']\nfor c in compounds:\n    tokens = tok.encode(' ' + c)\n    decoded = [tok.decode([t]) for t in tokens]\n    print(f'{c:20s} -> {decoded}')\nprint()\n# Also check individual words\nwords = ['washing', 'machine', 'hot', 'dog', 'coffee', 'table', 'swimming', 'pool']\nfor w in words:\n    tokens = tok.encode(' ' + w)\n    decoded = [tok.decode([t]) for t in tokens]\n    print(f'{w:20s} -> {decoded}')\n\" 2>&1","description":"Check GPT-2 tokenization of compound nouns","timeout":60000}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":344,"cache_read_input_tokens":54373,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":344},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"4033031a-3105-408e-a670-b3aad81f109e"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Gk3FsnW7WQ5UHYqeaU8SHu","type":"tool_result","content":"washing machine      -> [' washing', ' machine']\ncoffee table         -> [' coffee', ' table']\nhot dog              -> [' hot', ' dog']\nbutterfly            -> [' butterfly']\nswimming pool        -> [' swimming', ' pool']\nparking lot          -> [' parking', ' lot']\ngreenhouse           -> [' greenhouse']\nkeyboard             -> [' keyboard']\nbreakfast            -> [' breakfast']\nrainbow              -> [' rainbow']\nbookworm             -> [' book', 'worm']\nladybug              -> [' lady', 'bug']\neggplant             -> [' egg', 'plant']\npopcorn              -> [' popcorn']\nfootball             -> [' football']\n\nwashing              -> [' washing']\nmachine              -> [' machine']\nhot                  -> [' hot']\ndog                  -> [' dog']\ncoffee               -> [' coffee']\ntable                -> [' table']\nswimming             -> [' swimming']\npool                 -> [' pool']","is_error":false}]},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"d66cac9f-68d1-49c0-bd38-66590a916a72","tool_use_result":{"stdout":"washing machine      -> [' washing', ' machine']\ncoffee table         -> [' coffee', ' table']\nhot dog              -> [' hot', ' dog']\nbutterfly            -> [' butterfly']\nswimming pool        -> [' swimming', ' pool']\nparking lot          -> [' parking', ' lot']\ngreenhouse           -> [' greenhouse']\nkeyboard             -> [' keyboard']\nbreakfast            -> [' breakfast']\nrainbow              -> [' rainbow']\nbookworm             -> [' book', 'worm']\nladybug              -> [' lady', 'bug']\neggplant             -> [' egg', 'plant']\npopcorn              -> [' popcorn']\nfootball             -> [' football']\n\nwashing              -> [' washing']\nmachine              -> [' machine']\nhot                  -> [' hot']\ndog                  -> [' dog']\ncoffee               -> [' coffee']\ntable                -> [' table']\nswimming             -> [' swimming']\npool                 -> [' pool']","stderr":"","interrupted":false,"isImage":false}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01VgGsqsZqSxPVXMH5jtk5pi","type":"message","role":"assistant","content":[{"type":"text","text":"Good — \"washing machine\" tokenizes cleanly as two tokens. Some compounds are single tokens (butterfly, greenhouse, keyboard, etc.) which I'll need to handle differently. Now let me write the main experiment code."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":662,"cache_read_input_tokens":54717,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":662},"output_tokens":2,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"b60e2fc1-be4e-4522-a4d7-2a00d8aade13"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01VgGsqsZqSxPVXMH5jtk5pi","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_014zUX8a1wGu2y464HDjJE6U","name":"Write","input":{"file_path":"/data/hypogenicai/workspaces/llm-washing-machine-claude/src/experiment.py","content":"\"\"\"\nExperiment: Where is \"Washing Machine\" Stored in LLMs?\n\nThree experiments testing how compound concepts are represented:\n1. Next-token prediction analysis\n2. Residual stream direction analysis\n3. Layer-wise probing for compound concept emergence\n\nUses GPT-2 (124M) via TransformerLens for interpretability access.\n\"\"\"\n\nimport json\nimport os\nimport random\nimport sys\nfrom pathlib import Path\n\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nimport matplotlib\nmatplotlib.use('Agg')\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nfrom sklearn.linear_model import LogisticRegression, Ridge\nfrom sklearn.model_selection import cross_val_score\nfrom tqdm import tqdm\nimport transformer_lens as tl\n\n# Reproducibility\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed_all(SEED)\n\nDEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\nRESULTS_DIR = Path(\"/data/hypogenicai/workspaces/llm-washing-machine-claude/results\")\nPLOTS_DIR = RESULTS_DIR / \"plots\"\nPLOTS_DIR.mkdir(parents=True, exist_ok=True)\n\n# ── Data ──────────────────────────────────────────────────────────────────\n\n# Two-token compound nouns with compositionality ratings and control phrases\n# Each entry: (compound, word1, word2, compositionality, control_phrase)\n# Control phrases use the same word2 but a different, non-compound word1\nCOMPOUNDS = [\n    (\"washing machine\", \"washing\", \"machine\", 4, \"red machine\"),\n    (\"coffee table\", \"coffee\", \"table\", 5, \"wooden table\"),\n    (\"swimming pool\", \"swimming\", \"pool\", 4, \"deep pool\"),\n    (\"parking lot\", \"parking\", \"lot\", 4, \"empty lot\"),\n    (\"hot dog\", \"hot\", \"dog\", 1, \"big dog\"),\n    (\"shooting star\", \"shooting\", \"star\", 2, \"bright star\"),\n    (\"living room\", \"living\", \"room\", 3, \"large room\"),\n    (\"driving license\", \"driving\", \"license\", 4, \"new license\"),\n    (\"guinea pig\", \"guinea\", \"pig\", 2, \"small pig\"),\n    (\"brick house\", \"brick\", \"house\", 5, \"old house\"),\n    (\"mountain cabin\", \"mountain\", \"cabin\", 5, \"small cabin\"),\n    (\"garden hose\", \"garden\", \"hose\", 5, \"long hose\"),\n    (\"water bottle\", \"water\", \"bottle\", 5, \"glass bottle\"),\n    (\"steel bridge\", \"steel\", \"bridge\", 5, \"old bridge\"),\n    (\"chocolate cake\", \"chocolate\", \"cake\", 5, \"big cake\"),\n    (\"door handle\", \"door\", \"handle\", 5, \"metal handle\"),\n    (\"blueberry\", \"blue\", \"berry\", 4, \"small berry\"),\n    (\"snowman\", \"snow\", \"man\", 4, \"tall man\"),\n    (\"sunflower\", \"sun\", \"flower\", 4, \"red flower\"),\n]\n\n# Sentence templates for generating diverse contexts\nTEMPLATES = [\n    \"The {compound} was\",\n    \"She bought a {compound} for\",\n    \"I saw a {compound} in the\",\n    \"There is a {compound} near the\",\n    \"He fixed the {compound} with\",\n    \"A new {compound} arrived\",\n    \"The old {compound} needed\",\n    \"We need a {compound} to\",\n]\n\n# Additional contexts for word-in-isolation analysis\nISOLATION_TEMPLATES = [\n    \"The {word} was very\",\n    \"I noticed the {word} seemed\",\n    \"That {word} is quite\",\n    \"A {word} appeared in the\",\n]\n\n\ndef load_model(model_name=\"gpt2\"):\n    \"\"\"Load GPT-2 model via TransformerLens with hooks.\"\"\"\n    print(f\"Loading model: {model_name}\")\n    model = tl.HookedTransformer.from_pretrained(model_name, device=DEVICE)\n    model.eval()\n    print(f\"Model loaded: {model.cfg.n_layers} layers, d_model={model.cfg.d_model}\")\n    return model\n\n\ndef get_token_ids(model, word):\n    \"\"\"Get the token ID for a word (with leading space).\"\"\"\n    tokens = model.to_tokens(f\" {word}\", prepend_bos=False)\n    return tokens[0].tolist()\n\n\n# ── Experiment 1: Next-Token Prediction Analysis ─────────────────────────\n\ndef experiment1_next_token_prediction(model):\n    \"\"\"\n    Test whether 'washing' alone makes 'machine' more likely.\n    Compare P(word2 | word1) across compositionality levels.\n    \"\"\"\n    print(\"\\n\" + \"=\"*70)\n    print(\"EXPERIMENT 1: Next-Token Prediction Analysis\")\n    print(\"=\"*70)\n\n    results = []\n\n    for compound, word1, word2, comp_rating, control in tqdm(COMPOUNDS, desc=\"Compounds\"):\n        # Get target token id for word2\n        word2_tokens = get_token_ids(model, word2)\n        if len(word2_tokens) != 1:\n            print(f\"  Skipping {compound}: word2 '{word2}' is multi-token\")\n            continue\n        word2_id = word2_tokens[0]\n\n        # 1. P(word2 | \"The word1\")  — compound context\n        compound_probs = []\n        compound_ranks = []\n        for template in TEMPLATES:\n            prompt = template.split(\"{compound}\")[0] + word1\n            tokens = model.to_tokens(prompt)\n            with torch.no_grad():\n                logits = model(tokens)\n            last_logits = logits[0, -1]\n            probs = F.softmax(last_logits, dim=-1)\n            p_word2 = probs[word2_id].item()\n            rank = (probs > probs[word2_id]).sum().item() + 1\n            compound_probs.append(p_word2)\n            compound_ranks.append(rank)\n\n        # 2. P(word2 | \"The control_word1\") — control context\n        control_word1 = control.split()[0]\n        control_probs = []\n        control_ranks = []\n        for template in TEMPLATES:\n            prompt = template.split(\"{compound}\")[0] + control_word1\n            tokens = model.to_tokens(prompt)\n            with torch.no_grad():\n                logits = model(tokens)\n            last_logits = logits[0, -1]\n            probs = F.softmax(last_logits, dim=-1)\n            p_word2 = probs[word2_id].item()\n            rank = (probs > probs[word2_id]).sum().item() + 1\n            control_probs.append(p_word2)\n            control_ranks.append(rank)\n\n        # 3. P(word2 | unconditional) — just BOS token\n        bos_tokens = model.to_tokens(\"The\")\n        with torch.no_grad():\n            logits = model(bos_tokens)\n        last_logits = logits[0, -1]\n        probs = F.softmax(last_logits, dim=-1)\n        p_word2_uncond = probs[word2_id].item()\n        rank_uncond = (probs > probs[word2_id]).sum().item() + 1\n\n        # 4. Get top-5 predictions after word1 for interpretability\n        tokens = model.to_tokens(f\"The {word1}\")\n        with torch.no_grad():\n            logits = model(tokens)\n        last_logits = logits[0, -1]\n        probs = F.softmax(last_logits, dim=-1)\n        top5_ids = torch.topk(probs, 5).indices.tolist()\n        top5 = [(model.to_string([tid]).strip(), probs[tid].item()) for tid in top5_ids]\n\n        result = {\n            \"compound\": compound,\n            \"word1\": word1,\n            \"word2\": word2,\n            \"compositionality\": comp_rating,\n            \"p_word2_compound_mean\": np.mean(compound_probs),\n            \"p_word2_compound_std\": np.std(compound_probs),\n            \"rank_compound_mean\": np.mean(compound_ranks),\n            \"p_word2_control_mean\": np.mean(control_probs),\n            \"p_word2_control_std\": np.std(control_probs),\n            \"rank_control_mean\": np.mean(control_ranks),\n            \"p_word2_unconditional\": p_word2_uncond,\n            \"rank_unconditional\": rank_uncond,\n            \"boost_ratio\": np.mean(compound_probs) / max(np.mean(control_probs), 1e-10),\n            \"top5_after_word1\": top5,\n        }\n        results.append(result)\n\n        print(f\"  {compound:20s} | P(w2|w1)={result['p_word2_compound_mean']:.4f} \"\n              f\"rank={result['rank_compound_mean']:.0f} | \"\n              f\"P(w2|ctrl)={result['p_word2_control_mean']:.4f} \"\n              f\"rank={result['rank_control_mean']:.0f} | \"\n              f\"boost={result['boost_ratio']:.1f}x | \"\n              f\"top5: {[t[0] for t in top5]}\")\n\n    # Save results\n    with open(RESULTS_DIR / \"exp1_next_token.json\", \"w\") as f:\n        json.dump(results, f, indent=2)\n\n    return results\n\n\ndef plot_experiment1(results):\n    \"\"\"Visualize Experiment 1 results.\"\"\"\n    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n\n    compounds = [r[\"compound\"] for r in results]\n    comp_ratings = [r[\"compositionality\"] for r in results]\n    p_compound = [r[\"p_word2_compound_mean\"] for r in results]\n    p_control = [r[\"p_word2_control_mean\"] for r in results]\n    boost_ratios = [r[\"boost_ratio\"] for r in results]\n\n    # Sort by boost ratio for bar chart\n    sorted_idx = np.argsort(boost_ratios)[::-1]\n\n    # Plot 1: Boost ratio bar chart\n    ax = axes[0]\n    bars = ax.barh(range(len(compounds)),\n                   [boost_ratios[i] for i in sorted_idx],\n                   color=['#e74c3c' if comp_ratings[i] <= 2 else\n                          '#f39c12' if comp_ratings[i] == 3 else\n                          '#2ecc71' for i in sorted_idx])\n    ax.set_yticks(range(len(compounds)))\n    ax.set_yticklabels([compounds[i] for i in sorted_idx], fontsize=8)\n    ax.set_xlabel(\"Boost Ratio: P(w2|w1) / P(w2|control)\")\n    ax.set_title(\"How Much Does Word1 Boost Word2 Prediction?\")\n    ax.axvline(x=1, color='k', linestyle='--', alpha=0.5)\n    ax.invert_yaxis()\n\n    # Plot 2: Compound prob vs control prob scatter\n    ax = axes[1]\n    scatter = ax.scatter(p_control, p_compound, c=comp_ratings,\n                        cmap='RdYlGn', s=80, edgecolors='k', linewidth=0.5,\n                        vmin=1, vmax=5)\n    ax.plot([0, max(max(p_compound), max(p_control))],\n            [0, max(max(p_compound), max(p_control))],\n            'k--', alpha=0.3, label='y=x')\n    for i, c in enumerate(compounds):\n        if boost_ratios[i] > 5 or p_compound[i] > 0.05:\n            ax.annotate(c, (p_control[i], p_compound[i]),\n                       fontsize=6, ha='left', va='bottom')\n    ax.set_xlabel(\"P(word2 | control word)\")\n    ax.set_ylabel(\"P(word2 | compound word1)\")\n    ax.set_title(\"Compound vs Control Next-Token Probability\")\n    plt.colorbar(scatter, ax=ax, label=\"Compositionality Rating\")\n\n    # Plot 3: Compositionality vs boost ratio\n    ax = axes[2]\n    ax.scatter(comp_ratings, boost_ratios, s=80, c='steelblue', edgecolors='k')\n    for i, c in enumerate(compounds):\n        ax.annotate(c, (comp_ratings[i], boost_ratios[i]),\n                   fontsize=6, ha='left', va='bottom', rotation=15)\n    r, p = stats.spearmanr(comp_ratings, boost_ratios)\n    ax.set_xlabel(\"Compositionality Rating (1=idiomatic, 5=compositional)\")\n    ax.set_ylabel(\"Boost Ratio\")\n    ax.set_title(f\"Compositionality vs Prediction Boost\\n(Spearman r={r:.3f}, p={p:.3f})\")\n\n    plt.tight_layout()\n    plt.savefig(PLOTS_DIR / \"exp1_next_token_prediction.png\", dpi=150, bbox_inches='tight')\n    plt.close()\n    print(f\"Saved: {PLOTS_DIR / 'exp1_next_token_prediction.png'}\")\n\n\n# ── Experiment 2: Residual Stream Direction Analysis ─────────────────────\n\ndef experiment2_residual_directions(model):\n    \"\"\"\n    Compare directions for compound concepts vs. constituent words.\n    Test: is the compound direction a linear combination of constituent directions?\n    \"\"\"\n    print(\"\\n\" + \"=\"*70)\n    print(\"EXPERIMENT 2: Residual Stream Direction Analysis\")\n    print(\"=\"*70)\n\n    n_layers = model.cfg.n_layers\n    results = []\n\n    for compound, word1, word2, comp_rating, control in tqdm(COMPOUNDS, desc=\"Compounds\"):\n        # Verify both words are single tokens\n        w1_toks = get_token_ids(model, word1)\n        w2_toks = get_token_ids(model, word2)\n        if len(w1_toks) != 1 or len(w2_toks) != 1:\n            print(f\"  Skipping {compound}: multi-token constituent\")\n            continue\n\n        # Collect hidden states across contexts\n        compound_states = {l: [] for l in range(n_layers)}\n        word1_states = {l: [] for l in range(n_layers)}\n        word2_states = {l: [] for l in range(n_layers)}\n        control_states = {l: [] for l in range(n_layers)}\n\n        # Compound contexts: hidden state at word2 position\n        for template in TEMPLATES:\n            sentence = template.format(compound=compound)\n            tokens = model.to_tokens(sentence)\n            with torch.no_grad():\n                _, cache = model.run_with_cache(tokens)\n\n            # Find position of word2 in tokenized sentence\n            token_strs = [model.to_string([t]) for t in tokens[0]]\n            # word2 with space prefix\n            w2_str = f\" {word2}\"\n            w2_pos = None\n            for pos, ts in enumerate(token_strs):\n                if ts == w2_str:\n                    # Check that previous token is word1\n                    if pos > 0 and token_strs[pos-1].strip() == word1:\n                        w2_pos = pos\n                        break\n            if w2_pos is None:\n                continue\n\n            for layer in range(n_layers):\n                h = cache[f\"blocks.{layer}.hook_resid_post\"][0, w2_pos].cpu().numpy()\n                compound_states[layer].append(h)\n\n        # Word1 in isolation contexts\n        for template in ISOLATION_TEMPLATES:\n            sentence = template.format(word=word1)\n            tokens = model.to_tokens(sentence)\n            with torch.no_grad():\n                _, cache = model.run_with_cache(tokens)\n            token_strs = [model.to_string([t]) for t in tokens[0]]\n            w1_str = f\" {word1}\"\n            w1_pos = None\n            for pos, ts in enumerate(token_strs):\n                if ts == w1_str:\n                    w1_pos = pos\n                    break\n            if w1_pos is None:\n                continue\n            for layer in range(n_layers):\n                h = cache[f\"blocks.{layer}.hook_resid_post\"][0, w1_pos].cpu().numpy()\n                word1_states[layer].append(h)\n\n        # Word2 in isolation contexts\n        for template in ISOLATION_TEMPLATES:\n            sentence = template.format(word=word2)\n            tokens = model.to_tokens(sentence)\n            with torch.no_grad():\n                _, cache = model.run_with_cache(tokens)\n            token_strs = [model.to_string([t]) for t in tokens[0]]\n            w2_str = f\" {word2}\"\n            w2_pos = None\n            for pos, ts in enumerate(token_strs):\n                if ts == w2_str:\n                    w2_pos = pos\n                    break\n            if w2_pos is None:\n                continue\n            for layer in range(n_layers):\n                h = cache[f\"blocks.{layer}.hook_resid_post\"][0, w2_pos].cpu().numpy()\n                word2_states[layer].append(h)\n\n        # Control contexts: hidden state at word2 position in non-compound context\n        control_word1 = control.split()[0]\n        for template in TEMPLATES:\n            sentence = template.format(compound=control)\n            tokens = model.to_tokens(sentence)\n            with torch.no_grad():\n                _, cache = model.run_with_cache(tokens)\n            token_strs = [model.to_string([t]) for t in tokens[0]]\n            w2_str = f\" {word2}\"\n            w2_pos = None\n            for pos, ts in enumerate(token_strs):\n                if ts == w2_str:\n                    w2_pos = pos\n                    break\n            if w2_pos is None:\n                continue\n            for layer in range(n_layers):\n                h = cache[f\"blocks.{layer}.hook_resid_post\"][0, w2_pos].cpu().numpy()\n                control_states[layer].append(h)\n\n        # Compute metrics per layer\n        layer_metrics = []\n        for layer in range(n_layers):\n            if not compound_states[layer] or not word1_states[layer] or not word2_states[layer]:\n                layer_metrics.append(None)\n                continue\n\n            # Mean directions\n            compound_dir = np.mean(compound_states[layer], axis=0)\n            word1_dir = np.mean(word1_states[layer], axis=0)\n            word2_dir = np.mean(word2_states[layer], axis=0)\n\n            # Cosine similarities\n            def cosine_sim(a, b):\n                return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b) + 1e-10)\n\n            sim_compound_w1 = cosine_sim(compound_dir, word1_dir)\n            sim_compound_w2 = cosine_sim(compound_dir, word2_dir)\n            sim_w1_w2 = cosine_sim(word1_dir, word2_dir)\n\n            # Linear reconstruction: compound = alpha*word1 + beta*word2 + bias\n            X = np.stack([word1_dir, word2_dir], axis=0).T  # d_model x 2\n            y = compound_dir\n            # Least squares: (X^T X)^{-1} X^T y\n            try:\n                coeffs = np.linalg.lstsq(X, y, rcond=None)[0]\n                y_pred = X @ coeffs\n                ss_res = np.sum((y - y_pred) ** 2)\n                ss_tot = np.sum((y - np.mean(y)) ** 2)\n                r_squared = 1 - ss_res / ss_tot if ss_tot > 0 else 0\n            except np.linalg.LinAlgError:\n                coeffs = np.array([0, 0])\n                r_squared = 0\n\n            # Control comparison\n            if control_states[layer]:\n                control_dir = np.mean(control_states[layer], axis=0)\n                sim_control_w2 = cosine_sim(control_dir, word2_dir)\n                sim_compound_control = cosine_sim(compound_dir, control_dir)\n            else:\n                sim_control_w2 = None\n                sim_compound_control = None\n\n            # Uniqueness: residual after removing word1 and word2 components\n            residual = compound_dir - y_pred\n            residual_norm_ratio = np.linalg.norm(residual) / (np.linalg.norm(compound_dir) + 1e-10)\n\n            layer_metrics.append({\n                \"layer\": layer,\n                \"sim_compound_word1\": float(sim_compound_w1),\n                \"sim_compound_word2\": float(sim_compound_w2),\n                \"sim_word1_word2\": float(sim_w1_w2),\n                \"reconstruction_r2\": float(r_squared),\n                \"alpha_word1\": float(coeffs[0]),\n                \"beta_word2\": float(coeffs[1]),\n                \"residual_norm_ratio\": float(residual_norm_ratio),\n                \"sim_control_word2\": float(sim_control_w2) if sim_control_w2 is not None else None,\n                \"sim_compound_control\": float(sim_compound_control) if sim_compound_control is not None else None,\n            })\n\n        result = {\n            \"compound\": compound,\n            \"word1\": word1,\n            \"word2\": word2,\n            \"compositionality\": comp_rating,\n            \"n_compound_contexts\": len(compound_states[0]),\n            \"n_word1_contexts\": len(word1_states[0]),\n            \"n_word2_contexts\": len(word2_states[0]),\n            \"layer_metrics\": layer_metrics,\n        }\n        results.append(result)\n\n        # Print summary for last layer\n        last = layer_metrics[-1]\n        if last:\n            print(f\"  {compound:20s} | cos(C,w1)={last['sim_compound_word1']:.3f} \"\n                  f\"cos(C,w2)={last['sim_compound_word2']:.3f} \"\n                  f\"R²={last['reconstruction_r2']:.3f} \"\n                  f\"residual={last['residual_norm_ratio']:.3f}\")\n\n    with open(RESULTS_DIR / \"exp2_residual_directions.json\", \"w\") as f:\n        json.dump(results, f, indent=2)\n\n    return results\n\n\ndef plot_experiment2(results):\n    \"\"\"Visualize Experiment 2 results.\"\"\"\n    fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n\n    n_layers = 12  # GPT-2\n\n    # Plot 1: R² across layers (all compounds)\n    ax = axes[0, 0]\n    for r in results:\n        layers = []\n        r2_vals = []\n        for m in r[\"layer_metrics\"]:\n            if m is not None:\n                layers.append(m[\"layer\"])\n                r2_vals.append(m[\"reconstruction_r2\"])\n        color = plt.cm.RdYlGn(r[\"compositionality\"] / 5.0)\n        ax.plot(layers, r2_vals, alpha=0.6, color=color, linewidth=1.5)\n    ax.set_xlabel(\"Layer\")\n    ax.set_ylabel(\"R² (compound ≈ α·word1 + β·word2)\")\n    ax.set_title(\"Linear Reconstruction Quality Across Layers\")\n    ax.set_ylim(-0.1, 1.1)\n    # Add colorbar\n    sm = plt.cm.ScalarMappable(cmap='RdYlGn', norm=plt.Normalize(1, 5))\n    plt.colorbar(sm, ax=ax, label=\"Compositionality\")\n\n    # Plot 2: Cosine similarity (compound vs word2) across layers\n    ax = axes[0, 1]\n    for r in results:\n        layers = []\n        sims = []\n        for m in r[\"layer_metrics\"]:\n            if m is not None:\n                layers.append(m[\"layer\"])\n                sims.append(m[\"sim_compound_word2\"])\n        color = plt.cm.RdYlGn(r[\"compositionality\"] / 5.0)\n        ax.plot(layers, sims, alpha=0.6, color=color, linewidth=1.5)\n    ax.set_xlabel(\"Layer\")\n    ax.set_ylabel(\"Cosine Similarity\")\n    ax.set_title(\"Similarity: Compound Direction vs Word2 Direction\")\n\n    # Plot 3: Residual norm ratio across layers\n    ax = axes[1, 0]\n    for r in results:\n        layers = []\n        residuals = []\n        for m in r[\"layer_metrics\"]:\n            if m is not None:\n                layers.append(m[\"layer\"])\n                residuals.append(m[\"residual_norm_ratio\"])\n        color = plt.cm.RdYlGn(r[\"compositionality\"] / 5.0)\n        ax.plot(layers, residuals, alpha=0.6, color=color, linewidth=1.5)\n    ax.set_xlabel(\"Layer\")\n    ax.set_ylabel(\"||residual|| / ||compound||\")\n    ax.set_title(\"Unique Component (Not Explained by Constituents)\")\n\n    # Plot 4: Final layer R² vs compositionality\n    ax = axes[1, 1]\n    comps = []\n    r2_finals = []\n    labels = []\n    for r in results:\n        last = r[\"layer_metrics\"][-1]\n        if last:\n            comps.append(r[\"compositionality\"])\n            r2_finals.append(last[\"reconstruction_r2\"])\n            labels.append(r[\"compound\"])\n    ax.scatter(comps, r2_finals, s=80, c='steelblue', edgecolors='k')\n    for i, label in enumerate(labels):\n        ax.annotate(label, (comps[i], r2_finals[i]), fontsize=6,\n                   ha='left', va='bottom', rotation=15)\n    r_corr, p_val = stats.spearmanr(comps, r2_finals)\n    ax.set_xlabel(\"Compositionality Rating\")\n    ax.set_ylabel(\"Final Layer R²\")\n    ax.set_title(f\"Compositionality vs Reconstruction Quality\\n(Spearman r={r_corr:.3f}, p={p_val:.3f})\")\n\n    plt.tight_layout()\n    plt.savefig(PLOTS_DIR / \"exp2_residual_directions.png\", dpi=150, bbox_inches='tight')\n    plt.close()\n    print(f\"Saved: {PLOTS_DIR / 'exp2_residual_directions.png'}\")\n\n\n# ── Experiment 3: Layer-wise Probing ─────────────────────────────────────\n\ndef experiment3_layerwise_probing(model):\n    \"\"\"\n    Train probes to test where compound concept representations emerge.\n\n    Probe 1: At the word2 position, can we predict what word1 was?\n             (Tests token erasure: if accuracy drops, word1 info is being erased)\n    Probe 2: Can we distinguish compound vs. non-compound contexts at the word2 position?\n             (Tests whether compounds create a unique representation)\n    \"\"\"\n    print(\"\\n\" + \"=\"*70)\n    print(\"EXPERIMENT 3: Layer-wise Probing for Compound Concept Emergence\")\n    print(\"=\"*70)\n\n    n_layers = model.cfg.n_layers\n\n    # Collect data: hidden states at the word2 position\n    # Label 1: which word1 preceded (for erasure analysis)\n    # Label 2: compound (1) vs control (0) context\n\n    compound_data = []  # (hidden_states_per_layer, word1_label, compound_label=1, compound_name)\n    control_data = []   # (hidden_states_per_layer, word1_label, compound_label=0, compound_name)\n\n    word1_to_idx = {}\n    idx_counter = 0\n\n    for compound, word1, word2, comp_rating, control in tqdm(COMPOUNDS, desc=\"Collecting activations\"):\n        w1_toks = get_token_ids(model, word1)\n        w2_toks = get_token_ids(model, word2)\n        if len(w1_toks) != 1 or len(w2_toks) != 1:\n            continue\n\n        if word1 not in word1_to_idx:\n            word1_to_idx[word1] = idx_counter\n            idx_counter += 1\n        w1_idx = word1_to_idx[word1]\n\n        control_word1 = control.split()[0]\n        if control_word1 not in word1_to_idx:\n            word1_to_idx[control_word1] = idx_counter\n            idx_counter += 1\n        ctrl_w1_idx = word1_to_idx[control_word1]\n\n        # Compound contexts\n        for template in TEMPLATES:\n            sentence = template.format(compound=compound)\n            tokens = model.to_tokens(sentence)\n            with torch.no_grad():\n                _, cache = model.run_with_cache(tokens)\n\n            token_strs = [model.to_string([t]) for t in tokens[0]]\n            w2_str = f\" {word2}\"\n            w2_pos = None\n            for pos, ts in enumerate(token_strs):\n                if ts == w2_str and pos > 0 and token_strs[pos-1].strip() == word1:\n                    w2_pos = pos\n                    break\n            if w2_pos is None:\n                continue\n\n            states = {}\n            for layer in range(n_layers):\n                states[layer] = cache[f\"blocks.{layer}.hook_resid_post\"][0, w2_pos].cpu().numpy()\n            compound_data.append((states, w1_idx, 1, compound, comp_rating))\n\n        # Control contexts\n        for template in TEMPLATES:\n            sentence = template.format(compound=control)\n            tokens = model.to_tokens(sentence)\n            with torch.no_grad():\n                _, cache = model.run_with_cache(tokens)\n\n            token_strs = [model.to_string([t]) for t in tokens[0]]\n            w2_str = f\" {word2}\"\n            w2_pos = None\n            for pos, ts in enumerate(token_strs):\n                if ts == w2_str:\n                    w2_pos = pos\n                    break\n            if w2_pos is None:\n                continue\n\n            states = {}\n            for layer in range(n_layers):\n                states[layer] = cache[f\"blocks.{layer}.hook_resid_post\"][0, w2_pos].cpu().numpy()\n            control_data.append((states, ctrl_w1_idx, 0, control, comp_rating))\n\n    print(f\"\\nCollected {len(compound_data)} compound samples, {len(control_data)} control samples\")\n    print(f\"Number of unique word1 labels: {len(word1_to_idx)}\")\n\n    # ── Probe 1: Word1 identity prediction (erasure analysis) ──\n    # Only on compound data: can we tell what word1 was from the word2 position?\n    print(\"\\nProbe 1: Word1 Identity Prediction (Token Erasure)\")\n\n    probe1_results = {\"layer\": [], \"accuracy\": [], \"accuracy_std\": []}\n\n    for layer in range(n_layers):\n        X = np.array([d[0][layer] for d in compound_data])\n        y = np.array([d[1] for d in compound_data])\n\n        if len(np.unique(y)) < 2:\n            probe1_results[\"layer\"].append(layer)\n            probe1_results[\"accuracy\"].append(0)\n            probe1_results[\"accuracy_std\"].append(0)\n            continue\n\n        clf = LogisticRegression(max_iter=1000, random_state=SEED, C=1.0)\n        scores = cross_val_score(clf, X, y, cv=min(5, len(X)), scoring='accuracy')\n        probe1_results[\"layer\"].append(layer)\n        probe1_results[\"accuracy\"].append(scores.mean())\n        probe1_results[\"accuracy_std\"].append(scores.std())\n\n        print(f\"  Layer {layer:2d}: accuracy = {scores.mean():.3f} ± {scores.std():.3f}\")\n\n    # ── Probe 2: Compound vs. Control Classification ──\n    print(\"\\nProbe 2: Compound vs. Control Context Classification\")\n\n    all_data = compound_data + control_data\n    probe2_results = {\"layer\": [], \"accuracy\": [], \"accuracy_std\": []}\n\n    for layer in range(n_layers):\n        X = np.array([d[0][layer] for d in all_data])\n        y = np.array([d[2] for d in all_data])\n\n        clf = LogisticRegression(max_iter=1000, random_state=SEED, C=1.0)\n        scores = cross_val_score(clf, X, y, cv=min(5, len(X)), scoring='accuracy')\n        probe2_results[\"layer\"].append(layer)\n        probe2_results[\"accuracy\"].append(scores.mean())\n        probe2_results[\"accuracy_std\"].append(scores.std())\n\n        print(f\"  Layer {layer:2d}: accuracy = {scores.mean():.3f} ± {scores.std():.3f}\")\n\n    # ── Probe 3: Per-compositionality-level compound vs. control ──\n    print(\"\\nProbe 3: Compound vs. Control by Compositionality Level\")\n\n    comp_levels = sorted(set(r for _, _, _, _, r in compound_data))\n    probe3_results = {level: {\"layer\": [], \"accuracy\": []} for level in comp_levels}\n\n    for level in comp_levels:\n        level_compound = [d for d in compound_data if d[4] == level]\n        level_control = [d for d in control_data if d[4] == level]\n        level_data = level_compound + level_control\n\n        if len(level_data) < 10:\n            continue\n\n        for layer in range(n_layers):\n            X = np.array([d[0][layer] for d in level_data])\n            y = np.array([d[2] for d in level_data])\n\n            if len(np.unique(y)) < 2:\n                continue\n\n            clf = LogisticRegression(max_iter=1000, random_state=SEED, C=1.0)\n            cv_folds = min(3, min(np.sum(y==0), np.sum(y==1)))\n            if cv_folds < 2:\n                continue\n            scores = cross_val_score(clf, X, y, cv=cv_folds, scoring='accuracy')\n            probe3_results[level][\"layer\"].append(layer)\n            probe3_results[level][\"accuracy\"].append(scores.mean())\n\n    results = {\n        \"probe1_word1_identity\": probe1_results,\n        \"probe2_compound_vs_control\": probe2_results,\n        \"probe3_by_compositionality\": {str(k): v for k, v in probe3_results.items()},\n        \"n_compound_samples\": len(compound_data),\n        \"n_control_samples\": len(control_data),\n        \"n_word1_classes\": len(word1_to_idx),\n    }\n\n    with open(RESULTS_DIR / \"exp3_probing.json\", \"w\") as f:\n        json.dump(results, f, indent=2)\n\n    return results\n\n\ndef plot_experiment3(results):\n    \"\"\"Visualize Experiment 3 results.\"\"\"\n    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n\n    # Plot 1: Word1 identity probe accuracy across layers (erasure)\n    ax = axes[0]\n    p1 = results[\"probe1_word1_identity\"]\n    ax.errorbar(p1[\"layer\"], p1[\"accuracy\"], yerr=p1[\"accuracy_std\"],\n                marker='o', capsize=3, color='steelblue', linewidth=2)\n    chance = 1.0 / results[\"n_word1_classes\"]\n    ax.axhline(y=chance, color='red', linestyle='--', alpha=0.5, label=f'Chance ({chance:.2f})')\n    ax.set_xlabel(\"Layer\")\n    ax.set_ylabel(\"Accuracy\")\n    ax.set_title(\"Probe 1: Can We Predict Word1 from Word2 Position?\\n(Token Erasure Test)\")\n    ax.legend()\n    ax.set_ylim(0, 1.05)\n\n    # Plot 2: Compound vs control classification\n    ax = axes[1]\n    p2 = results[\"probe2_compound_vs_control\"]\n    ax.errorbar(p2[\"layer\"], p2[\"accuracy\"], yerr=p2[\"accuracy_std\"],\n                marker='s', capsize=3, color='darkorange', linewidth=2)\n    ax.axhline(y=0.5, color='red', linestyle='--', alpha=0.5, label='Chance (0.50)')\n    ax.set_xlabel(\"Layer\")\n    ax.set_ylabel(\"Accuracy\")\n    ax.set_title(\"Probe 2: Can We Distinguish Compound vs. Control Context?\")\n    ax.legend()\n    ax.set_ylim(0, 1.05)\n\n    # Plot 3: By compositionality level\n    ax = axes[2]\n    colors = {1: '#e74c3c', 2: '#e67e22', 3: '#f1c40f', 4: '#2ecc71', 5: '#27ae60'}\n    for level_str, data in results[\"probe3_by_compositionality\"].items():\n        level = int(level_str)\n        if data[\"layer\"]:\n            ax.plot(data[\"layer\"], data[\"accuracy\"],\n                   marker='o', color=colors.get(level, 'gray'),\n                   label=f'Comp={level}', linewidth=1.5, markersize=4)\n    ax.axhline(y=0.5, color='red', linestyle='--', alpha=0.5)\n    ax.set_xlabel(\"Layer\")\n    ax.set_ylabel(\"Accuracy\")\n    ax.set_title(\"Probe 3: Compound vs. Control by Compositionality\")\n    ax.legend(fontsize=8)\n    ax.set_ylim(0, 1.05)\n\n    plt.tight_layout()\n    plt.savefig(PLOTS_DIR / \"exp3_layerwise_probing.png\", dpi=150, bbox_inches='tight')\n    plt.close()\n    print(f\"Saved: {PLOTS_DIR / 'exp3_layerwise_probing.png'}\")\n\n\n# ── Experiment 4: Attention Pattern Analysis ─────────────────────────────\n\ndef experiment4_attention_patterns(model):\n    \"\"\"\n    Analyze how attention at the word2 position relates to word1.\n    If compound concepts are assembled via attention, the word2 position\n    should attend heavily to the word1 position specifically in compound contexts.\n    \"\"\"\n    print(\"\\n\" + \"=\"*70)\n    print(\"EXPERIMENT 4: Attention Pattern Analysis\")\n    print(\"=\"*70)\n\n    n_layers = model.cfg.n_layers\n    n_heads = model.cfg.n_heads\n    results = []\n\n    for compound, word1, word2, comp_rating, control in tqdm(COMPOUNDS, desc=\"Attention analysis\"):\n        w1_toks = get_token_ids(model, word1)\n        w2_toks = get_token_ids(model, word2)\n        if len(w1_toks) != 1 or len(w2_toks) != 1:\n            continue\n\n        compound_attn_to_w1 = np.zeros((n_layers, n_heads))\n        control_attn_to_w1_pos = np.zeros((n_layers, n_heads))\n        n_compound = 0\n        n_control = 0\n\n        # Compound contexts\n        for template in TEMPLATES:\n            sentence = template.format(compound=compound)\n            tokens = model.to_tokens(sentence)\n            with torch.no_grad():\n                _, cache = model.run_with_cache(tokens)\n\n            token_strs = [model.to_string([t]) for t in tokens[0]]\n            w2_str = f\" {word2}\"\n            w2_pos = None\n            w1_pos = None\n            for pos, ts in enumerate(token_strs):\n                if ts == w2_str and pos > 0 and token_strs[pos-1].strip() == word1:\n                    w2_pos = pos\n                    w1_pos = pos - 1\n                    break\n            if w2_pos is None:\n                continue\n\n            for layer in range(n_layers):\n                attn = cache[f\"blocks.{layer}.attn.hook_pattern\"][0, :, w2_pos, w1_pos]\n                compound_attn_to_w1[layer] += attn.cpu().numpy()\n            n_compound += 1\n\n        # Control contexts\n        for template in TEMPLATES:\n            sentence = template.format(compound=control)\n            tokens = model.to_tokens(sentence)\n            with torch.no_grad():\n                _, cache = model.run_with_cache(tokens)\n\n            token_strs = [model.to_string([t]) for t in tokens[0]]\n            w2_str = f\" {word2}\"\n            w2_pos = None\n            for pos, ts in enumerate(token_strs):\n                if ts == w2_str:\n                    w2_pos = pos\n                    break\n            if w2_pos is None or w2_pos < 1:\n                continue\n\n            ctrl_w1_pos = w2_pos - 1  # word just before word2 in control\n\n            for layer in range(n_layers):\n                attn = cache[f\"blocks.{layer}.attn.hook_pattern\"][0, :, w2_pos, ctrl_w1_pos]\n                control_attn_to_w1_pos[layer] += attn.cpu().numpy()\n            n_control += 1\n\n        if n_compound > 0:\n            compound_attn_to_w1 /= n_compound\n        if n_control > 0:\n            control_attn_to_w1_pos /= n_control\n\n        # Compute per-layer average attention difference\n        attn_diff = compound_attn_to_w1 - control_attn_to_w1_pos\n\n        results.append({\n            \"compound\": compound,\n            \"compositionality\": comp_rating,\n            \"compound_attn_to_word1\": compound_attn_to_w1.tolist(),\n            \"control_attn_to_prev\": control_attn_to_w1_pos.tolist(),\n            \"attn_diff_mean_per_layer\": attn_diff.mean(axis=1).tolist(),\n            \"n_compound\": n_compound,\n            \"n_control\": n_control,\n        })\n\n        mean_diff = attn_diff.mean(axis=1)\n        max_layer = np.argmax(np.abs(mean_diff))\n        print(f\"  {compound:20s} | max attn diff at layer {max_layer}: {mean_diff[max_layer]:.4f}\")\n\n    with open(RESULTS_DIR / \"exp4_attention.json\", \"w\") as f:\n        json.dump(results, f, indent=2)\n\n    return results\n\n\ndef plot_experiment4(results):\n    \"\"\"Visualize attention pattern analysis.\"\"\"\n    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n\n    # Plot 1: Attention to word1 across layers (compound vs control)\n    ax = axes[0]\n    all_compound_attn = []\n    all_control_attn = []\n    for r in results:\n        compound_mean = np.array(r[\"compound_attn_to_word1\"]).mean(axis=1)\n        control_mean = np.array(r[\"control_attn_to_prev\"]).mean(axis=1)\n        all_compound_attn.append(compound_mean)\n        all_control_attn.append(control_mean)\n\n    all_compound_attn = np.array(all_compound_attn)\n    all_control_attn = np.array(all_control_attn)\n\n    layers = range(all_compound_attn.shape[1])\n    ax.plot(layers, all_compound_attn.mean(axis=0), 'b-o', label='Compound (w2→w1)', linewidth=2)\n    ax.fill_between(layers,\n                    all_compound_attn.mean(axis=0) - all_compound_attn.std(axis=0),\n                    all_compound_attn.mean(axis=0) + all_compound_attn.std(axis=0),\n                    alpha=0.2, color='blue')\n    ax.plot(layers, all_control_attn.mean(axis=0), 'r-s', label='Control (w2→prev)', linewidth=2)\n    ax.fill_between(layers,\n                    all_control_attn.mean(axis=0) - all_control_attn.std(axis=0),\n                    all_control_attn.mean(axis=0) + all_control_attn.std(axis=0),\n                    alpha=0.2, color='red')\n    ax.set_xlabel(\"Layer\")\n    ax.set_ylabel(\"Mean Attention Weight\")\n    ax.set_title(\"Attention from Word2 to Word1/Previous Word\")\n    ax.legend()\n\n    # Plot 2: Attention difference by compositionality\n    ax = axes[1]\n    for r in results:\n        diff = r[\"attn_diff_mean_per_layer\"]\n        color = plt.cm.RdYlGn(r[\"compositionality\"] / 5.0)\n        ax.plot(range(len(diff)), diff, alpha=0.5, color=color, linewidth=1.5)\n    ax.axhline(y=0, color='k', linestyle='--', alpha=0.3)\n    ax.set_xlabel(\"Layer\")\n    ax.set_ylabel(\"Attention Difference (Compound - Control)\")\n    ax.set_title(\"Differential Attention to Preceding Word\")\n    sm = plt.cm.ScalarMappable(cmap='RdYlGn', norm=plt.Normalize(1, 5))\n    plt.colorbar(sm, ax=ax, label=\"Compositionality\")\n\n    plt.tight_layout()\n    plt.savefig(PLOTS_DIR / \"exp4_attention_patterns.png\", dpi=150, bbox_inches='tight')\n    plt.close()\n    print(f\"Saved: {PLOTS_DIR / 'exp4_attention_patterns.png'}\")\n\n\n# ── Main ─────────────────────────────────────────────────────────────────\n\ndef main():\n    print(\"=\"*70)\n    print(\"WHERE IS 'WASHING MACHINE' STORED IN LLMs?\")\n    print(\"=\"*70)\n    print(f\"\\nDevice: {DEVICE}\")\n    print(f\"Seed: {SEED}\")\n    print(f\"Number of compounds: {len(COMPOUNDS)}\")\n    print(f\"Number of templates: {len(TEMPLATES)}\")\n\n    # Log environment\n    print(f\"\\nPython: {sys.version}\")\n    print(f\"PyTorch: {torch.__version__}\")\n    print(f\"TransformerLens: {tl.__version__}\")\n    if torch.cuda.is_available():\n        print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n        print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_mem / 1e9:.1f} GB\")\n\n    # Save config\n    config = {\n        \"seed\": SEED,\n        \"model\": \"gpt2\",\n        \"n_compounds\": len(COMPOUNDS),\n        \"n_templates\": len(TEMPLATES),\n        \"device\": DEVICE,\n        \"python_version\": sys.version,\n        \"torch_version\": torch.__version__,\n    }\n    with open(RESULTS_DIR / \"config.json\", \"w\") as f:\n        json.dump(config, f, indent=2)\n\n    # Load model\n    model = load_model(\"gpt2\")\n\n    # Run experiments\n    print(\"\\n\\n\" + \"=\"*70)\n    print(\"RUNNING ALL EXPERIMENTS\")\n    print(\"=\"*70)\n\n    # Experiment 1: Next-token prediction\n    exp1_results = experiment1_next_token_prediction(model)\n    plot_experiment1(exp1_results)\n\n    # Experiment 2: Residual stream directions\n    exp2_results = experiment2_residual_directions(model)\n    plot_experiment2(exp2_results)\n\n    # Experiment 3: Layer-wise probing\n    exp3_results = experiment3_layerwise_probing(model)\n    plot_experiment3(exp3_results)\n\n    # Experiment 4: Attention patterns\n    exp4_results = experiment4_attention_patterns(model)\n    plot_experiment4(exp4_results)\n\n    print(\"\\n\\n\" + \"=\"*70)\n    print(\"ALL EXPERIMENTS COMPLETE\")\n    print(\"=\"*70)\n    print(f\"\\nResults saved to: {RESULTS_DIR}\")\n    print(f\"Plots saved to: {PLOTS_DIR}\")\n\n    return exp1_results, exp2_results, exp3_results, exp4_results\n\n\nif __name__ == \"__main__\":\n    main()\n"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":662,"cache_read_input_tokens":54717,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":662},"output_tokens":2,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"b17232d5-d541-4b73-b309-260e396a6adb"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_014zUX8a1wGu2y464HDjJE6U","type":"tool_result","content":"File created successfully at: /data/hypogenicai/workspaces/llm-washing-machine-claude/src/experiment.py"}]},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"85da5625-97bd-4e48-b637-8f46c10a9edc","tool_use_result":{"type":"create","filePath":"/data/hypogenicai/workspaces/llm-washing-machine-claude/src/experiment.py","content":"\"\"\"\nExperiment: Where is \"Washing Machine\" Stored in LLMs?\n\nThree experiments testing how compound concepts are represented:\n1. Next-token prediction analysis\n2. Residual stream direction analysis\n3. Layer-wise probing for compound concept emergence\n\nUses GPT-2 (124M) via TransformerLens for interpretability access.\n\"\"\"\n\nimport json\nimport os\nimport random\nimport sys\nfrom pathlib import Path\n\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nimport matplotlib\nmatplotlib.use('Agg')\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nfrom sklearn.linear_model import LogisticRegression, Ridge\nfrom sklearn.model_selection import cross_val_score\nfrom tqdm import tqdm\nimport transformer_lens as tl\n\n# Reproducibility\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed_all(SEED)\n\nDEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\nRESULTS_DIR = Path(\"/data/hypogenicai/workspaces/llm-washing-machine-claude/results\")\nPLOTS_DIR = RESULTS_DIR / \"plots\"\nPLOTS_DIR.mkdir(parents=True, exist_ok=True)\n\n# ── Data ──────────────────────────────────────────────────────────────────\n\n# Two-token compound nouns with compositionality ratings and control phrases\n# Each entry: (compound, word1, word2, compositionality, control_phrase)\n# Control phrases use the same word2 but a different, non-compound word1\nCOMPOUNDS = [\n    (\"washing machine\", \"washing\", \"machine\", 4, \"red machine\"),\n    (\"coffee table\", \"coffee\", \"table\", 5, \"wooden table\"),\n    (\"swimming pool\", \"swimming\", \"pool\", 4, \"deep pool\"),\n    (\"parking lot\", \"parking\", \"lot\", 4, \"empty lot\"),\n    (\"hot dog\", \"hot\", \"dog\", 1, \"big dog\"),\n    (\"shooting star\", \"shooting\", \"star\", 2, \"bright star\"),\n    (\"living room\", \"living\", \"room\", 3, \"large room\"),\n    (\"driving license\", \"driving\", \"license\", 4, \"new license\"),\n    (\"guinea pig\", \"guinea\", \"pig\", 2, \"small pig\"),\n    (\"brick house\", \"brick\", \"house\", 5, \"old house\"),\n    (\"mountain cabin\", \"mountain\", \"cabin\", 5, \"small cabin\"),\n    (\"garden hose\", \"garden\", \"hose\", 5, \"long hose\"),\n    (\"water bottle\", \"water\", \"bottle\", 5, \"glass bottle\"),\n    (\"steel bridge\", \"steel\", \"bridge\", 5, \"old bridge\"),\n    (\"chocolate cake\", \"chocolate\", \"cake\", 5, \"big cake\"),\n    (\"door handle\", \"door\", \"handle\", 5, \"metal handle\"),\n    (\"blueberry\", \"blue\", \"berry\", 4, \"small berry\"),\n    (\"snowman\", \"snow\", \"man\", 4, \"tall man\"),\n    (\"sunflower\", \"sun\", \"flower\", 4, \"red flower\"),\n]\n\n# Sentence templates for generating diverse contexts\nTEMPLATES = [\n    \"The {compound} was\",\n    \"She bought a {compound} for\",\n    \"I saw a {compound} in the\",\n    \"There is a {compound} near the\",\n    \"He fixed the {compound} with\",\n    \"A new {compound} arrived\",\n    \"The old {compound} needed\",\n    \"We need a {compound} to\",\n]\n\n# Additional contexts for word-in-isolation analysis\nISOLATION_TEMPLATES = [\n    \"The {word} was very\",\n    \"I noticed the {word} seemed\",\n    \"That {word} is quite\",\n    \"A {word} appeared in the\",\n]\n\n\ndef load_model(model_name=\"gpt2\"):\n    \"\"\"Load GPT-2 model via TransformerLens with hooks.\"\"\"\n    print(f\"Loading model: {model_name}\")\n    model = tl.HookedTransformer.from_pretrained(model_name, device=DEVICE)\n    model.eval()\n    print(f\"Model loaded: {model.cfg.n_layers} layers, d_model={model.cfg.d_model}\")\n    return model\n\n\ndef get_token_ids(model, word):\n    \"\"\"Get the token ID for a word (with leading space).\"\"\"\n    tokens = model.to_tokens(f\" {word}\", prepend_bos=False)\n    return tokens[0].tolist()\n\n\n# ── Experiment 1: Next-Token Prediction Analysis ─────────────────────────\n\ndef experiment1_next_token_prediction(model):\n    \"\"\"\n    Test whether 'washing' alone makes 'machine' more likely.\n    Compare P(word2 | word1) across compositionality levels.\n    \"\"\"\n    print(\"\\n\" + \"=\"*70)\n    print(\"EXPERIMENT 1: Next-Token Prediction Analysis\")\n    print(\"=\"*70)\n\n    results = []\n\n    for compound, word1, word2, comp_rating, control in tqdm(COMPOUNDS, desc=\"Compounds\"):\n        # Get target token id for word2\n        word2_tokens = get_token_ids(model, word2)\n        if len(word2_tokens) != 1:\n            print(f\"  Skipping {compound}: word2 '{word2}' is multi-token\")\n            continue\n        word2_id = word2_tokens[0]\n\n        # 1. P(word2 | \"The word1\")  — compound context\n        compound_probs = []\n        compound_ranks = []\n        for template in TEMPLATES:\n            prompt = template.split(\"{compound}\")[0] + word1\n            tokens = model.to_tokens(prompt)\n            with torch.no_grad():\n                logits = model(tokens)\n            last_logits = logits[0, -1]\n            probs = F.softmax(last_logits, dim=-1)\n            p_word2 = probs[word2_id].item()\n            rank = (probs > probs[word2_id]).sum().item() + 1\n            compound_probs.append(p_word2)\n            compound_ranks.append(rank)\n\n        # 2. P(word2 | \"The control_word1\") — control context\n        control_word1 = control.split()[0]\n        control_probs = []\n        control_ranks = []\n        for template in TEMPLATES:\n            prompt = template.split(\"{compound}\")[0] + control_word1\n            tokens = model.to_tokens(prompt)\n            with torch.no_grad():\n                logits = model(tokens)\n            last_logits = logits[0, -1]\n            probs = F.softmax(last_logits, dim=-1)\n            p_word2 = probs[word2_id].item()\n            rank = (probs > probs[word2_id]).sum().item() + 1\n            control_probs.append(p_word2)\n            control_ranks.append(rank)\n\n        # 3. P(word2 | unconditional) — just BOS token\n        bos_tokens = model.to_tokens(\"The\")\n        with torch.no_grad():\n            logits = model(bos_tokens)\n        last_logits = logits[0, -1]\n        probs = F.softmax(last_logits, dim=-1)\n        p_word2_uncond = probs[word2_id].item()\n        rank_uncond = (probs > probs[word2_id]).sum().item() + 1\n\n        # 4. Get top-5 predictions after word1 for interpretability\n        tokens = model.to_tokens(f\"The {word1}\")\n        with torch.no_grad():\n            logits = model(tokens)\n        last_logits = logits[0, -1]\n        probs = F.softmax(last_logits, dim=-1)\n        top5_ids = torch.topk(probs, 5).indices.tolist()\n        top5 = [(model.to_string([tid]).strip(), probs[tid].item()) for tid in top5_ids]\n\n        result = {\n            \"compound\": compound,\n            \"word1\": word1,\n            \"word2\": word2,\n            \"compositionality\": comp_rating,\n            \"p_word2_compound_mean\": np.mean(compound_probs),\n            \"p_word2_compound_std\": np.std(compound_probs),\n            \"rank_compound_mean\": np.mean(compound_ranks),\n            \"p_word2_control_mean\": np.mean(control_probs),\n            \"p_word2_control_std\": np.std(control_probs),\n            \"rank_control_mean\": np.mean(control_ranks),\n            \"p_word2_unconditional\": p_word2_uncond,\n            \"rank_unconditional\": rank_uncond,\n            \"boost_ratio\": np.mean(compound_probs) / max(np.mean(control_probs), 1e-10),\n            \"top5_after_word1\": top5,\n        }\n        results.append(result)\n\n        print(f\"  {compound:20s} | P(w2|w1)={result['p_word2_compound_mean']:.4f} \"\n              f\"rank={result['rank_compound_mean']:.0f} | \"\n              f\"P(w2|ctrl)={result['p_word2_control_mean']:.4f} \"\n              f\"rank={result['rank_control_mean']:.0f} | \"\n              f\"boost={result['boost_ratio']:.1f}x | \"\n              f\"top5: {[t[0] for t in top5]}\")\n\n    # Save results\n    with open(RESULTS_DIR / \"exp1_next_token.json\", \"w\") as f:\n        json.dump(results, f, indent=2)\n\n    return results\n\n\ndef plot_experiment1(results):\n    \"\"\"Visualize Experiment 1 results.\"\"\"\n    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n\n    compounds = [r[\"compound\"] for r in results]\n    comp_ratings = [r[\"compositionality\"] for r in results]\n    p_compound = [r[\"p_word2_compound_mean\"] for r in results]\n    p_control = [r[\"p_word2_control_mean\"] for r in results]\n    boost_ratios = [r[\"boost_ratio\"] for r in results]\n\n    # Sort by boost ratio for bar chart\n    sorted_idx = np.argsort(boost_ratios)[::-1]\n\n    # Plot 1: Boost ratio bar chart\n    ax = axes[0]\n    bars = ax.barh(range(len(compounds)),\n                   [boost_ratios[i] for i in sorted_idx],\n                   color=['#e74c3c' if comp_ratings[i] <= 2 else\n                          '#f39c12' if comp_ratings[i] == 3 else\n                          '#2ecc71' for i in sorted_idx])\n    ax.set_yticks(range(len(compounds)))\n    ax.set_yticklabels([compounds[i] for i in sorted_idx], fontsize=8)\n    ax.set_xlabel(\"Boost Ratio: P(w2|w1) / P(w2|control)\")\n    ax.set_title(\"How Much Does Word1 Boost Word2 Prediction?\")\n    ax.axvline(x=1, color='k', linestyle='--', alpha=0.5)\n    ax.invert_yaxis()\n\n    # Plot 2: Compound prob vs control prob scatter\n    ax = axes[1]\n    scatter = ax.scatter(p_control, p_compound, c=comp_ratings,\n                        cmap='RdYlGn', s=80, edgecolors='k', linewidth=0.5,\n                        vmin=1, vmax=5)\n    ax.plot([0, max(max(p_compound), max(p_control))],\n            [0, max(max(p_compound), max(p_control))],\n            'k--', alpha=0.3, label='y=x')\n    for i, c in enumerate(compounds):\n        if boost_ratios[i] > 5 or p_compound[i] > 0.05:\n            ax.annotate(c, (p_control[i], p_compound[i]),\n                       fontsize=6, ha='left', va='bottom')\n    ax.set_xlabel(\"P(word2 | control word)\")\n    ax.set_ylabel(\"P(word2 | compound word1)\")\n    ax.set_title(\"Compound vs Control Next-Token Probability\")\n    plt.colorbar(scatter, ax=ax, label=\"Compositionality Rating\")\n\n    # Plot 3: Compositionality vs boost ratio\n    ax = axes[2]\n    ax.scatter(comp_ratings, boost_ratios, s=80, c='steelblue', edgecolors='k')\n    for i, c in enumerate(compounds):\n        ax.annotate(c, (comp_ratings[i], boost_ratios[i]),\n                   fontsize=6, ha='left', va='bottom', rotation=15)\n    r, p = stats.spearmanr(comp_ratings, boost_ratios)\n    ax.set_xlabel(\"Compositionality Rating (1=idiomatic, 5=compositional)\")\n    ax.set_ylabel(\"Boost Ratio\")\n    ax.set_title(f\"Compositionality vs Prediction Boost\\n(Spearman r={r:.3f}, p={p:.3f})\")\n\n    plt.tight_layout()\n    plt.savefig(PLOTS_DIR / \"exp1_next_token_prediction.png\", dpi=150, bbox_inches='tight')\n    plt.close()\n    print(f\"Saved: {PLOTS_DIR / 'exp1_next_token_prediction.png'}\")\n\n\n# ── Experiment 2: Residual Stream Direction Analysis ─────────────────────\n\ndef experiment2_residual_directions(model):\n    \"\"\"\n    Compare directions for compound concepts vs. constituent words.\n    Test: is the compound direction a linear combination of constituent directions?\n    \"\"\"\n    print(\"\\n\" + \"=\"*70)\n    print(\"EXPERIMENT 2: Residual Stream Direction Analysis\")\n    print(\"=\"*70)\n\n    n_layers = model.cfg.n_layers\n    results = []\n\n    for compound, word1, word2, comp_rating, control in tqdm(COMPOUNDS, desc=\"Compounds\"):\n        # Verify both words are single tokens\n        w1_toks = get_token_ids(model, word1)\n        w2_toks = get_token_ids(model, word2)\n        if len(w1_toks) != 1 or len(w2_toks) != 1:\n            print(f\"  Skipping {compound}: multi-token constituent\")\n            continue\n\n        # Collect hidden states across contexts\n        compound_states = {l: [] for l in range(n_layers)}\n        word1_states = {l: [] for l in range(n_layers)}\n        word2_states = {l: [] for l in range(n_layers)}\n        control_states = {l: [] for l in range(n_layers)}\n\n        # Compound contexts: hidden state at word2 position\n        for template in TEMPLATES:\n            sentence = template.format(compound=compound)\n            tokens = model.to_tokens(sentence)\n            with torch.no_grad():\n                _, cache = model.run_with_cache(tokens)\n\n            # Find position of word2 in tokenized sentence\n            token_strs = [model.to_string([t]) for t in tokens[0]]\n            # word2 with space prefix\n            w2_str = f\" {word2}\"\n            w2_pos = None\n            for pos, ts in enumerate(token_strs):\n                if ts == w2_str:\n                    # Check that previous token is word1\n                    if pos > 0 and token_strs[pos-1].strip() == word1:\n                        w2_pos = pos\n                        break\n            if w2_pos is None:\n                continue\n\n            for layer in range(n_layers):\n                h = cache[f\"blocks.{layer}.hook_resid_post\"][0, w2_pos].cpu().numpy()\n                compound_states[layer].append(h)\n\n        # Word1 in isolation contexts\n        for template in ISOLATION_TEMPLATES:\n            sentence = template.format(word=word1)\n            tokens = model.to_tokens(sentence)\n            with torch.no_grad():\n                _, cache = model.run_with_cache(tokens)\n            token_strs = [model.to_string([t]) for t in tokens[0]]\n            w1_str = f\" {word1}\"\n            w1_pos = None\n            for pos, ts in enumerate(token_strs):\n                if ts == w1_str:\n                    w1_pos = pos\n                    break\n            if w1_pos is None:\n                continue\n            for layer in range(n_layers):\n                h = cache[f\"blocks.{layer}.hook_resid_post\"][0, w1_pos].cpu().numpy()\n                word1_states[layer].append(h)\n\n        # Word2 in isolation contexts\n        for template in ISOLATION_TEMPLATES:\n            sentence = template.format(word=word2)\n            tokens = model.to_tokens(sentence)\n            with torch.no_grad():\n                _, cache = model.run_with_cache(tokens)\n            token_strs = [model.to_string([t]) for t in tokens[0]]\n            w2_str = f\" {word2}\"\n            w2_pos = None\n            for pos, ts in enumerate(token_strs):\n                if ts == w2_str:\n                    w2_pos = pos\n                    break\n            if w2_pos is None:\n                continue\n            for layer in range(n_layers):\n                h = cache[f\"blocks.{layer}.hook_resid_post\"][0, w2_pos].cpu().numpy()\n                word2_states[layer].append(h)\n\n        # Control contexts: hidden state at word2 position in non-compound context\n        control_word1 = control.split()[0]\n        for template in TEMPLATES:\n            sentence = template.format(compound=control)\n            tokens = model.to_tokens(sentence)\n            with torch.no_grad():\n                _, cache = model.run_with_cache(tokens)\n            token_strs = [model.to_string([t]) for t in tokens[0]]\n            w2_str = f\" {word2}\"\n            w2_pos = None\n            for pos, ts in enumerate(token_strs):\n                if ts == w2_str:\n                    w2_pos = pos\n                    break\n            if w2_pos is None:\n                continue\n            for layer in range(n_layers):\n                h = cache[f\"blocks.{layer}.hook_resid_post\"][0, w2_pos].cpu().numpy()\n                control_states[layer].append(h)\n\n        # Compute metrics per layer\n        layer_metrics = []\n        for layer in range(n_layers):\n            if not compound_states[layer] or not word1_states[layer] or not word2_states[layer]:\n                layer_metrics.append(None)\n                continue\n\n            # Mean directions\n            compound_dir = np.mean(compound_states[layer], axis=0)\n            word1_dir = np.mean(word1_states[layer], axis=0)\n            word2_dir = np.mean(word2_states[layer], axis=0)\n\n            # Cosine similarities\n            def cosine_sim(a, b):\n                return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b) + 1e-10)\n\n            sim_compound_w1 = cosine_sim(compound_dir, word1_dir)\n            sim_compound_w2 = cosine_sim(compound_dir, word2_dir)\n            sim_w1_w2 = cosine_sim(word1_dir, word2_dir)\n\n            # Linear reconstruction: compound = alpha*word1 + beta*word2 + bias\n            X = np.stack([word1_dir, word2_dir], axis=0).T  # d_model x 2\n            y = compound_dir\n            # Least squares: (X^T X)^{-1} X^T y\n            try:\n                coeffs = np.linalg.lstsq(X, y, rcond=None)[0]\n                y_pred = X @ coeffs\n                ss_res = np.sum((y - y_pred) ** 2)\n                ss_tot = np.sum((y - np.mean(y)) ** 2)\n                r_squared = 1 - ss_res / ss_tot if ss_tot > 0 else 0\n            except np.linalg.LinAlgError:\n                coeffs = np.array([0, 0])\n                r_squared = 0\n\n            # Control comparison\n            if control_states[layer]:\n                control_dir = np.mean(control_states[layer], axis=0)\n                sim_control_w2 = cosine_sim(control_dir, word2_dir)\n                sim_compound_control = cosine_sim(compound_dir, control_dir)\n            else:\n                sim_control_w2 = None\n                sim_compound_control = None\n\n            # Uniqueness: residual after removing word1 and word2 components\n            residual = compound_dir - y_pred\n            residual_norm_ratio = np.linalg.norm(residual) / (np.linalg.norm(compound_dir) + 1e-10)\n\n            layer_metrics.append({\n                \"layer\": layer,\n                \"sim_compound_word1\": float(sim_compound_w1),\n                \"sim_compound_word2\": float(sim_compound_w2),\n                \"sim_word1_word2\": float(sim_w1_w2),\n                \"reconstruction_r2\": float(r_squared),\n                \"alpha_word1\": float(coeffs[0]),\n                \"beta_word2\": float(coeffs[1]),\n                \"residual_norm_ratio\": float(residual_norm_ratio),\n                \"sim_control_word2\": float(sim_control_w2) if sim_control_w2 is not None else None,\n                \"sim_compound_control\": float(sim_compound_control) if sim_compound_control is not None else None,\n            })\n\n        result = {\n            \"compound\": compound,\n            \"word1\": word1,\n            \"word2\": word2,\n            \"compositionality\": comp_rating,\n            \"n_compound_contexts\": len(compound_states[0]),\n            \"n_word1_contexts\": len(word1_states[0]),\n            \"n_word2_contexts\": len(word2_states[0]),\n            \"layer_metrics\": layer_metrics,\n        }\n        results.append(result)\n\n        # Print summary for last layer\n        last = layer_metrics[-1]\n        if last:\n            print(f\"  {compound:20s} | cos(C,w1)={last['sim_compound_word1']:.3f} \"\n                  f\"cos(C,w2)={last['sim_compound_word2']:.3f} \"\n                  f\"R²={last['reconstruction_r2']:.3f} \"\n                  f\"residual={last['residual_norm_ratio']:.3f}\")\n\n    with open(RESULTS_DIR / \"exp2_residual_directions.json\", \"w\") as f:\n        json.dump(results, f, indent=2)\n\n    return results\n\n\ndef plot_experiment2(results):\n    \"\"\"Visualize Experiment 2 results.\"\"\"\n    fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n\n    n_layers = 12  # GPT-2\n\n    # Plot 1: R² across layers (all compounds)\n    ax = axes[0, 0]\n    for r in results:\n        layers = []\n        r2_vals = []\n        for m in r[\"layer_metrics\"]:\n            if m is not None:\n                layers.append(m[\"layer\"])\n                r2_vals.append(m[\"reconstruction_r2\"])\n        color = plt.cm.RdYlGn(r[\"compositionality\"] / 5.0)\n        ax.plot(layers, r2_vals, alpha=0.6, color=color, linewidth=1.5)\n    ax.set_xlabel(\"Layer\")\n    ax.set_ylabel(\"R² (compound ≈ α·word1 + β·word2)\")\n    ax.set_title(\"Linear Reconstruction Quality Across Layers\")\n    ax.set_ylim(-0.1, 1.1)\n    # Add colorbar\n    sm = plt.cm.ScalarMappable(cmap='RdYlGn', norm=plt.Normalize(1, 5))\n    plt.colorbar(sm, ax=ax, label=\"Compositionality\")\n\n    # Plot 2: Cosine similarity (compound vs word2) across layers\n    ax = axes[0, 1]\n    for r in results:\n        layers = []\n        sims = []\n        for m in r[\"layer_metrics\"]:\n            if m is not None:\n                layers.append(m[\"layer\"])\n                sims.append(m[\"sim_compound_word2\"])\n        color = plt.cm.RdYlGn(r[\"compositionality\"] / 5.0)\n        ax.plot(layers, sims, alpha=0.6, color=color, linewidth=1.5)\n    ax.set_xlabel(\"Layer\")\n    ax.set_ylabel(\"Cosine Similarity\")\n    ax.set_title(\"Similarity: Compound Direction vs Word2 Direction\")\n\n    # Plot 3: Residual norm ratio across layers\n    ax = axes[1, 0]\n    for r in results:\n        layers = []\n        residuals = []\n        for m in r[\"layer_metrics\"]:\n            if m is not None:\n                layers.append(m[\"layer\"])\n                residuals.append(m[\"residual_norm_ratio\"])\n        color = plt.cm.RdYlGn(r[\"compositionality\"] / 5.0)\n        ax.plot(layers, residuals, alpha=0.6, color=color, linewidth=1.5)\n    ax.set_xlabel(\"Layer\")\n    ax.set_ylabel(\"||residual|| / ||compound||\")\n    ax.set_title(\"Unique Component (Not Explained by Constituents)\")\n\n    # Plot 4: Final layer R² vs compositionality\n    ax = axes[1, 1]\n    comps = []\n    r2_finals = []\n    labels = []\n    for r in results:\n        last = r[\"layer_metrics\"][-1]\n        if last:\n            comps.append(r[\"compositionality\"])\n            r2_finals.append(last[\"reconstruction_r2\"])\n            labels.append(r[\"compound\"])\n    ax.scatter(comps, r2_finals, s=80, c='steelblue', edgecolors='k')\n    for i, label in enumerate(labels):\n        ax.annotate(label, (comps[i], r2_finals[i]), fontsize=6,\n                   ha='left', va='bottom', rotation=15)\n    r_corr, p_val = stats.spearmanr(comps, r2_finals)\n    ax.set_xlabel(\"Compositionality Rating\")\n    ax.set_ylabel(\"Final Layer R²\")\n    ax.set_title(f\"Compositionality vs Reconstruction Quality\\n(Spearman r={r_corr:.3f}, p={p_val:.3f})\")\n\n    plt.tight_layout()\n    plt.savefig(PLOTS_DIR / \"exp2_residual_directions.png\", dpi=150, bbox_inches='tight')\n    plt.close()\n    print(f\"Saved: {PLOTS_DIR / 'exp2_residual_directions.png'}\")\n\n\n# ── Experiment 3: Layer-wise Probing ─────────────────────────────────────\n\ndef experiment3_layerwise_probing(model):\n    \"\"\"\n    Train probes to test where compound concept representations emerge.\n\n    Probe 1: At the word2 position, can we predict what word1 was?\n             (Tests token erasure: if accuracy drops, word1 info is being erased)\n    Probe 2: Can we distinguish compound vs. non-compound contexts at the word2 position?\n             (Tests whether compounds create a unique representation)\n    \"\"\"\n    print(\"\\n\" + \"=\"*70)\n    print(\"EXPERIMENT 3: Layer-wise Probing for Compound Concept Emergence\")\n    print(\"=\"*70)\n\n    n_layers = model.cfg.n_layers\n\n    # Collect data: hidden states at the word2 position\n    # Label 1: which word1 preceded (for erasure analysis)\n    # Label 2: compound (1) vs control (0) context\n\n    compound_data = []  # (hidden_states_per_layer, word1_label, compound_label=1, compound_name)\n    control_data = []   # (hidden_states_per_layer, word1_label, compound_label=0, compound_name)\n\n    word1_to_idx = {}\n    idx_counter = 0\n\n    for compound, word1, word2, comp_rating, control in tqdm(COMPOUNDS, desc=\"Collecting activations\"):\n        w1_toks = get_token_ids(model, word1)\n        w2_toks = get_token_ids(model, word2)\n        if len(w1_toks) != 1 or len(w2_toks) != 1:\n            continue\n\n        if word1 not in word1_to_idx:\n            word1_to_idx[word1] = idx_counter\n            idx_counter += 1\n        w1_idx = word1_to_idx[word1]\n\n        control_word1 = control.split()[0]\n        if control_word1 not in word1_to_idx:\n            word1_to_idx[control_word1] = idx_counter\n            idx_counter += 1\n        ctrl_w1_idx = word1_to_idx[control_word1]\n\n        # Compound contexts\n        for template in TEMPLATES:\n            sentence = template.format(compound=compound)\n            tokens = model.to_tokens(sentence)\n            with torch.no_grad():\n                _, cache = model.run_with_cache(tokens)\n\n            token_strs = [model.to_string([t]) for t in tokens[0]]\n            w2_str = f\" {word2}\"\n            w2_pos = None\n            for pos, ts in enumerate(token_strs):\n                if ts == w2_str and pos > 0 and token_strs[pos-1].strip() == word1:\n                    w2_pos = pos\n                    break\n            if w2_pos is None:\n                continue\n\n            states = {}\n            for layer in range(n_layers):\n                states[layer] = cache[f\"blocks.{layer}.hook_resid_post\"][0, w2_pos].cpu().numpy()\n            compound_data.append((states, w1_idx, 1, compound, comp_rating))\n\n        # Control contexts\n        for template in TEMPLATES:\n            sentence = template.format(compound=control)\n            tokens = model.to_tokens(sentence)\n            with torch.no_grad():\n                _, cache = model.run_with_cache(tokens)\n\n            token_strs = [model.to_string([t]) for t in tokens[0]]\n            w2_str = f\" {word2}\"\n            w2_pos = None\n            for pos, ts in enumerate(token_strs):\n                if ts == w2_str:\n                    w2_pos = pos\n                    break\n            if w2_pos is None:\n                continue\n\n            states = {}\n            for layer in range(n_layers):\n                states[layer] = cache[f\"blocks.{layer}.hook_resid_post\"][0, w2_pos].cpu().numpy()\n            control_data.append((states, ctrl_w1_idx, 0, control, comp_rating))\n\n    print(f\"\\nCollected {len(compound_data)} compound samples, {len(control_data)} control samples\")\n    print(f\"Number of unique word1 labels: {len(word1_to_idx)}\")\n\n    # ── Probe 1: Word1 identity prediction (erasure analysis) ──\n    # Only on compound data: can we tell what word1 was from the word2 position?\n    print(\"\\nProbe 1: Word1 Identity Prediction (Token Erasure)\")\n\n    probe1_results = {\"layer\": [], \"accuracy\": [], \"accuracy_std\": []}\n\n    for layer in range(n_layers):\n        X = np.array([d[0][layer] for d in compound_data])\n        y = np.array([d[1] for d in compound_data])\n\n        if len(np.unique(y)) < 2:\n            probe1_results[\"layer\"].append(layer)\n            probe1_results[\"accuracy\"].append(0)\n            probe1_results[\"accuracy_std\"].append(0)\n            continue\n\n        clf = LogisticRegression(max_iter=1000, random_state=SEED, C=1.0)\n        scores = cross_val_score(clf, X, y, cv=min(5, len(X)), scoring='accuracy')\n        probe1_results[\"layer\"].append(layer)\n        probe1_results[\"accuracy\"].append(scores.mean())\n        probe1_results[\"accuracy_std\"].append(scores.std())\n\n        print(f\"  Layer {layer:2d}: accuracy = {scores.mean():.3f} ± {scores.std():.3f}\")\n\n    # ── Probe 2: Compound vs. Control Classification ──\n    print(\"\\nProbe 2: Compound vs. Control Context Classification\")\n\n    all_data = compound_data + control_data\n    probe2_results = {\"layer\": [], \"accuracy\": [], \"accuracy_std\": []}\n\n    for layer in range(n_layers):\n        X = np.array([d[0][layer] for d in all_data])\n        y = np.array([d[2] for d in all_data])\n\n        clf = LogisticRegression(max_iter=1000, random_state=SEED, C=1.0)\n        scores = cross_val_score(clf, X, y, cv=min(5, len(X)), scoring='accuracy')\n        probe2_results[\"layer\"].append(layer)\n        probe2_results[\"accuracy\"].append(scores.mean())\n        probe2_results[\"accuracy_std\"].append(scores.std())\n\n        print(f\"  Layer {layer:2d}: accuracy = {scores.mean():.3f} ± {scores.std():.3f}\")\n\n    # ── Probe 3: Per-compositionality-level compound vs. control ──\n    print(\"\\nProbe 3: Compound vs. Control by Compositionality Level\")\n\n    comp_levels = sorted(set(r for _, _, _, _, r in compound_data))\n    probe3_results = {level: {\"layer\": [], \"accuracy\": []} for level in comp_levels}\n\n    for level in comp_levels:\n        level_compound = [d for d in compound_data if d[4] == level]\n        level_control = [d for d in control_data if d[4] == level]\n        level_data = level_compound + level_control\n\n        if len(level_data) < 10:\n            continue\n\n        for layer in range(n_layers):\n            X = np.array([d[0][layer] for d in level_data])\n            y = np.array([d[2] for d in level_data])\n\n            if len(np.unique(y)) < 2:\n                continue\n\n            clf = LogisticRegression(max_iter=1000, random_state=SEED, C=1.0)\n            cv_folds = min(3, min(np.sum(y==0), np.sum(y==1)))\n            if cv_folds < 2:\n                continue\n            scores = cross_val_score(clf, X, y, cv=cv_folds, scoring='accuracy')\n            probe3_results[level][\"layer\"].append(layer)\n            probe3_results[level][\"accuracy\"].append(scores.mean())\n\n    results = {\n        \"probe1_word1_identity\": probe1_results,\n        \"probe2_compound_vs_control\": probe2_results,\n        \"probe3_by_compositionality\": {str(k): v for k, v in probe3_results.items()},\n        \"n_compound_samples\": len(compound_data),\n        \"n_control_samples\": len(control_data),\n        \"n_word1_classes\": len(word1_to_idx),\n    }\n\n    with open(RESULTS_DIR / \"exp3_probing.json\", \"w\") as f:\n        json.dump(results, f, indent=2)\n\n    return results\n\n\ndef plot_experiment3(results):\n    \"\"\"Visualize Experiment 3 results.\"\"\"\n    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n\n    # Plot 1: Word1 identity probe accuracy across layers (erasure)\n    ax = axes[0]\n    p1 = results[\"probe1_word1_identity\"]\n    ax.errorbar(p1[\"layer\"], p1[\"accuracy\"], yerr=p1[\"accuracy_std\"],\n                marker='o', capsize=3, color='steelblue', linewidth=2)\n    chance = 1.0 / results[\"n_word1_classes\"]\n    ax.axhline(y=chance, color='red', linestyle='--', alpha=0.5, label=f'Chance ({chance:.2f})')\n    ax.set_xlabel(\"Layer\")\n    ax.set_ylabel(\"Accuracy\")\n    ax.set_title(\"Probe 1: Can We Predict Word1 from Word2 Position?\\n(Token Erasure Test)\")\n    ax.legend()\n    ax.set_ylim(0, 1.05)\n\n    # Plot 2: Compound vs control classification\n    ax = axes[1]\n    p2 = results[\"probe2_compound_vs_control\"]\n    ax.errorbar(p2[\"layer\"], p2[\"accuracy\"], yerr=p2[\"accuracy_std\"],\n                marker='s', capsize=3, color='darkorange', linewidth=2)\n    ax.axhline(y=0.5, color='red', linestyle='--', alpha=0.5, label='Chance (0.50)')\n    ax.set_xlabel(\"Layer\")\n    ax.set_ylabel(\"Accuracy\")\n    ax.set_title(\"Probe 2: Can We Distinguish Compound vs. Control Context?\")\n    ax.legend()\n    ax.set_ylim(0, 1.05)\n\n    # Plot 3: By compositionality level\n    ax = axes[2]\n    colors = {1: '#e74c3c', 2: '#e67e22', 3: '#f1c40f', 4: '#2ecc71', 5: '#27ae60'}\n    for level_str, data in results[\"probe3_by_compositionality\"].items():\n        level = int(level_str)\n        if data[\"layer\"]:\n            ax.plot(data[\"layer\"], data[\"accuracy\"],\n                   marker='o', color=colors.get(level, 'gray'),\n                   label=f'Comp={level}', linewidth=1.5, markersize=4)\n    ax.axhline(y=0.5, color='red', linestyle='--', alpha=0.5)\n    ax.set_xlabel(\"Layer\")\n    ax.set_ylabel(\"Accuracy\")\n    ax.set_title(\"Probe 3: Compound vs. Control by Compositionality\")\n    ax.legend(fontsize=8)\n    ax.set_ylim(0, 1.05)\n\n    plt.tight_layout()\n    plt.savefig(PLOTS_DIR / \"exp3_layerwise_probing.png\", dpi=150, bbox_inches='tight')\n    plt.close()\n    print(f\"Saved: {PLOTS_DIR / 'exp3_layerwise_probing.png'}\")\n\n\n# ── Experiment 4: Attention Pattern Analysis ─────────────────────────────\n\ndef experiment4_attention_patterns(model):\n    \"\"\"\n    Analyze how attention at the word2 position relates to word1.\n    If compound concepts are assembled via attention, the word2 position\n    should attend heavily to the word1 position specifically in compound contexts.\n    \"\"\"\n    print(\"\\n\" + \"=\"*70)\n    print(\"EXPERIMENT 4: Attention Pattern Analysis\")\n    print(\"=\"*70)\n\n    n_layers = model.cfg.n_layers\n    n_heads = model.cfg.n_heads\n    results = []\n\n    for compound, word1, word2, comp_rating, control in tqdm(COMPOUNDS, desc=\"Attention analysis\"):\n        w1_toks = get_token_ids(model, word1)\n        w2_toks = get_token_ids(model, word2)\n        if len(w1_toks) != 1 or len(w2_toks) != 1:\n            continue\n\n        compound_attn_to_w1 = np.zeros((n_layers, n_heads))\n        control_attn_to_w1_pos = np.zeros((n_layers, n_heads))\n        n_compound = 0\n        n_control = 0\n\n        # Compound contexts\n        for template in TEMPLATES:\n            sentence = template.format(compound=compound)\n            tokens = model.to_tokens(sentence)\n            with torch.no_grad():\n                _, cache = model.run_with_cache(tokens)\n\n            token_strs = [model.to_string([t]) for t in tokens[0]]\n            w2_str = f\" {word2}\"\n            w2_pos = None\n            w1_pos = None\n            for pos, ts in enumerate(token_strs):\n                if ts == w2_str and pos > 0 and token_strs[pos-1].strip() == word1:\n                    w2_pos = pos\n                    w1_pos = pos - 1\n                    break\n            if w2_pos is None:\n                continue\n\n            for layer in range(n_layers):\n                attn = cache[f\"blocks.{layer}.attn.hook_pattern\"][0, :, w2_pos, w1_pos]\n                compound_attn_to_w1[layer] += attn.cpu().numpy()\n            n_compound += 1\n\n        # Control contexts\n        for template in TEMPLATES:\n            sentence = template.format(compound=control)\n            tokens = model.to_tokens(sentence)\n            with torch.no_grad():\n                _, cache = model.run_with_cache(tokens)\n\n            token_strs = [model.to_string([t]) for t in tokens[0]]\n            w2_str = f\" {word2}\"\n            w2_pos = None\n            for pos, ts in enumerate(token_strs):\n                if ts == w2_str:\n                    w2_pos = pos\n                    break\n            if w2_pos is None or w2_pos < 1:\n                continue\n\n            ctrl_w1_pos = w2_pos - 1  # word just before word2 in control\n\n            for layer in range(n_layers):\n                attn = cache[f\"blocks.{layer}.attn.hook_pattern\"][0, :, w2_pos, ctrl_w1_pos]\n                control_attn_to_w1_pos[layer] += attn.cpu().numpy()\n            n_control += 1\n\n        if n_compound > 0:\n            compound_attn_to_w1 /= n_compound\n        if n_control > 0:\n            control_attn_to_w1_pos /= n_control\n\n        # Compute per-layer average attention difference\n        attn_diff = compound_attn_to_w1 - control_attn_to_w1_pos\n\n        results.append({\n            \"compound\": compound,\n            \"compositionality\": comp_rating,\n            \"compound_attn_to_word1\": compound_attn_to_w1.tolist(),\n            \"control_attn_to_prev\": control_attn_to_w1_pos.tolist(),\n            \"attn_diff_mean_per_layer\": attn_diff.mean(axis=1).tolist(),\n            \"n_compound\": n_compound,\n            \"n_control\": n_control,\n        })\n\n        mean_diff = attn_diff.mean(axis=1)\n        max_layer = np.argmax(np.abs(mean_diff))\n        print(f\"  {compound:20s} | max attn diff at layer {max_layer}: {mean_diff[max_layer]:.4f}\")\n\n    with open(RESULTS_DIR / \"exp4_attention.json\", \"w\") as f:\n        json.dump(results, f, indent=2)\n\n    return results\n\n\ndef plot_experiment4(results):\n    \"\"\"Visualize attention pattern analysis.\"\"\"\n    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n\n    # Plot 1: Attention to word1 across layers (compound vs control)\n    ax = axes[0]\n    all_compound_attn = []\n    all_control_attn = []\n    for r in results:\n        compound_mean = np.array(r[\"compound_attn_to_word1\"]).mean(axis=1)\n        control_mean = np.array(r[\"control_attn_to_prev\"]).mean(axis=1)\n        all_compound_attn.append(compound_mean)\n        all_control_attn.append(control_mean)\n\n    all_compound_attn = np.array(all_compound_attn)\n    all_control_attn = np.array(all_control_attn)\n\n    layers = range(all_compound_attn.shape[1])\n    ax.plot(layers, all_compound_attn.mean(axis=0), 'b-o', label='Compound (w2→w1)', linewidth=2)\n    ax.fill_between(layers,\n                    all_compound_attn.mean(axis=0) - all_compound_attn.std(axis=0),\n                    all_compound_attn.mean(axis=0) + all_compound_attn.std(axis=0),\n                    alpha=0.2, color='blue')\n    ax.plot(layers, all_control_attn.mean(axis=0), 'r-s', label='Control (w2→prev)', linewidth=2)\n    ax.fill_between(layers,\n                    all_control_attn.mean(axis=0) - all_control_attn.std(axis=0),\n                    all_control_attn.mean(axis=0) + all_control_attn.std(axis=0),\n                    alpha=0.2, color='red')\n    ax.set_xlabel(\"Layer\")\n    ax.set_ylabel(\"Mean Attention Weight\")\n    ax.set_title(\"Attention from Word2 to Word1/Previous Word\")\n    ax.legend()\n\n    # Plot 2: Attention difference by compositionality\n    ax = axes[1]\n    for r in results:\n        diff = r[\"attn_diff_mean_per_layer\"]\n        color = plt.cm.RdYlGn(r[\"compositionality\"] / 5.0)\n        ax.plot(range(len(diff)), diff, alpha=0.5, color=color, linewidth=1.5)\n    ax.axhline(y=0, color='k', linestyle='--', alpha=0.3)\n    ax.set_xlabel(\"Layer\")\n    ax.set_ylabel(\"Attention Difference (Compound - Control)\")\n    ax.set_title(\"Differential Attention to Preceding Word\")\n    sm = plt.cm.ScalarMappable(cmap='RdYlGn', norm=plt.Normalize(1, 5))\n    plt.colorbar(sm, ax=ax, label=\"Compositionality\")\n\n    plt.tight_layout()\n    plt.savefig(PLOTS_DIR / \"exp4_attention_patterns.png\", dpi=150, bbox_inches='tight')\n    plt.close()\n    print(f\"Saved: {PLOTS_DIR / 'exp4_attention_patterns.png'}\")\n\n\n# ── Main ─────────────────────────────────────────────────────────────────\n\ndef main():\n    print(\"=\"*70)\n    print(\"WHERE IS 'WASHING MACHINE' STORED IN LLMs?\")\n    print(\"=\"*70)\n    print(f\"\\nDevice: {DEVICE}\")\n    print(f\"Seed: {SEED}\")\n    print(f\"Number of compounds: {len(COMPOUNDS)}\")\n    print(f\"Number of templates: {len(TEMPLATES)}\")\n\n    # Log environment\n    print(f\"\\nPython: {sys.version}\")\n    print(f\"PyTorch: {torch.__version__}\")\n    print(f\"TransformerLens: {tl.__version__}\")\n    if torch.cuda.is_available():\n        print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n        print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_mem / 1e9:.1f} GB\")\n\n    # Save config\n    config = {\n        \"seed\": SEED,\n        \"model\": \"gpt2\",\n        \"n_compounds\": len(COMPOUNDS),\n        \"n_templates\": len(TEMPLATES),\n        \"device\": DEVICE,\n        \"python_version\": sys.version,\n        \"torch_version\": torch.__version__,\n    }\n    with open(RESULTS_DIR / \"config.json\", \"w\") as f:\n        json.dump(config, f, indent=2)\n\n    # Load model\n    model = load_model(\"gpt2\")\n\n    # Run experiments\n    print(\"\\n\\n\" + \"=\"*70)\n    print(\"RUNNING ALL EXPERIMENTS\")\n    print(\"=\"*70)\n\n    # Experiment 1: Next-token prediction\n    exp1_results = experiment1_next_token_prediction(model)\n    plot_experiment1(exp1_results)\n\n    # Experiment 2: Residual stream directions\n    exp2_results = experiment2_residual_directions(model)\n    plot_experiment2(exp2_results)\n\n    # Experiment 3: Layer-wise probing\n    exp3_results = experiment3_layerwise_probing(model)\n    plot_experiment3(exp3_results)\n\n    # Experiment 4: Attention patterns\n    exp4_results = experiment4_attention_patterns(model)\n    plot_experiment4(exp4_results)\n\n    print(\"\\n\\n\" + \"=\"*70)\n    print(\"ALL EXPERIMENTS COMPLETE\")\n    print(\"=\"*70)\n    print(f\"\\nResults saved to: {RESULTS_DIR}\")\n    print(f\"Plots saved to: {PLOTS_DIR}\")\n\n    return exp1_results, exp2_results, exp3_results, exp4_results\n\n\nif __name__ == \"__main__\":\n    main()\n","structuredPatch":[],"originalFile":null}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_013whNMTR6eQa1oE3RN8JyDH","type":"message","role":"assistant","content":[{"type":"text","text":"Now let me run the experiments."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":13014,"cache_read_input_tokens":55379,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":13014},"output_tokens":3,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"4645bde5-244e-4cdd-8350-7b82e3c8a42a"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_013whNMTR6eQa1oE3RN8JyDH","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01KpfruuY8hhYsDLjd2aUDXT","name":"TodoWrite","input":{"todos":[{"content":"Review pre-gathered resources (literature_review.md, resources.md, papers/, datasets/, code/)","status":"completed","activeForm":"Reviewing pre-gathered resources"},{"content":"Phase 0 & 1: Motivation, novelty assessment, and research plan (planning.md)","status":"completed","activeForm":"Writing motivation assessment and research plan"},{"content":"Phase 2: Environment & data setup","status":"completed","activeForm":"Setting up environment and data"},{"content":"Phase 3: Implementation - write experiment code","status":"completed","activeForm":"Implementing experiment code"},{"content":"Phase 4: Run experiments","status":"in_progress","activeForm":"Running experiments"},{"content":"Phase 5: Analysis - statistical analysis and visualizations","status":"pending","activeForm":"Analyzing results"},{"content":"Phase 6: Final documentation (REPORT.md, README.md)","status":"pending","activeForm":"Writing final documentation"}]}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":13014,"cache_read_input_tokens":55379,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":13014},"output_tokens":3,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"e938def2-fd5b-4514-b89b-4b4bbe3d1e9d"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01KpfruuY8hhYsDLjd2aUDXT","type":"tool_result","content":"Todos have been modified successfully. Ensure that you continue to use the todo list to track your progress. Please proceed with the current tasks if applicable"}]},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"6d0e357f-fb43-4b59-b5d3-f518d1452523","tool_use_result":{"oldTodos":[{"content":"Review pre-gathered resources (literature_review.md, resources.md, papers/, datasets/, code/)","status":"completed","activeForm":"Reviewing pre-gathered resources"},{"content":"Phase 0 & 1: Motivation, novelty assessment, and research plan (planning.md)","status":"completed","activeForm":"Writing motivation assessment and research plan"},{"content":"Phase 2: Environment & data setup","status":"completed","activeForm":"Setting up environment and data"},{"content":"Phase 3: Implementation - write experiment code","status":"in_progress","activeForm":"Implementing experiment code"},{"content":"Phase 4: Run experiments","status":"pending","activeForm":"Running experiments"},{"content":"Phase 5: Analysis - statistical analysis and visualizations","status":"pending","activeForm":"Analyzing results"},{"content":"Phase 6: Final documentation (REPORT.md, README.md)","status":"pending","activeForm":"Writing final documentation"}],"newTodos":[{"content":"Review pre-gathered resources (literature_review.md, resources.md, papers/, datasets/, code/)","status":"completed","activeForm":"Reviewing pre-gathered resources"},{"content":"Phase 0 & 1: Motivation, novelty assessment, and research plan (planning.md)","status":"completed","activeForm":"Writing motivation assessment and research plan"},{"content":"Phase 2: Environment & data setup","status":"completed","activeForm":"Setting up environment and data"},{"content":"Phase 3: Implementation - write experiment code","status":"completed","activeForm":"Implementing experiment code"},{"content":"Phase 4: Run experiments","status":"in_progress","activeForm":"Running experiments"},{"content":"Phase 5: Analysis - statistical analysis and visualizations","status":"pending","activeForm":"Analyzing results"},{"content":"Phase 6: Final documentation (REPORT.md, README.md)","status":"pending","activeForm":"Writing final documentation"}]}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01TZjwEGZjtPZHUgDXhUiWyN","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01NXiV9AkkQM8Xvw3ck5aoAf","name":"Bash","input":{"command":"source .venv/bin/activate && CUDA_VISIBLE_DEVICES=0 python src/experiment.py 2>&1","description":"Run all experiments (GPT-2 on GPU)","timeout":600000}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":352,"cache_read_input_tokens":68393,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":352},"output_tokens":26,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"bc1473b5-a2b2-43af-8f76-1f3678e5671e"}
{"type":"user","message":{"role":"user","content":[{"type":"tool_result","content":"Exit code 1\n======================================================================\nWHERE IS 'WASHING MACHINE' STORED IN LLMs?\n======================================================================\n\nDevice: cuda:0\nSeed: 42\nNumber of compounds: 19\nNumber of templates: 8\n\nPython: 3.12.2 | packaged by Anaconda, Inc. | (main, Feb 27 2024, 17:35:02) [GCC 11.2.0]\nPyTorch: 2.10.0+cu128\nTraceback (most recent call last):\n  File \"/data/hypogenicai/workspaces/llm-washing-machine-claude/src/experiment.py\", line 996, in <module>\n    main()\n  File \"/data/hypogenicai/workspaces/llm-washing-machine-claude/src/experiment.py\", line 944, in main\n    print(f\"TransformerLens: {tl.__version__}\")\n                              ^^^^^^^^^^^^^^\nAttributeError: module 'transformer_lens' has no attribute '__version__'","is_error":true,"tool_use_id":"toolu_01NXiV9AkkQM8Xvw3ck5aoAf"}]},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"64cf468d-d26c-4e80-9a51-bcf4c7404a0b","tool_use_result":"Error: Exit code 1\n======================================================================\nWHERE IS 'WASHING MACHINE' STORED IN LLMs?\n======================================================================\n\nDevice: cuda:0\nSeed: 42\nNumber of compounds: 19\nNumber of templates: 8\n\nPython: 3.12.2 | packaged by Anaconda, Inc. | (main, Feb 27 2024, 17:35:02) [GCC 11.2.0]\nPyTorch: 2.10.0+cu128\nTraceback (most recent call last):\n  File \"/data/hypogenicai/workspaces/llm-washing-machine-claude/src/experiment.py\", line 996, in <module>\n    main()\n  File \"/data/hypogenicai/workspaces/llm-washing-machine-claude/src/experiment.py\", line 944, in main\n    print(f\"TransformerLens: {tl.__version__}\")\n                              ^^^^^^^^^^^^^^\nAttributeError: module 'transformer_lens' has no attribute '__version__'"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01CfJ4x57yuiJG2ReM1iP8GT","type":"message","role":"assistant","content":[{"type":"text","text":"Small issue. Let me fix and rerun."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":393,"cache_read_input_tokens":68745,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":393},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"6138174e-7a54-4a3a-9857-28f95618607e"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01CfJ4x57yuiJG2ReM1iP8GT","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01BQXA4iJ9G5gA1oRWbaRt9R","name":"Edit","input":{"replace_all":false,"file_path":"/data/hypogenicai/workspaces/llm-washing-machine-claude/src/experiment.py","old_string":"    print(f\"TransformerLens: {tl.__version__}\")","new_string":"    print(f\"TransformerLens: {getattr(tl, '__version__', 'unknown')}\")"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":393,"cache_read_input_tokens":68745,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":393},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"a11d142c-8ae4-4230-8185-78470371e28e"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01BQXA4iJ9G5gA1oRWbaRt9R","type":"tool_result","content":"The file /data/hypogenicai/workspaces/llm-washing-machine-claude/src/experiment.py has been updated successfully."}]},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"e7a51c63-92db-4be9-94c1-5f325e391704","tool_use_result":{"filePath":"/data/hypogenicai/workspaces/llm-washing-machine-claude/src/experiment.py","oldString":"    print(f\"TransformerLens: {tl.__version__}\")","newString":"    print(f\"TransformerLens: {getattr(tl, '__version__', 'unknown')}\")","originalFile":"\"\"\"\nExperiment: Where is \"Washing Machine\" Stored in LLMs?\n\nThree experiments testing how compound concepts are represented:\n1. Next-token prediction analysis\n2. Residual stream direction analysis\n3. Layer-wise probing for compound concept emergence\n\nUses GPT-2 (124M) via TransformerLens for interpretability access.\n\"\"\"\n\nimport json\nimport os\nimport random\nimport sys\nfrom pathlib import Path\n\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nimport matplotlib\nmatplotlib.use('Agg')\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nfrom sklearn.linear_model import LogisticRegression, Ridge\nfrom sklearn.model_selection import cross_val_score\nfrom tqdm import tqdm\nimport transformer_lens as tl\n\n# Reproducibility\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed_all(SEED)\n\nDEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\nRESULTS_DIR = Path(\"/data/hypogenicai/workspaces/llm-washing-machine-claude/results\")\nPLOTS_DIR = RESULTS_DIR / \"plots\"\nPLOTS_DIR.mkdir(parents=True, exist_ok=True)\n\n# ── Data ──────────────────────────────────────────────────────────────────\n\n# Two-token compound nouns with compositionality ratings and control phrases\n# Each entry: (compound, word1, word2, compositionality, control_phrase)\n# Control phrases use the same word2 but a different, non-compound word1\nCOMPOUNDS = [\n    (\"washing machine\", \"washing\", \"machine\", 4, \"red machine\"),\n    (\"coffee table\", \"coffee\", \"table\", 5, \"wooden table\"),\n    (\"swimming pool\", \"swimming\", \"pool\", 4, \"deep pool\"),\n    (\"parking lot\", \"parking\", \"lot\", 4, \"empty lot\"),\n    (\"hot dog\", \"hot\", \"dog\", 1, \"big dog\"),\n    (\"shooting star\", \"shooting\", \"star\", 2, \"bright star\"),\n    (\"living room\", \"living\", \"room\", 3, \"large room\"),\n    (\"driving license\", \"driving\", \"license\", 4, \"new license\"),\n    (\"guinea pig\", \"guinea\", \"pig\", 2, \"small pig\"),\n    (\"brick house\", \"brick\", \"house\", 5, \"old house\"),\n    (\"mountain cabin\", \"mountain\", \"cabin\", 5, \"small cabin\"),\n    (\"garden hose\", \"garden\", \"hose\", 5, \"long hose\"),\n    (\"water bottle\", \"water\", \"bottle\", 5, \"glass bottle\"),\n    (\"steel bridge\", \"steel\", \"bridge\", 5, \"old bridge\"),\n    (\"chocolate cake\", \"chocolate\", \"cake\", 5, \"big cake\"),\n    (\"door handle\", \"door\", \"handle\", 5, \"metal handle\"),\n    (\"blueberry\", \"blue\", \"berry\", 4, \"small berry\"),\n    (\"snowman\", \"snow\", \"man\", 4, \"tall man\"),\n    (\"sunflower\", \"sun\", \"flower\", 4, \"red flower\"),\n]\n\n# Sentence templates for generating diverse contexts\nTEMPLATES = [\n    \"The {compound} was\",\n    \"She bought a {compound} for\",\n    \"I saw a {compound} in the\",\n    \"There is a {compound} near the\",\n    \"He fixed the {compound} with\",\n    \"A new {compound} arrived\",\n    \"The old {compound} needed\",\n    \"We need a {compound} to\",\n]\n\n# Additional contexts for word-in-isolation analysis\nISOLATION_TEMPLATES = [\n    \"The {word} was very\",\n    \"I noticed the {word} seemed\",\n    \"That {word} is quite\",\n    \"A {word} appeared in the\",\n]\n\n\ndef load_model(model_name=\"gpt2\"):\n    \"\"\"Load GPT-2 model via TransformerLens with hooks.\"\"\"\n    print(f\"Loading model: {model_name}\")\n    model = tl.HookedTransformer.from_pretrained(model_name, device=DEVICE)\n    model.eval()\n    print(f\"Model loaded: {model.cfg.n_layers} layers, d_model={model.cfg.d_model}\")\n    return model\n\n\ndef get_token_ids(model, word):\n    \"\"\"Get the token ID for a word (with leading space).\"\"\"\n    tokens = model.to_tokens(f\" {word}\", prepend_bos=False)\n    return tokens[0].tolist()\n\n\n# ── Experiment 1: Next-Token Prediction Analysis ─────────────────────────\n\ndef experiment1_next_token_prediction(model):\n    \"\"\"\n    Test whether 'washing' alone makes 'machine' more likely.\n    Compare P(word2 | word1) across compositionality levels.\n    \"\"\"\n    print(\"\\n\" + \"=\"*70)\n    print(\"EXPERIMENT 1: Next-Token Prediction Analysis\")\n    print(\"=\"*70)\n\n    results = []\n\n    for compound, word1, word2, comp_rating, control in tqdm(COMPOUNDS, desc=\"Compounds\"):\n        # Get target token id for word2\n        word2_tokens = get_token_ids(model, word2)\n        if len(word2_tokens) != 1:\n            print(f\"  Skipping {compound}: word2 '{word2}' is multi-token\")\n            continue\n        word2_id = word2_tokens[0]\n\n        # 1. P(word2 | \"The word1\")  — compound context\n        compound_probs = []\n        compound_ranks = []\n        for template in TEMPLATES:\n            prompt = template.split(\"{compound}\")[0] + word1\n            tokens = model.to_tokens(prompt)\n            with torch.no_grad():\n                logits = model(tokens)\n            last_logits = logits[0, -1]\n            probs = F.softmax(last_logits, dim=-1)\n            p_word2 = probs[word2_id].item()\n            rank = (probs > probs[word2_id]).sum().item() + 1\n            compound_probs.append(p_word2)\n            compound_ranks.append(rank)\n\n        # 2. P(word2 | \"The control_word1\") — control context\n        control_word1 = control.split()[0]\n        control_probs = []\n        control_ranks = []\n        for template in TEMPLATES:\n            prompt = template.split(\"{compound}\")[0] + control_word1\n            tokens = model.to_tokens(prompt)\n            with torch.no_grad():\n                logits = model(tokens)\n            last_logits = logits[0, -1]\n            probs = F.softmax(last_logits, dim=-1)\n            p_word2 = probs[word2_id].item()\n            rank = (probs > probs[word2_id]).sum().item() + 1\n            control_probs.append(p_word2)\n            control_ranks.append(rank)\n\n        # 3. P(word2 | unconditional) — just BOS token\n        bos_tokens = model.to_tokens(\"The\")\n        with torch.no_grad():\n            logits = model(bos_tokens)\n        last_logits = logits[0, -1]\n        probs = F.softmax(last_logits, dim=-1)\n        p_word2_uncond = probs[word2_id].item()\n        rank_uncond = (probs > probs[word2_id]).sum().item() + 1\n\n        # 4. Get top-5 predictions after word1 for interpretability\n        tokens = model.to_tokens(f\"The {word1}\")\n        with torch.no_grad():\n            logits = model(tokens)\n        last_logits = logits[0, -1]\n        probs = F.softmax(last_logits, dim=-1)\n        top5_ids = torch.topk(probs, 5).indices.tolist()\n        top5 = [(model.to_string([tid]).strip(), probs[tid].item()) for tid in top5_ids]\n\n        result = {\n            \"compound\": compound,\n            \"word1\": word1,\n            \"word2\": word2,\n            \"compositionality\": comp_rating,\n            \"p_word2_compound_mean\": np.mean(compound_probs),\n            \"p_word2_compound_std\": np.std(compound_probs),\n            \"rank_compound_mean\": np.mean(compound_ranks),\n            \"p_word2_control_mean\": np.mean(control_probs),\n            \"p_word2_control_std\": np.std(control_probs),\n            \"rank_control_mean\": np.mean(control_ranks),\n            \"p_word2_unconditional\": p_word2_uncond,\n            \"rank_unconditional\": rank_uncond,\n            \"boost_ratio\": np.mean(compound_probs) / max(np.mean(control_probs), 1e-10),\n            \"top5_after_word1\": top5,\n        }\n        results.append(result)\n\n        print(f\"  {compound:20s} | P(w2|w1)={result['p_word2_compound_mean']:.4f} \"\n              f\"rank={result['rank_compound_mean']:.0f} | \"\n              f\"P(w2|ctrl)={result['p_word2_control_mean']:.4f} \"\n              f\"rank={result['rank_control_mean']:.0f} | \"\n              f\"boost={result['boost_ratio']:.1f}x | \"\n              f\"top5: {[t[0] for t in top5]}\")\n\n    # Save results\n    with open(RESULTS_DIR / \"exp1_next_token.json\", \"w\") as f:\n        json.dump(results, f, indent=2)\n\n    return results\n\n\ndef plot_experiment1(results):\n    \"\"\"Visualize Experiment 1 results.\"\"\"\n    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n\n    compounds = [r[\"compound\"] for r in results]\n    comp_ratings = [r[\"compositionality\"] for r in results]\n    p_compound = [r[\"p_word2_compound_mean\"] for r in results]\n    p_control = [r[\"p_word2_control_mean\"] for r in results]\n    boost_ratios = [r[\"boost_ratio\"] for r in results]\n\n    # Sort by boost ratio for bar chart\n    sorted_idx = np.argsort(boost_ratios)[::-1]\n\n    # Plot 1: Boost ratio bar chart\n    ax = axes[0]\n    bars = ax.barh(range(len(compounds)),\n                   [boost_ratios[i] for i in sorted_idx],\n                   color=['#e74c3c' if comp_ratings[i] <= 2 else\n                          '#f39c12' if comp_ratings[i] == 3 else\n                          '#2ecc71' for i in sorted_idx])\n    ax.set_yticks(range(len(compounds)))\n    ax.set_yticklabels([compounds[i] for i in sorted_idx], fontsize=8)\n    ax.set_xlabel(\"Boost Ratio: P(w2|w1) / P(w2|control)\")\n    ax.set_title(\"How Much Does Word1 Boost Word2 Prediction?\")\n    ax.axvline(x=1, color='k', linestyle='--', alpha=0.5)\n    ax.invert_yaxis()\n\n    # Plot 2: Compound prob vs control prob scatter\n    ax = axes[1]\n    scatter = ax.scatter(p_control, p_compound, c=comp_ratings,\n                        cmap='RdYlGn', s=80, edgecolors='k', linewidth=0.5,\n                        vmin=1, vmax=5)\n    ax.plot([0, max(max(p_compound), max(p_control))],\n            [0, max(max(p_compound), max(p_control))],\n            'k--', alpha=0.3, label='y=x')\n    for i, c in enumerate(compounds):\n        if boost_ratios[i] > 5 or p_compound[i] > 0.05:\n            ax.annotate(c, (p_control[i], p_compound[i]),\n                       fontsize=6, ha='left', va='bottom')\n    ax.set_xlabel(\"P(word2 | control word)\")\n    ax.set_ylabel(\"P(word2 | compound word1)\")\n    ax.set_title(\"Compound vs Control Next-Token Probability\")\n    plt.colorbar(scatter, ax=ax, label=\"Compositionality Rating\")\n\n    # Plot 3: Compositionality vs boost ratio\n    ax = axes[2]\n    ax.scatter(comp_ratings, boost_ratios, s=80, c='steelblue', edgecolors='k')\n    for i, c in enumerate(compounds):\n        ax.annotate(c, (comp_ratings[i], boost_ratios[i]),\n                   fontsize=6, ha='left', va='bottom', rotation=15)\n    r, p = stats.spearmanr(comp_ratings, boost_ratios)\n    ax.set_xlabel(\"Compositionality Rating (1=idiomatic, 5=compositional)\")\n    ax.set_ylabel(\"Boost Ratio\")\n    ax.set_title(f\"Compositionality vs Prediction Boost\\n(Spearman r={r:.3f}, p={p:.3f})\")\n\n    plt.tight_layout()\n    plt.savefig(PLOTS_DIR / \"exp1_next_token_prediction.png\", dpi=150, bbox_inches='tight')\n    plt.close()\n    print(f\"Saved: {PLOTS_DIR / 'exp1_next_token_prediction.png'}\")\n\n\n# ── Experiment 2: Residual Stream Direction Analysis ─────────────────────\n\ndef experiment2_residual_directions(model):\n    \"\"\"\n    Compare directions for compound concepts vs. constituent words.\n    Test: is the compound direction a linear combination of constituent directions?\n    \"\"\"\n    print(\"\\n\" + \"=\"*70)\n    print(\"EXPERIMENT 2: Residual Stream Direction Analysis\")\n    print(\"=\"*70)\n\n    n_layers = model.cfg.n_layers\n    results = []\n\n    for compound, word1, word2, comp_rating, control in tqdm(COMPOUNDS, desc=\"Compounds\"):\n        # Verify both words are single tokens\n        w1_toks = get_token_ids(model, word1)\n        w2_toks = get_token_ids(model, word2)\n        if len(w1_toks) != 1 or len(w2_toks) != 1:\n            print(f\"  Skipping {compound}: multi-token constituent\")\n            continue\n\n        # Collect hidden states across contexts\n        compound_states = {l: [] for l in range(n_layers)}\n        word1_states = {l: [] for l in range(n_layers)}\n        word2_states = {l: [] for l in range(n_layers)}\n        control_states = {l: [] for l in range(n_layers)}\n\n        # Compound contexts: hidden state at word2 position\n        for template in TEMPLATES:\n            sentence = template.format(compound=compound)\n            tokens = model.to_tokens(sentence)\n            with torch.no_grad():\n                _, cache = model.run_with_cache(tokens)\n\n            # Find position of word2 in tokenized sentence\n            token_strs = [model.to_string([t]) for t in tokens[0]]\n            # word2 with space prefix\n            w2_str = f\" {word2}\"\n            w2_pos = None\n            for pos, ts in enumerate(token_strs):\n                if ts == w2_str:\n                    # Check that previous token is word1\n                    if pos > 0 and token_strs[pos-1].strip() == word1:\n                        w2_pos = pos\n                        break\n            if w2_pos is None:\n                continue\n\n            for layer in range(n_layers):\n                h = cache[f\"blocks.{layer}.hook_resid_post\"][0, w2_pos].cpu().numpy()\n                compound_states[layer].append(h)\n\n        # Word1 in isolation contexts\n        for template in ISOLATION_TEMPLATES:\n            sentence = template.format(word=word1)\n            tokens = model.to_tokens(sentence)\n            with torch.no_grad():\n                _, cache = model.run_with_cache(tokens)\n            token_strs = [model.to_string([t]) for t in tokens[0]]\n            w1_str = f\" {word1}\"\n            w1_pos = None\n            for pos, ts in enumerate(token_strs):\n                if ts == w1_str:\n                    w1_pos = pos\n                    break\n            if w1_pos is None:\n                continue\n            for layer in range(n_layers):\n                h = cache[f\"blocks.{layer}.hook_resid_post\"][0, w1_pos].cpu().numpy()\n                word1_states[layer].append(h)\n\n        # Word2 in isolation contexts\n        for template in ISOLATION_TEMPLATES:\n            sentence = template.format(word=word2)\n            tokens = model.to_tokens(sentence)\n            with torch.no_grad():\n                _, cache = model.run_with_cache(tokens)\n            token_strs = [model.to_string([t]) for t in tokens[0]]\n            w2_str = f\" {word2}\"\n            w2_pos = None\n            for pos, ts in enumerate(token_strs):\n                if ts == w2_str:\n                    w2_pos = pos\n                    break\n            if w2_pos is None:\n                continue\n            for layer in range(n_layers):\n                h = cache[f\"blocks.{layer}.hook_resid_post\"][0, w2_pos].cpu().numpy()\n                word2_states[layer].append(h)\n\n        # Control contexts: hidden state at word2 position in non-compound context\n        control_word1 = control.split()[0]\n        for template in TEMPLATES:\n            sentence = template.format(compound=control)\n            tokens = model.to_tokens(sentence)\n            with torch.no_grad():\n                _, cache = model.run_with_cache(tokens)\n            token_strs = [model.to_string([t]) for t in tokens[0]]\n            w2_str = f\" {word2}\"\n            w2_pos = None\n            for pos, ts in enumerate(token_strs):\n                if ts == w2_str:\n                    w2_pos = pos\n                    break\n            if w2_pos is None:\n                continue\n            for layer in range(n_layers):\n                h = cache[f\"blocks.{layer}.hook_resid_post\"][0, w2_pos].cpu().numpy()\n                control_states[layer].append(h)\n\n        # Compute metrics per layer\n        layer_metrics = []\n        for layer in range(n_layers):\n            if not compound_states[layer] or not word1_states[layer] or not word2_states[layer]:\n                layer_metrics.append(None)\n                continue\n\n            # Mean directions\n            compound_dir = np.mean(compound_states[layer], axis=0)\n            word1_dir = np.mean(word1_states[layer], axis=0)\n            word2_dir = np.mean(word2_states[layer], axis=0)\n\n            # Cosine similarities\n            def cosine_sim(a, b):\n                return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b) + 1e-10)\n\n            sim_compound_w1 = cosine_sim(compound_dir, word1_dir)\n            sim_compound_w2 = cosine_sim(compound_dir, word2_dir)\n            sim_w1_w2 = cosine_sim(word1_dir, word2_dir)\n\n            # Linear reconstruction: compound = alpha*word1 + beta*word2 + bias\n            X = np.stack([word1_dir, word2_dir], axis=0).T  # d_model x 2\n            y = compound_dir\n            # Least squares: (X^T X)^{-1} X^T y\n            try:\n                coeffs = np.linalg.lstsq(X, y, rcond=None)[0]\n                y_pred = X @ coeffs\n                ss_res = np.sum((y - y_pred) ** 2)\n                ss_tot = np.sum((y - np.mean(y)) ** 2)\n                r_squared = 1 - ss_res / ss_tot if ss_tot > 0 else 0\n            except np.linalg.LinAlgError:\n                coeffs = np.array([0, 0])\n                r_squared = 0\n\n            # Control comparison\n            if control_states[layer]:\n                control_dir = np.mean(control_states[layer], axis=0)\n                sim_control_w2 = cosine_sim(control_dir, word2_dir)\n                sim_compound_control = cosine_sim(compound_dir, control_dir)\n            else:\n                sim_control_w2 = None\n                sim_compound_control = None\n\n            # Uniqueness: residual after removing word1 and word2 components\n            residual = compound_dir - y_pred\n            residual_norm_ratio = np.linalg.norm(residual) / (np.linalg.norm(compound_dir) + 1e-10)\n\n            layer_metrics.append({\n                \"layer\": layer,\n                \"sim_compound_word1\": float(sim_compound_w1),\n                \"sim_compound_word2\": float(sim_compound_w2),\n                \"sim_word1_word2\": float(sim_w1_w2),\n                \"reconstruction_r2\": float(r_squared),\n                \"alpha_word1\": float(coeffs[0]),\n                \"beta_word2\": float(coeffs[1]),\n                \"residual_norm_ratio\": float(residual_norm_ratio),\n                \"sim_control_word2\": float(sim_control_w2) if sim_control_w2 is not None else None,\n                \"sim_compound_control\": float(sim_compound_control) if sim_compound_control is not None else None,\n            })\n\n        result = {\n            \"compound\": compound,\n            \"word1\": word1,\n            \"word2\": word2,\n            \"compositionality\": comp_rating,\n            \"n_compound_contexts\": len(compound_states[0]),\n            \"n_word1_contexts\": len(word1_states[0]),\n            \"n_word2_contexts\": len(word2_states[0]),\n            \"layer_metrics\": layer_metrics,\n        }\n        results.append(result)\n\n        # Print summary for last layer\n        last = layer_metrics[-1]\n        if last:\n            print(f\"  {compound:20s} | cos(C,w1)={last['sim_compound_word1']:.3f} \"\n                  f\"cos(C,w2)={last['sim_compound_word2']:.3f} \"\n                  f\"R²={last['reconstruction_r2']:.3f} \"\n                  f\"residual={last['residual_norm_ratio']:.3f}\")\n\n    with open(RESULTS_DIR / \"exp2_residual_directions.json\", \"w\") as f:\n        json.dump(results, f, indent=2)\n\n    return results\n\n\ndef plot_experiment2(results):\n    \"\"\"Visualize Experiment 2 results.\"\"\"\n    fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n\n    n_layers = 12  # GPT-2\n\n    # Plot 1: R² across layers (all compounds)\n    ax = axes[0, 0]\n    for r in results:\n        layers = []\n        r2_vals = []\n        for m in r[\"layer_metrics\"]:\n            if m is not None:\n                layers.append(m[\"layer\"])\n                r2_vals.append(m[\"reconstruction_r2\"])\n        color = plt.cm.RdYlGn(r[\"compositionality\"] / 5.0)\n        ax.plot(layers, r2_vals, alpha=0.6, color=color, linewidth=1.5)\n    ax.set_xlabel(\"Layer\")\n    ax.set_ylabel(\"R² (compound ≈ α·word1 + β·word2)\")\n    ax.set_title(\"Linear Reconstruction Quality Across Layers\")\n    ax.set_ylim(-0.1, 1.1)\n    # Add colorbar\n    sm = plt.cm.ScalarMappable(cmap='RdYlGn', norm=plt.Normalize(1, 5))\n    plt.colorbar(sm, ax=ax, label=\"Compositionality\")\n\n    # Plot 2: Cosine similarity (compound vs word2) across layers\n    ax = axes[0, 1]\n    for r in results:\n        layers = []\n        sims = []\n        for m in r[\"layer_metrics\"]:\n            if m is not None:\n                layers.append(m[\"layer\"])\n                sims.append(m[\"sim_compound_word2\"])\n        color = plt.cm.RdYlGn(r[\"compositionality\"] / 5.0)\n        ax.plot(layers, sims, alpha=0.6, color=color, linewidth=1.5)\n    ax.set_xlabel(\"Layer\")\n    ax.set_ylabel(\"Cosine Similarity\")\n    ax.set_title(\"Similarity: Compound Direction vs Word2 Direction\")\n\n    # Plot 3: Residual norm ratio across layers\n    ax = axes[1, 0]\n    for r in results:\n        layers = []\n        residuals = []\n        for m in r[\"layer_metrics\"]:\n            if m is not None:\n                layers.append(m[\"layer\"])\n                residuals.append(m[\"residual_norm_ratio\"])\n        color = plt.cm.RdYlGn(r[\"compositionality\"] / 5.0)\n        ax.plot(layers, residuals, alpha=0.6, color=color, linewidth=1.5)\n    ax.set_xlabel(\"Layer\")\n    ax.set_ylabel(\"||residual|| / ||compound||\")\n    ax.set_title(\"Unique Component (Not Explained by Constituents)\")\n\n    # Plot 4: Final layer R² vs compositionality\n    ax = axes[1, 1]\n    comps = []\n    r2_finals = []\n    labels = []\n    for r in results:\n        last = r[\"layer_metrics\"][-1]\n        if last:\n            comps.append(r[\"compositionality\"])\n            r2_finals.append(last[\"reconstruction_r2\"])\n            labels.append(r[\"compound\"])\n    ax.scatter(comps, r2_finals, s=80, c='steelblue', edgecolors='k')\n    for i, label in enumerate(labels):\n        ax.annotate(label, (comps[i], r2_finals[i]), fontsize=6,\n                   ha='left', va='bottom', rotation=15)\n    r_corr, p_val = stats.spearmanr(comps, r2_finals)\n    ax.set_xlabel(\"Compositionality Rating\")\n    ax.set_ylabel(\"Final Layer R²\")\n    ax.set_title(f\"Compositionality vs Reconstruction Quality\\n(Spearman r={r_corr:.3f}, p={p_val:.3f})\")\n\n    plt.tight_layout()\n    plt.savefig(PLOTS_DIR / \"exp2_residual_directions.png\", dpi=150, bbox_inches='tight')\n    plt.close()\n    print(f\"Saved: {PLOTS_DIR / 'exp2_residual_directions.png'}\")\n\n\n# ── Experiment 3: Layer-wise Probing ─────────────────────────────────────\n\ndef experiment3_layerwise_probing(model):\n    \"\"\"\n    Train probes to test where compound concept representations emerge.\n\n    Probe 1: At the word2 position, can we predict what word1 was?\n             (Tests token erasure: if accuracy drops, word1 info is being erased)\n    Probe 2: Can we distinguish compound vs. non-compound contexts at the word2 position?\n             (Tests whether compounds create a unique representation)\n    \"\"\"\n    print(\"\\n\" + \"=\"*70)\n    print(\"EXPERIMENT 3: Layer-wise Probing for Compound Concept Emergence\")\n    print(\"=\"*70)\n\n    n_layers = model.cfg.n_layers\n\n    # Collect data: hidden states at the word2 position\n    # Label 1: which word1 preceded (for erasure analysis)\n    # Label 2: compound (1) vs control (0) context\n\n    compound_data = []  # (hidden_states_per_layer, word1_label, compound_label=1, compound_name)\n    control_data = []   # (hidden_states_per_layer, word1_label, compound_label=0, compound_name)\n\n    word1_to_idx = {}\n    idx_counter = 0\n\n    for compound, word1, word2, comp_rating, control in tqdm(COMPOUNDS, desc=\"Collecting activations\"):\n        w1_toks = get_token_ids(model, word1)\n        w2_toks = get_token_ids(model, word2)\n        if len(w1_toks) != 1 or len(w2_toks) != 1:\n            continue\n\n        if word1 not in word1_to_idx:\n            word1_to_idx[word1] = idx_counter\n            idx_counter += 1\n        w1_idx = word1_to_idx[word1]\n\n        control_word1 = control.split()[0]\n        if control_word1 not in word1_to_idx:\n            word1_to_idx[control_word1] = idx_counter\n            idx_counter += 1\n        ctrl_w1_idx = word1_to_idx[control_word1]\n\n        # Compound contexts\n        for template in TEMPLATES:\n            sentence = template.format(compound=compound)\n            tokens = model.to_tokens(sentence)\n            with torch.no_grad():\n                _, cache = model.run_with_cache(tokens)\n\n            token_strs = [model.to_string([t]) for t in tokens[0]]\n            w2_str = f\" {word2}\"\n            w2_pos = None\n            for pos, ts in enumerate(token_strs):\n                if ts == w2_str and pos > 0 and token_strs[pos-1].strip() == word1:\n                    w2_pos = pos\n                    break\n            if w2_pos is None:\n                continue\n\n            states = {}\n            for layer in range(n_layers):\n                states[layer] = cache[f\"blocks.{layer}.hook_resid_post\"][0, w2_pos].cpu().numpy()\n            compound_data.append((states, w1_idx, 1, compound, comp_rating))\n\n        # Control contexts\n        for template in TEMPLATES:\n            sentence = template.format(compound=control)\n            tokens = model.to_tokens(sentence)\n            with torch.no_grad():\n                _, cache = model.run_with_cache(tokens)\n\n            token_strs = [model.to_string([t]) for t in tokens[0]]\n            w2_str = f\" {word2}\"\n            w2_pos = None\n            for pos, ts in enumerate(token_strs):\n                if ts == w2_str:\n                    w2_pos = pos\n                    break\n            if w2_pos is None:\n                continue\n\n            states = {}\n            for layer in range(n_layers):\n                states[layer] = cache[f\"blocks.{layer}.hook_resid_post\"][0, w2_pos].cpu().numpy()\n            control_data.append((states, ctrl_w1_idx, 0, control, comp_rating))\n\n    print(f\"\\nCollected {len(compound_data)} compound samples, {len(control_data)} control samples\")\n    print(f\"Number of unique word1 labels: {len(word1_to_idx)}\")\n\n    # ── Probe 1: Word1 identity prediction (erasure analysis) ──\n    # Only on compound data: can we tell what word1 was from the word2 position?\n    print(\"\\nProbe 1: Word1 Identity Prediction (Token Erasure)\")\n\n    probe1_results = {\"layer\": [], \"accuracy\": [], \"accuracy_std\": []}\n\n    for layer in range(n_layers):\n        X = np.array([d[0][layer] for d in compound_data])\n        y = np.array([d[1] for d in compound_data])\n\n        if len(np.unique(y)) < 2:\n            probe1_results[\"layer\"].append(layer)\n            probe1_results[\"accuracy\"].append(0)\n            probe1_results[\"accuracy_std\"].append(0)\n            continue\n\n        clf = LogisticRegression(max_iter=1000, random_state=SEED, C=1.0)\n        scores = cross_val_score(clf, X, y, cv=min(5, len(X)), scoring='accuracy')\n        probe1_results[\"layer\"].append(layer)\n        probe1_results[\"accuracy\"].append(scores.mean())\n        probe1_results[\"accuracy_std\"].append(scores.std())\n\n        print(f\"  Layer {layer:2d}: accuracy = {scores.mean():.3f} ± {scores.std():.3f}\")\n\n    # ── Probe 2: Compound vs. Control Classification ──\n    print(\"\\nProbe 2: Compound vs. Control Context Classification\")\n\n    all_data = compound_data + control_data\n    probe2_results = {\"layer\": [], \"accuracy\": [], \"accuracy_std\": []}\n\n    for layer in range(n_layers):\n        X = np.array([d[0][layer] for d in all_data])\n        y = np.array([d[2] for d in all_data])\n\n        clf = LogisticRegression(max_iter=1000, random_state=SEED, C=1.0)\n        scores = cross_val_score(clf, X, y, cv=min(5, len(X)), scoring='accuracy')\n        probe2_results[\"layer\"].append(layer)\n        probe2_results[\"accuracy\"].append(scores.mean())\n        probe2_results[\"accuracy_std\"].append(scores.std())\n\n        print(f\"  Layer {layer:2d}: accuracy = {scores.mean():.3f} ± {scores.std():.3f}\")\n\n    # ── Probe 3: Per-compositionality-level compound vs. control ──\n    print(\"\\nProbe 3: Compound vs. Control by Compositionality Level\")\n\n    comp_levels = sorted(set(r for _, _, _, _, r in compound_data))\n    probe3_results = {level: {\"layer\": [], \"accuracy\": []} for level in comp_levels}\n\n    for level in comp_levels:\n        level_compound = [d for d in compound_data if d[4] == level]\n        level_control = [d for d in control_data if d[4] == level]\n        level_data = level_compound + level_control\n\n        if len(level_data) < 10:\n            continue\n\n        for layer in range(n_layers):\n            X = np.array([d[0][layer] for d in level_data])\n            y = np.array([d[2] for d in level_data])\n\n            if len(np.unique(y)) < 2:\n                continue\n\n            clf = LogisticRegression(max_iter=1000, random_state=SEED, C=1.0)\n            cv_folds = min(3, min(np.sum(y==0), np.sum(y==1)))\n            if cv_folds < 2:\n                continue\n            scores = cross_val_score(clf, X, y, cv=cv_folds, scoring='accuracy')\n            probe3_results[level][\"layer\"].append(layer)\n            probe3_results[level][\"accuracy\"].append(scores.mean())\n\n    results = {\n        \"probe1_word1_identity\": probe1_results,\n        \"probe2_compound_vs_control\": probe2_results,\n        \"probe3_by_compositionality\": {str(k): v for k, v in probe3_results.items()},\n        \"n_compound_samples\": len(compound_data),\n        \"n_control_samples\": len(control_data),\n        \"n_word1_classes\": len(word1_to_idx),\n    }\n\n    with open(RESULTS_DIR / \"exp3_probing.json\", \"w\") as f:\n        json.dump(results, f, indent=2)\n\n    return results\n\n\ndef plot_experiment3(results):\n    \"\"\"Visualize Experiment 3 results.\"\"\"\n    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n\n    # Plot 1: Word1 identity probe accuracy across layers (erasure)\n    ax = axes[0]\n    p1 = results[\"probe1_word1_identity\"]\n    ax.errorbar(p1[\"layer\"], p1[\"accuracy\"], yerr=p1[\"accuracy_std\"],\n                marker='o', capsize=3, color='steelblue', linewidth=2)\n    chance = 1.0 / results[\"n_word1_classes\"]\n    ax.axhline(y=chance, color='red', linestyle='--', alpha=0.5, label=f'Chance ({chance:.2f})')\n    ax.set_xlabel(\"Layer\")\n    ax.set_ylabel(\"Accuracy\")\n    ax.set_title(\"Probe 1: Can We Predict Word1 from Word2 Position?\\n(Token Erasure Test)\")\n    ax.legend()\n    ax.set_ylim(0, 1.05)\n\n    # Plot 2: Compound vs control classification\n    ax = axes[1]\n    p2 = results[\"probe2_compound_vs_control\"]\n    ax.errorbar(p2[\"layer\"], p2[\"accuracy\"], yerr=p2[\"accuracy_std\"],\n                marker='s', capsize=3, color='darkorange', linewidth=2)\n    ax.axhline(y=0.5, color='red', linestyle='--', alpha=0.5, label='Chance (0.50)')\n    ax.set_xlabel(\"Layer\")\n    ax.set_ylabel(\"Accuracy\")\n    ax.set_title(\"Probe 2: Can We Distinguish Compound vs. Control Context?\")\n    ax.legend()\n    ax.set_ylim(0, 1.05)\n\n    # Plot 3: By compositionality level\n    ax = axes[2]\n    colors = {1: '#e74c3c', 2: '#e67e22', 3: '#f1c40f', 4: '#2ecc71', 5: '#27ae60'}\n    for level_str, data in results[\"probe3_by_compositionality\"].items():\n        level = int(level_str)\n        if data[\"layer\"]:\n            ax.plot(data[\"layer\"], data[\"accuracy\"],\n                   marker='o', color=colors.get(level, 'gray'),\n                   label=f'Comp={level}', linewidth=1.5, markersize=4)\n    ax.axhline(y=0.5, color='red', linestyle='--', alpha=0.5)\n    ax.set_xlabel(\"Layer\")\n    ax.set_ylabel(\"Accuracy\")\n    ax.set_title(\"Probe 3: Compound vs. Control by Compositionality\")\n    ax.legend(fontsize=8)\n    ax.set_ylim(0, 1.05)\n\n    plt.tight_layout()\n    plt.savefig(PLOTS_DIR / \"exp3_layerwise_probing.png\", dpi=150, bbox_inches='tight')\n    plt.close()\n    print(f\"Saved: {PLOTS_DIR / 'exp3_layerwise_probing.png'}\")\n\n\n# ── Experiment 4: Attention Pattern Analysis ─────────────────────────────\n\ndef experiment4_attention_patterns(model):\n    \"\"\"\n    Analyze how attention at the word2 position relates to word1.\n    If compound concepts are assembled via attention, the word2 position\n    should attend heavily to the word1 position specifically in compound contexts.\n    \"\"\"\n    print(\"\\n\" + \"=\"*70)\n    print(\"EXPERIMENT 4: Attention Pattern Analysis\")\n    print(\"=\"*70)\n\n    n_layers = model.cfg.n_layers\n    n_heads = model.cfg.n_heads\n    results = []\n\n    for compound, word1, word2, comp_rating, control in tqdm(COMPOUNDS, desc=\"Attention analysis\"):\n        w1_toks = get_token_ids(model, word1)\n        w2_toks = get_token_ids(model, word2)\n        if len(w1_toks) != 1 or len(w2_toks) != 1:\n            continue\n\n        compound_attn_to_w1 = np.zeros((n_layers, n_heads))\n        control_attn_to_w1_pos = np.zeros((n_layers, n_heads))\n        n_compound = 0\n        n_control = 0\n\n        # Compound contexts\n        for template in TEMPLATES:\n            sentence = template.format(compound=compound)\n            tokens = model.to_tokens(sentence)\n            with torch.no_grad():\n                _, cache = model.run_with_cache(tokens)\n\n            token_strs = [model.to_string([t]) for t in tokens[0]]\n            w2_str = f\" {word2}\"\n            w2_pos = None\n            w1_pos = None\n            for pos, ts in enumerate(token_strs):\n                if ts == w2_str and pos > 0 and token_strs[pos-1].strip() == word1:\n                    w2_pos = pos\n                    w1_pos = pos - 1\n                    break\n            if w2_pos is None:\n                continue\n\n            for layer in range(n_layers):\n                attn = cache[f\"blocks.{layer}.attn.hook_pattern\"][0, :, w2_pos, w1_pos]\n                compound_attn_to_w1[layer] += attn.cpu().numpy()\n            n_compound += 1\n\n        # Control contexts\n        for template in TEMPLATES:\n            sentence = template.format(compound=control)\n            tokens = model.to_tokens(sentence)\n            with torch.no_grad():\n                _, cache = model.run_with_cache(tokens)\n\n            token_strs = [model.to_string([t]) for t in tokens[0]]\n            w2_str = f\" {word2}\"\n            w2_pos = None\n            for pos, ts in enumerate(token_strs):\n                if ts == w2_str:\n                    w2_pos = pos\n                    break\n            if w2_pos is None or w2_pos < 1:\n                continue\n\n            ctrl_w1_pos = w2_pos - 1  # word just before word2 in control\n\n            for layer in range(n_layers):\n                attn = cache[f\"blocks.{layer}.attn.hook_pattern\"][0, :, w2_pos, ctrl_w1_pos]\n                control_attn_to_w1_pos[layer] += attn.cpu().numpy()\n            n_control += 1\n\n        if n_compound > 0:\n            compound_attn_to_w1 /= n_compound\n        if n_control > 0:\n            control_attn_to_w1_pos /= n_control\n\n        # Compute per-layer average attention difference\n        attn_diff = compound_attn_to_w1 - control_attn_to_w1_pos\n\n        results.append({\n            \"compound\": compound,\n            \"compositionality\": comp_rating,\n            \"compound_attn_to_word1\": compound_attn_to_w1.tolist(),\n            \"control_attn_to_prev\": control_attn_to_w1_pos.tolist(),\n            \"attn_diff_mean_per_layer\": attn_diff.mean(axis=1).tolist(),\n            \"n_compound\": n_compound,\n            \"n_control\": n_control,\n        })\n\n        mean_diff = attn_diff.mean(axis=1)\n        max_layer = np.argmax(np.abs(mean_diff))\n        print(f\"  {compound:20s} | max attn diff at layer {max_layer}: {mean_diff[max_layer]:.4f}\")\n\n    with open(RESULTS_DIR / \"exp4_attention.json\", \"w\") as f:\n        json.dump(results, f, indent=2)\n\n    return results\n\n\ndef plot_experiment4(results):\n    \"\"\"Visualize attention pattern analysis.\"\"\"\n    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n\n    # Plot 1: Attention to word1 across layers (compound vs control)\n    ax = axes[0]\n    all_compound_attn = []\n    all_control_attn = []\n    for r in results:\n        compound_mean = np.array(r[\"compound_attn_to_word1\"]).mean(axis=1)\n        control_mean = np.array(r[\"control_attn_to_prev\"]).mean(axis=1)\n        all_compound_attn.append(compound_mean)\n        all_control_attn.append(control_mean)\n\n    all_compound_attn = np.array(all_compound_attn)\n    all_control_attn = np.array(all_control_attn)\n\n    layers = range(all_compound_attn.shape[1])\n    ax.plot(layers, all_compound_attn.mean(axis=0), 'b-o', label='Compound (w2→w1)', linewidth=2)\n    ax.fill_between(layers,\n                    all_compound_attn.mean(axis=0) - all_compound_attn.std(axis=0),\n                    all_compound_attn.mean(axis=0) + all_compound_attn.std(axis=0),\n                    alpha=0.2, color='blue')\n    ax.plot(layers, all_control_attn.mean(axis=0), 'r-s', label='Control (w2→prev)', linewidth=2)\n    ax.fill_between(layers,\n                    all_control_attn.mean(axis=0) - all_control_attn.std(axis=0),\n                    all_control_attn.mean(axis=0) + all_control_attn.std(axis=0),\n                    alpha=0.2, color='red')\n    ax.set_xlabel(\"Layer\")\n    ax.set_ylabel(\"Mean Attention Weight\")\n    ax.set_title(\"Attention from Word2 to Word1/Previous Word\")\n    ax.legend()\n\n    # Plot 2: Attention difference by compositionality\n    ax = axes[1]\n    for r in results:\n        diff = r[\"attn_diff_mean_per_layer\"]\n        color = plt.cm.RdYlGn(r[\"compositionality\"] / 5.0)\n        ax.plot(range(len(diff)), diff, alpha=0.5, color=color, linewidth=1.5)\n    ax.axhline(y=0, color='k', linestyle='--', alpha=0.3)\n    ax.set_xlabel(\"Layer\")\n    ax.set_ylabel(\"Attention Difference (Compound - Control)\")\n    ax.set_title(\"Differential Attention to Preceding Word\")\n    sm = plt.cm.ScalarMappable(cmap='RdYlGn', norm=plt.Normalize(1, 5))\n    plt.colorbar(sm, ax=ax, label=\"Compositionality\")\n\n    plt.tight_layout()\n    plt.savefig(PLOTS_DIR / \"exp4_attention_patterns.png\", dpi=150, bbox_inches='tight')\n    plt.close()\n    print(f\"Saved: {PLOTS_DIR / 'exp4_attention_patterns.png'}\")\n\n\n# ── Main ─────────────────────────────────────────────────────────────────\n\ndef main():\n    print(\"=\"*70)\n    print(\"WHERE IS 'WASHING MACHINE' STORED IN LLMs?\")\n    print(\"=\"*70)\n    print(f\"\\nDevice: {DEVICE}\")\n    print(f\"Seed: {SEED}\")\n    print(f\"Number of compounds: {len(COMPOUNDS)}\")\n    print(f\"Number of templates: {len(TEMPLATES)}\")\n\n    # Log environment\n    print(f\"\\nPython: {sys.version}\")\n    print(f\"PyTorch: {torch.__version__}\")\n    print(f\"TransformerLens: {tl.__version__}\")\n    if torch.cuda.is_available():\n        print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n        print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_mem / 1e9:.1f} GB\")\n\n    # Save config\n    config = {\n        \"seed\": SEED,\n        \"model\": \"gpt2\",\n        \"n_compounds\": len(COMPOUNDS),\n        \"n_templates\": len(TEMPLATES),\n        \"device\": DEVICE,\n        \"python_version\": sys.version,\n        \"torch_version\": torch.__version__,\n    }\n    with open(RESULTS_DIR / \"config.json\", \"w\") as f:\n        json.dump(config, f, indent=2)\n\n    # Load model\n    model = load_model(\"gpt2\")\n\n    # Run experiments\n    print(\"\\n\\n\" + \"=\"*70)\n    print(\"RUNNING ALL EXPERIMENTS\")\n    print(\"=\"*70)\n\n    # Experiment 1: Next-token prediction\n    exp1_results = experiment1_next_token_prediction(model)\n    plot_experiment1(exp1_results)\n\n    # Experiment 2: Residual stream directions\n    exp2_results = experiment2_residual_directions(model)\n    plot_experiment2(exp2_results)\n\n    # Experiment 3: Layer-wise probing\n    exp3_results = experiment3_layerwise_probing(model)\n    plot_experiment3(exp3_results)\n\n    # Experiment 4: Attention patterns\n    exp4_results = experiment4_attention_patterns(model)\n    plot_experiment4(exp4_results)\n\n    print(\"\\n\\n\" + \"=\"*70)\n    print(\"ALL EXPERIMENTS COMPLETE\")\n    print(\"=\"*70)\n    print(f\"\\nResults saved to: {RESULTS_DIR}\")\n    print(f\"Plots saved to: {PLOTS_DIR}\")\n\n    return exp1_results, exp2_results, exp3_results, exp4_results\n\n\nif __name__ == \"__main__\":\n    main()\n","structuredPatch":[{"oldStart":941,"oldLines":7,"newStart":941,"newLines":7,"lines":["     # Log environment","     print(f\"\\nPython: {sys.version}\")","     print(f\"PyTorch: {torch.__version__}\")","-    print(f\"TransformerLens: {tl.__version__}\")","+    print(f\"TransformerLens: {getattr(tl, '__version__', 'unknown')}\")","     if torch.cuda.is_available():","         print(f\"GPU: {torch.cuda.get_device_name(0)}\")","         print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_mem / 1e9:.1f} GB\")"]}],"userModified":false,"replaceAll":false}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01YT67GnorMZBDfYMRK4Fghg","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01KeifPAUaan5nqU2bvbTKG1","name":"Bash","input":{"command":"source .venv/bin/activate && CUDA_VISIBLE_DEVICES=0 python src/experiment.py 2>&1","description":"Run all experiments (GPT-2 on GPU)","timeout":600000}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":233,"cache_read_input_tokens":69138,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":233},"output_tokens":19,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"29298085-1f95-4a05-8e60-24fc7f7dd63e"}
{"type":"user","message":{"role":"user","content":[{"type":"tool_result","content":"Exit code 1\n======================================================================\nWHERE IS 'WASHING MACHINE' STORED IN LLMs?\n======================================================================\n\nDevice: cuda:0\nSeed: 42\nNumber of compounds: 19\nNumber of templates: 8\n\nPython: 3.12.2 | packaged by Anaconda, Inc. | (main, Feb 27 2024, 17:35:02) [GCC 11.2.0]\nPyTorch: 2.10.0+cu128\nTransformerLens: unknown\nGPU: NVIDIA GeForce RTX 3090\nTraceback (most recent call last):\n  File \"/data/hypogenicai/workspaces/llm-washing-machine-claude/src/experiment.py\", line 996, in <module>\n    main()\n  File \"/data/hypogenicai/workspaces/llm-washing-machine-claude/src/experiment.py\", line 947, in main\n    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_mem / 1e9:.1f} GB\")\n                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'total_mem'. Did you mean: 'total_memory'?","is_error":true,"tool_use_id":"toolu_01KeifPAUaan5nqU2bvbTKG1"}]},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"2fff0e81-72ba-4c08-aaf0-c66f3d4c3bf9","tool_use_result":"Error: Exit code 1\n======================================================================\nWHERE IS 'WASHING MACHINE' STORED IN LLMs?\n======================================================================\n\nDevice: cuda:0\nSeed: 42\nNumber of compounds: 19\nNumber of templates: 8\n\nPython: 3.12.2 | packaged by Anaconda, Inc. | (main, Feb 27 2024, 17:35:02) [GCC 11.2.0]\nPyTorch: 2.10.0+cu128\nTransformerLens: unknown\nGPU: NVIDIA GeForce RTX 3090\nTraceback (most recent call last):\n  File \"/data/hypogenicai/workspaces/llm-washing-machine-claude/src/experiment.py\", line 996, in <module>\n    main()\n  File \"/data/hypogenicai/workspaces/llm-washing-machine-claude/src/experiment.py\", line 947, in main\n    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_mem / 1e9:.1f} GB\")\n                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'total_mem'. Did you mean: 'total_memory'?"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01LvkiRaTNqdtpdXo7zK6Dij","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01N7Wzstg8j1bw3owhJYCoRt","name":"Edit","input":{"replace_all":false,"file_path":"/data/hypogenicai/workspaces/llm-washing-machine-claude/src/experiment.py","old_string":"print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_mem / 1e9:.1f} GB\")","new_string":"print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":455,"cache_read_input_tokens":69371,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":455},"output_tokens":24,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"a99e3cac-29ef-46e5-8da9-2d2985c970bc"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01N7Wzstg8j1bw3owhJYCoRt","type":"tool_result","content":"The file /data/hypogenicai/workspaces/llm-washing-machine-claude/src/experiment.py has been updated successfully."}]},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"a2546e56-d854-41d0-a222-43b1b8e7618c","tool_use_result":{"filePath":"/data/hypogenicai/workspaces/llm-washing-machine-claude/src/experiment.py","oldString":"print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_mem / 1e9:.1f} GB\")","newString":"print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")","originalFile":"\"\"\"\nExperiment: Where is \"Washing Machine\" Stored in LLMs?\n\nThree experiments testing how compound concepts are represented:\n1. Next-token prediction analysis\n2. Residual stream direction analysis\n3. Layer-wise probing for compound concept emergence\n\nUses GPT-2 (124M) via TransformerLens for interpretability access.\n\"\"\"\n\nimport json\nimport os\nimport random\nimport sys\nfrom pathlib import Path\n\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nimport matplotlib\nmatplotlib.use('Agg')\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nfrom sklearn.linear_model import LogisticRegression, Ridge\nfrom sklearn.model_selection import cross_val_score\nfrom tqdm import tqdm\nimport transformer_lens as tl\n\n# Reproducibility\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed_all(SEED)\n\nDEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\nRESULTS_DIR = Path(\"/data/hypogenicai/workspaces/llm-washing-machine-claude/results\")\nPLOTS_DIR = RESULTS_DIR / \"plots\"\nPLOTS_DIR.mkdir(parents=True, exist_ok=True)\n\n# ── Data ──────────────────────────────────────────────────────────────────\n\n# Two-token compound nouns with compositionality ratings and control phrases\n# Each entry: (compound, word1, word2, compositionality, control_phrase)\n# Control phrases use the same word2 but a different, non-compound word1\nCOMPOUNDS = [\n    (\"washing machine\", \"washing\", \"machine\", 4, \"red machine\"),\n    (\"coffee table\", \"coffee\", \"table\", 5, \"wooden table\"),\n    (\"swimming pool\", \"swimming\", \"pool\", 4, \"deep pool\"),\n    (\"parking lot\", \"parking\", \"lot\", 4, \"empty lot\"),\n    (\"hot dog\", \"hot\", \"dog\", 1, \"big dog\"),\n    (\"shooting star\", \"shooting\", \"star\", 2, \"bright star\"),\n    (\"living room\", \"living\", \"room\", 3, \"large room\"),\n    (\"driving license\", \"driving\", \"license\", 4, \"new license\"),\n    (\"guinea pig\", \"guinea\", \"pig\", 2, \"small pig\"),\n    (\"brick house\", \"brick\", \"house\", 5, \"old house\"),\n    (\"mountain cabin\", \"mountain\", \"cabin\", 5, \"small cabin\"),\n    (\"garden hose\", \"garden\", \"hose\", 5, \"long hose\"),\n    (\"water bottle\", \"water\", \"bottle\", 5, \"glass bottle\"),\n    (\"steel bridge\", \"steel\", \"bridge\", 5, \"old bridge\"),\n    (\"chocolate cake\", \"chocolate\", \"cake\", 5, \"big cake\"),\n    (\"door handle\", \"door\", \"handle\", 5, \"metal handle\"),\n    (\"blueberry\", \"blue\", \"berry\", 4, \"small berry\"),\n    (\"snowman\", \"snow\", \"man\", 4, \"tall man\"),\n    (\"sunflower\", \"sun\", \"flower\", 4, \"red flower\"),\n]\n\n# Sentence templates for generating diverse contexts\nTEMPLATES = [\n    \"The {compound} was\",\n    \"She bought a {compound} for\",\n    \"I saw a {compound} in the\",\n    \"There is a {compound} near the\",\n    \"He fixed the {compound} with\",\n    \"A new {compound} arrived\",\n    \"The old {compound} needed\",\n    \"We need a {compound} to\",\n]\n\n# Additional contexts for word-in-isolation analysis\nISOLATION_TEMPLATES = [\n    \"The {word} was very\",\n    \"I noticed the {word} seemed\",\n    \"That {word} is quite\",\n    \"A {word} appeared in the\",\n]\n\n\ndef load_model(model_name=\"gpt2\"):\n    \"\"\"Load GPT-2 model via TransformerLens with hooks.\"\"\"\n    print(f\"Loading model: {model_name}\")\n    model = tl.HookedTransformer.from_pretrained(model_name, device=DEVICE)\n    model.eval()\n    print(f\"Model loaded: {model.cfg.n_layers} layers, d_model={model.cfg.d_model}\")\n    return model\n\n\ndef get_token_ids(model, word):\n    \"\"\"Get the token ID for a word (with leading space).\"\"\"\n    tokens = model.to_tokens(f\" {word}\", prepend_bos=False)\n    return tokens[0].tolist()\n\n\n# ── Experiment 1: Next-Token Prediction Analysis ─────────────────────────\n\ndef experiment1_next_token_prediction(model):\n    \"\"\"\n    Test whether 'washing' alone makes 'machine' more likely.\n    Compare P(word2 | word1) across compositionality levels.\n    \"\"\"\n    print(\"\\n\" + \"=\"*70)\n    print(\"EXPERIMENT 1: Next-Token Prediction Analysis\")\n    print(\"=\"*70)\n\n    results = []\n\n    for compound, word1, word2, comp_rating, control in tqdm(COMPOUNDS, desc=\"Compounds\"):\n        # Get target token id for word2\n        word2_tokens = get_token_ids(model, word2)\n        if len(word2_tokens) != 1:\n            print(f\"  Skipping {compound}: word2 '{word2}' is multi-token\")\n            continue\n        word2_id = word2_tokens[0]\n\n        # 1. P(word2 | \"The word1\")  — compound context\n        compound_probs = []\n        compound_ranks = []\n        for template in TEMPLATES:\n            prompt = template.split(\"{compound}\")[0] + word1\n            tokens = model.to_tokens(prompt)\n            with torch.no_grad():\n                logits = model(tokens)\n            last_logits = logits[0, -1]\n            probs = F.softmax(last_logits, dim=-1)\n            p_word2 = probs[word2_id].item()\n            rank = (probs > probs[word2_id]).sum().item() + 1\n            compound_probs.append(p_word2)\n            compound_ranks.append(rank)\n\n        # 2. P(word2 | \"The control_word1\") — control context\n        control_word1 = control.split()[0]\n        control_probs = []\n        control_ranks = []\n        for template in TEMPLATES:\n            prompt = template.split(\"{compound}\")[0] + control_word1\n            tokens = model.to_tokens(prompt)\n            with torch.no_grad():\n                logits = model(tokens)\n            last_logits = logits[0, -1]\n            probs = F.softmax(last_logits, dim=-1)\n            p_word2 = probs[word2_id].item()\n            rank = (probs > probs[word2_id]).sum().item() + 1\n            control_probs.append(p_word2)\n            control_ranks.append(rank)\n\n        # 3. P(word2 | unconditional) — just BOS token\n        bos_tokens = model.to_tokens(\"The\")\n        with torch.no_grad():\n            logits = model(bos_tokens)\n        last_logits = logits[0, -1]\n        probs = F.softmax(last_logits, dim=-1)\n        p_word2_uncond = probs[word2_id].item()\n        rank_uncond = (probs > probs[word2_id]).sum().item() + 1\n\n        # 4. Get top-5 predictions after word1 for interpretability\n        tokens = model.to_tokens(f\"The {word1}\")\n        with torch.no_grad():\n            logits = model(tokens)\n        last_logits = logits[0, -1]\n        probs = F.softmax(last_logits, dim=-1)\n        top5_ids = torch.topk(probs, 5).indices.tolist()\n        top5 = [(model.to_string([tid]).strip(), probs[tid].item()) for tid in top5_ids]\n\n        result = {\n            \"compound\": compound,\n            \"word1\": word1,\n            \"word2\": word2,\n            \"compositionality\": comp_rating,\n            \"p_word2_compound_mean\": np.mean(compound_probs),\n            \"p_word2_compound_std\": np.std(compound_probs),\n            \"rank_compound_mean\": np.mean(compound_ranks),\n            \"p_word2_control_mean\": np.mean(control_probs),\n            \"p_word2_control_std\": np.std(control_probs),\n            \"rank_control_mean\": np.mean(control_ranks),\n            \"p_word2_unconditional\": p_word2_uncond,\n            \"rank_unconditional\": rank_uncond,\n            \"boost_ratio\": np.mean(compound_probs) / max(np.mean(control_probs), 1e-10),\n            \"top5_after_word1\": top5,\n        }\n        results.append(result)\n\n        print(f\"  {compound:20s} | P(w2|w1)={result['p_word2_compound_mean']:.4f} \"\n              f\"rank={result['rank_compound_mean']:.0f} | \"\n              f\"P(w2|ctrl)={result['p_word2_control_mean']:.4f} \"\n              f\"rank={result['rank_control_mean']:.0f} | \"\n              f\"boost={result['boost_ratio']:.1f}x | \"\n              f\"top5: {[t[0] for t in top5]}\")\n\n    # Save results\n    with open(RESULTS_DIR / \"exp1_next_token.json\", \"w\") as f:\n        json.dump(results, f, indent=2)\n\n    return results\n\n\ndef plot_experiment1(results):\n    \"\"\"Visualize Experiment 1 results.\"\"\"\n    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n\n    compounds = [r[\"compound\"] for r in results]\n    comp_ratings = [r[\"compositionality\"] for r in results]\n    p_compound = [r[\"p_word2_compound_mean\"] for r in results]\n    p_control = [r[\"p_word2_control_mean\"] for r in results]\n    boost_ratios = [r[\"boost_ratio\"] for r in results]\n\n    # Sort by boost ratio for bar chart\n    sorted_idx = np.argsort(boost_ratios)[::-1]\n\n    # Plot 1: Boost ratio bar chart\n    ax = axes[0]\n    bars = ax.barh(range(len(compounds)),\n                   [boost_ratios[i] for i in sorted_idx],\n                   color=['#e74c3c' if comp_ratings[i] <= 2 else\n                          '#f39c12' if comp_ratings[i] == 3 else\n                          '#2ecc71' for i in sorted_idx])\n    ax.set_yticks(range(len(compounds)))\n    ax.set_yticklabels([compounds[i] for i in sorted_idx], fontsize=8)\n    ax.set_xlabel(\"Boost Ratio: P(w2|w1) / P(w2|control)\")\n    ax.set_title(\"How Much Does Word1 Boost Word2 Prediction?\")\n    ax.axvline(x=1, color='k', linestyle='--', alpha=0.5)\n    ax.invert_yaxis()\n\n    # Plot 2: Compound prob vs control prob scatter\n    ax = axes[1]\n    scatter = ax.scatter(p_control, p_compound, c=comp_ratings,\n                        cmap='RdYlGn', s=80, edgecolors='k', linewidth=0.5,\n                        vmin=1, vmax=5)\n    ax.plot([0, max(max(p_compound), max(p_control))],\n            [0, max(max(p_compound), max(p_control))],\n            'k--', alpha=0.3, label='y=x')\n    for i, c in enumerate(compounds):\n        if boost_ratios[i] > 5 or p_compound[i] > 0.05:\n            ax.annotate(c, (p_control[i], p_compound[i]),\n                       fontsize=6, ha='left', va='bottom')\n    ax.set_xlabel(\"P(word2 | control word)\")\n    ax.set_ylabel(\"P(word2 | compound word1)\")\n    ax.set_title(\"Compound vs Control Next-Token Probability\")\n    plt.colorbar(scatter, ax=ax, label=\"Compositionality Rating\")\n\n    # Plot 3: Compositionality vs boost ratio\n    ax = axes[2]\n    ax.scatter(comp_ratings, boost_ratios, s=80, c='steelblue', edgecolors='k')\n    for i, c in enumerate(compounds):\n        ax.annotate(c, (comp_ratings[i], boost_ratios[i]),\n                   fontsize=6, ha='left', va='bottom', rotation=15)\n    r, p = stats.spearmanr(comp_ratings, boost_ratios)\n    ax.set_xlabel(\"Compositionality Rating (1=idiomatic, 5=compositional)\")\n    ax.set_ylabel(\"Boost Ratio\")\n    ax.set_title(f\"Compositionality vs Prediction Boost\\n(Spearman r={r:.3f}, p={p:.3f})\")\n\n    plt.tight_layout()\n    plt.savefig(PLOTS_DIR / \"exp1_next_token_prediction.png\", dpi=150, bbox_inches='tight')\n    plt.close()\n    print(f\"Saved: {PLOTS_DIR / 'exp1_next_token_prediction.png'}\")\n\n\n# ── Experiment 2: Residual Stream Direction Analysis ─────────────────────\n\ndef experiment2_residual_directions(model):\n    \"\"\"\n    Compare directions for compound concepts vs. constituent words.\n    Test: is the compound direction a linear combination of constituent directions?\n    \"\"\"\n    print(\"\\n\" + \"=\"*70)\n    print(\"EXPERIMENT 2: Residual Stream Direction Analysis\")\n    print(\"=\"*70)\n\n    n_layers = model.cfg.n_layers\n    results = []\n\n    for compound, word1, word2, comp_rating, control in tqdm(COMPOUNDS, desc=\"Compounds\"):\n        # Verify both words are single tokens\n        w1_toks = get_token_ids(model, word1)\n        w2_toks = get_token_ids(model, word2)\n        if len(w1_toks) != 1 or len(w2_toks) != 1:\n            print(f\"  Skipping {compound}: multi-token constituent\")\n            continue\n\n        # Collect hidden states across contexts\n        compound_states = {l: [] for l in range(n_layers)}\n        word1_states = {l: [] for l in range(n_layers)}\n        word2_states = {l: [] for l in range(n_layers)}\n        control_states = {l: [] for l in range(n_layers)}\n\n        # Compound contexts: hidden state at word2 position\n        for template in TEMPLATES:\n            sentence = template.format(compound=compound)\n            tokens = model.to_tokens(sentence)\n            with torch.no_grad():\n                _, cache = model.run_with_cache(tokens)\n\n            # Find position of word2 in tokenized sentence\n            token_strs = [model.to_string([t]) for t in tokens[0]]\n            # word2 with space prefix\n            w2_str = f\" {word2}\"\n            w2_pos = None\n            for pos, ts in enumerate(token_strs):\n                if ts == w2_str:\n                    # Check that previous token is word1\n                    if pos > 0 and token_strs[pos-1].strip() == word1:\n                        w2_pos = pos\n                        break\n            if w2_pos is None:\n                continue\n\n            for layer in range(n_layers):\n                h = cache[f\"blocks.{layer}.hook_resid_post\"][0, w2_pos].cpu().numpy()\n                compound_states[layer].append(h)\n\n        # Word1 in isolation contexts\n        for template in ISOLATION_TEMPLATES:\n            sentence = template.format(word=word1)\n            tokens = model.to_tokens(sentence)\n            with torch.no_grad():\n                _, cache = model.run_with_cache(tokens)\n            token_strs = [model.to_string([t]) for t in tokens[0]]\n            w1_str = f\" {word1}\"\n            w1_pos = None\n            for pos, ts in enumerate(token_strs):\n                if ts == w1_str:\n                    w1_pos = pos\n                    break\n            if w1_pos is None:\n                continue\n            for layer in range(n_layers):\n                h = cache[f\"blocks.{layer}.hook_resid_post\"][0, w1_pos].cpu().numpy()\n                word1_states[layer].append(h)\n\n        # Word2 in isolation contexts\n        for template in ISOLATION_TEMPLATES:\n            sentence = template.format(word=word2)\n            tokens = model.to_tokens(sentence)\n            with torch.no_grad():\n                _, cache = model.run_with_cache(tokens)\n            token_strs = [model.to_string([t]) for t in tokens[0]]\n            w2_str = f\" {word2}\"\n            w2_pos = None\n            for pos, ts in enumerate(token_strs):\n                if ts == w2_str:\n                    w2_pos = pos\n                    break\n            if w2_pos is None:\n                continue\n            for layer in range(n_layers):\n                h = cache[f\"blocks.{layer}.hook_resid_post\"][0, w2_pos].cpu().numpy()\n                word2_states[layer].append(h)\n\n        # Control contexts: hidden state at word2 position in non-compound context\n        control_word1 = control.split()[0]\n        for template in TEMPLATES:\n            sentence = template.format(compound=control)\n            tokens = model.to_tokens(sentence)\n            with torch.no_grad():\n                _, cache = model.run_with_cache(tokens)\n            token_strs = [model.to_string([t]) for t in tokens[0]]\n            w2_str = f\" {word2}\"\n            w2_pos = None\n            for pos, ts in enumerate(token_strs):\n                if ts == w2_str:\n                    w2_pos = pos\n                    break\n            if w2_pos is None:\n                continue\n            for layer in range(n_layers):\n                h = cache[f\"blocks.{layer}.hook_resid_post\"][0, w2_pos].cpu().numpy()\n                control_states[layer].append(h)\n\n        # Compute metrics per layer\n        layer_metrics = []\n        for layer in range(n_layers):\n            if not compound_states[layer] or not word1_states[layer] or not word2_states[layer]:\n                layer_metrics.append(None)\n                continue\n\n            # Mean directions\n            compound_dir = np.mean(compound_states[layer], axis=0)\n            word1_dir = np.mean(word1_states[layer], axis=0)\n            word2_dir = np.mean(word2_states[layer], axis=0)\n\n            # Cosine similarities\n            def cosine_sim(a, b):\n                return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b) + 1e-10)\n\n            sim_compound_w1 = cosine_sim(compound_dir, word1_dir)\n            sim_compound_w2 = cosine_sim(compound_dir, word2_dir)\n            sim_w1_w2 = cosine_sim(word1_dir, word2_dir)\n\n            # Linear reconstruction: compound = alpha*word1 + beta*word2 + bias\n            X = np.stack([word1_dir, word2_dir], axis=0).T  # d_model x 2\n            y = compound_dir\n            # Least squares: (X^T X)^{-1} X^T y\n            try:\n                coeffs = np.linalg.lstsq(X, y, rcond=None)[0]\n                y_pred = X @ coeffs\n                ss_res = np.sum((y - y_pred) ** 2)\n                ss_tot = np.sum((y - np.mean(y)) ** 2)\n                r_squared = 1 - ss_res / ss_tot if ss_tot > 0 else 0\n            except np.linalg.LinAlgError:\n                coeffs = np.array([0, 0])\n                r_squared = 0\n\n            # Control comparison\n            if control_states[layer]:\n                control_dir = np.mean(control_states[layer], axis=0)\n                sim_control_w2 = cosine_sim(control_dir, word2_dir)\n                sim_compound_control = cosine_sim(compound_dir, control_dir)\n            else:\n                sim_control_w2 = None\n                sim_compound_control = None\n\n            # Uniqueness: residual after removing word1 and word2 components\n            residual = compound_dir - y_pred\n            residual_norm_ratio = np.linalg.norm(residual) / (np.linalg.norm(compound_dir) + 1e-10)\n\n            layer_metrics.append({\n                \"layer\": layer,\n                \"sim_compound_word1\": float(sim_compound_w1),\n                \"sim_compound_word2\": float(sim_compound_w2),\n                \"sim_word1_word2\": float(sim_w1_w2),\n                \"reconstruction_r2\": float(r_squared),\n                \"alpha_word1\": float(coeffs[0]),\n                \"beta_word2\": float(coeffs[1]),\n                \"residual_norm_ratio\": float(residual_norm_ratio),\n                \"sim_control_word2\": float(sim_control_w2) if sim_control_w2 is not None else None,\n                \"sim_compound_control\": float(sim_compound_control) if sim_compound_control is not None else None,\n            })\n\n        result = {\n            \"compound\": compound,\n            \"word1\": word1,\n            \"word2\": word2,\n            \"compositionality\": comp_rating,\n            \"n_compound_contexts\": len(compound_states[0]),\n            \"n_word1_contexts\": len(word1_states[0]),\n            \"n_word2_contexts\": len(word2_states[0]),\n            \"layer_metrics\": layer_metrics,\n        }\n        results.append(result)\n\n        # Print summary for last layer\n        last = layer_metrics[-1]\n        if last:\n            print(f\"  {compound:20s} | cos(C,w1)={last['sim_compound_word1']:.3f} \"\n                  f\"cos(C,w2)={last['sim_compound_word2']:.3f} \"\n                  f\"R²={last['reconstruction_r2']:.3f} \"\n                  f\"residual={last['residual_norm_ratio']:.3f}\")\n\n    with open(RESULTS_DIR / \"exp2_residual_directions.json\", \"w\") as f:\n        json.dump(results, f, indent=2)\n\n    return results\n\n\ndef plot_experiment2(results):\n    \"\"\"Visualize Experiment 2 results.\"\"\"\n    fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n\n    n_layers = 12  # GPT-2\n\n    # Plot 1: R² across layers (all compounds)\n    ax = axes[0, 0]\n    for r in results:\n        layers = []\n        r2_vals = []\n        for m in r[\"layer_metrics\"]:\n            if m is not None:\n                layers.append(m[\"layer\"])\n                r2_vals.append(m[\"reconstruction_r2\"])\n        color = plt.cm.RdYlGn(r[\"compositionality\"] / 5.0)\n        ax.plot(layers, r2_vals, alpha=0.6, color=color, linewidth=1.5)\n    ax.set_xlabel(\"Layer\")\n    ax.set_ylabel(\"R² (compound ≈ α·word1 + β·word2)\")\n    ax.set_title(\"Linear Reconstruction Quality Across Layers\")\n    ax.set_ylim(-0.1, 1.1)\n    # Add colorbar\n    sm = plt.cm.ScalarMappable(cmap='RdYlGn', norm=plt.Normalize(1, 5))\n    plt.colorbar(sm, ax=ax, label=\"Compositionality\")\n\n    # Plot 2: Cosine similarity (compound vs word2) across layers\n    ax = axes[0, 1]\n    for r in results:\n        layers = []\n        sims = []\n        for m in r[\"layer_metrics\"]:\n            if m is not None:\n                layers.append(m[\"layer\"])\n                sims.append(m[\"sim_compound_word2\"])\n        color = plt.cm.RdYlGn(r[\"compositionality\"] / 5.0)\n        ax.plot(layers, sims, alpha=0.6, color=color, linewidth=1.5)\n    ax.set_xlabel(\"Layer\")\n    ax.set_ylabel(\"Cosine Similarity\")\n    ax.set_title(\"Similarity: Compound Direction vs Word2 Direction\")\n\n    # Plot 3: Residual norm ratio across layers\n    ax = axes[1, 0]\n    for r in results:\n        layers = []\n        residuals = []\n        for m in r[\"layer_metrics\"]:\n            if m is not None:\n                layers.append(m[\"layer\"])\n                residuals.append(m[\"residual_norm_ratio\"])\n        color = plt.cm.RdYlGn(r[\"compositionality\"] / 5.0)\n        ax.plot(layers, residuals, alpha=0.6, color=color, linewidth=1.5)\n    ax.set_xlabel(\"Layer\")\n    ax.set_ylabel(\"||residual|| / ||compound||\")\n    ax.set_title(\"Unique Component (Not Explained by Constituents)\")\n\n    # Plot 4: Final layer R² vs compositionality\n    ax = axes[1, 1]\n    comps = []\n    r2_finals = []\n    labels = []\n    for r in results:\n        last = r[\"layer_metrics\"][-1]\n        if last:\n            comps.append(r[\"compositionality\"])\n            r2_finals.append(last[\"reconstruction_r2\"])\n            labels.append(r[\"compound\"])\n    ax.scatter(comps, r2_finals, s=80, c='steelblue', edgecolors='k')\n    for i, label in enumerate(labels):\n        ax.annotate(label, (comps[i], r2_finals[i]), fontsize=6,\n                   ha='left', va='bottom', rotation=15)\n    r_corr, p_val = stats.spearmanr(comps, r2_finals)\n    ax.set_xlabel(\"Compositionality Rating\")\n    ax.set_ylabel(\"Final Layer R²\")\n    ax.set_title(f\"Compositionality vs Reconstruction Quality\\n(Spearman r={r_corr:.3f}, p={p_val:.3f})\")\n\n    plt.tight_layout()\n    plt.savefig(PLOTS_DIR / \"exp2_residual_directions.png\", dpi=150, bbox_inches='tight')\n    plt.close()\n    print(f\"Saved: {PLOTS_DIR / 'exp2_residual_directions.png'}\")\n\n\n# ── Experiment 3: Layer-wise Probing ─────────────────────────────────────\n\ndef experiment3_layerwise_probing(model):\n    \"\"\"\n    Train probes to test where compound concept representations emerge.\n\n    Probe 1: At the word2 position, can we predict what word1 was?\n             (Tests token erasure: if accuracy drops, word1 info is being erased)\n    Probe 2: Can we distinguish compound vs. non-compound contexts at the word2 position?\n             (Tests whether compounds create a unique representation)\n    \"\"\"\n    print(\"\\n\" + \"=\"*70)\n    print(\"EXPERIMENT 3: Layer-wise Probing for Compound Concept Emergence\")\n    print(\"=\"*70)\n\n    n_layers = model.cfg.n_layers\n\n    # Collect data: hidden states at the word2 position\n    # Label 1: which word1 preceded (for erasure analysis)\n    # Label 2: compound (1) vs control (0) context\n\n    compound_data = []  # (hidden_states_per_layer, word1_label, compound_label=1, compound_name)\n    control_data = []   # (hidden_states_per_layer, word1_label, compound_label=0, compound_name)\n\n    word1_to_idx = {}\n    idx_counter = 0\n\n    for compound, word1, word2, comp_rating, control in tqdm(COMPOUNDS, desc=\"Collecting activations\"):\n        w1_toks = get_token_ids(model, word1)\n        w2_toks = get_token_ids(model, word2)\n        if len(w1_toks) != 1 or len(w2_toks) != 1:\n            continue\n\n        if word1 not in word1_to_idx:\n            word1_to_idx[word1] = idx_counter\n            idx_counter += 1\n        w1_idx = word1_to_idx[word1]\n\n        control_word1 = control.split()[0]\n        if control_word1 not in word1_to_idx:\n            word1_to_idx[control_word1] = idx_counter\n            idx_counter += 1\n        ctrl_w1_idx = word1_to_idx[control_word1]\n\n        # Compound contexts\n        for template in TEMPLATES:\n            sentence = template.format(compound=compound)\n            tokens = model.to_tokens(sentence)\n            with torch.no_grad():\n                _, cache = model.run_with_cache(tokens)\n\n            token_strs = [model.to_string([t]) for t in tokens[0]]\n            w2_str = f\" {word2}\"\n            w2_pos = None\n            for pos, ts in enumerate(token_strs):\n                if ts == w2_str and pos > 0 and token_strs[pos-1].strip() == word1:\n                    w2_pos = pos\n                    break\n            if w2_pos is None:\n                continue\n\n            states = {}\n            for layer in range(n_layers):\n                states[layer] = cache[f\"blocks.{layer}.hook_resid_post\"][0, w2_pos].cpu().numpy()\n            compound_data.append((states, w1_idx, 1, compound, comp_rating))\n\n        # Control contexts\n        for template in TEMPLATES:\n            sentence = template.format(compound=control)\n            tokens = model.to_tokens(sentence)\n            with torch.no_grad():\n                _, cache = model.run_with_cache(tokens)\n\n            token_strs = [model.to_string([t]) for t in tokens[0]]\n            w2_str = f\" {word2}\"\n            w2_pos = None\n            for pos, ts in enumerate(token_strs):\n                if ts == w2_str:\n                    w2_pos = pos\n                    break\n            if w2_pos is None:\n                continue\n\n            states = {}\n            for layer in range(n_layers):\n                states[layer] = cache[f\"blocks.{layer}.hook_resid_post\"][0, w2_pos].cpu().numpy()\n            control_data.append((states, ctrl_w1_idx, 0, control, comp_rating))\n\n    print(f\"\\nCollected {len(compound_data)} compound samples, {len(control_data)} control samples\")\n    print(f\"Number of unique word1 labels: {len(word1_to_idx)}\")\n\n    # ── Probe 1: Word1 identity prediction (erasure analysis) ──\n    # Only on compound data: can we tell what word1 was from the word2 position?\n    print(\"\\nProbe 1: Word1 Identity Prediction (Token Erasure)\")\n\n    probe1_results = {\"layer\": [], \"accuracy\": [], \"accuracy_std\": []}\n\n    for layer in range(n_layers):\n        X = np.array([d[0][layer] for d in compound_data])\n        y = np.array([d[1] for d in compound_data])\n\n        if len(np.unique(y)) < 2:\n            probe1_results[\"layer\"].append(layer)\n            probe1_results[\"accuracy\"].append(0)\n            probe1_results[\"accuracy_std\"].append(0)\n            continue\n\n        clf = LogisticRegression(max_iter=1000, random_state=SEED, C=1.0)\n        scores = cross_val_score(clf, X, y, cv=min(5, len(X)), scoring='accuracy')\n        probe1_results[\"layer\"].append(layer)\n        probe1_results[\"accuracy\"].append(scores.mean())\n        probe1_results[\"accuracy_std\"].append(scores.std())\n\n        print(f\"  Layer {layer:2d}: accuracy = {scores.mean():.3f} ± {scores.std():.3f}\")\n\n    # ── Probe 2: Compound vs. Control Classification ──\n    print(\"\\nProbe 2: Compound vs. Control Context Classification\")\n\n    all_data = compound_data + control_data\n    probe2_results = {\"layer\": [], \"accuracy\": [], \"accuracy_std\": []}\n\n    for layer in range(n_layers):\n        X = np.array([d[0][layer] for d in all_data])\n        y = np.array([d[2] for d in all_data])\n\n        clf = LogisticRegression(max_iter=1000, random_state=SEED, C=1.0)\n        scores = cross_val_score(clf, X, y, cv=min(5, len(X)), scoring='accuracy')\n        probe2_results[\"layer\"].append(layer)\n        probe2_results[\"accuracy\"].append(scores.mean())\n        probe2_results[\"accuracy_std\"].append(scores.std())\n\n        print(f\"  Layer {layer:2d}: accuracy = {scores.mean():.3f} ± {scores.std():.3f}\")\n\n    # ── Probe 3: Per-compositionality-level compound vs. control ──\n    print(\"\\nProbe 3: Compound vs. Control by Compositionality Level\")\n\n    comp_levels = sorted(set(r for _, _, _, _, r in compound_data))\n    probe3_results = {level: {\"layer\": [], \"accuracy\": []} for level in comp_levels}\n\n    for level in comp_levels:\n        level_compound = [d for d in compound_data if d[4] == level]\n        level_control = [d for d in control_data if d[4] == level]\n        level_data = level_compound + level_control\n\n        if len(level_data) < 10:\n            continue\n\n        for layer in range(n_layers):\n            X = np.array([d[0][layer] for d in level_data])\n            y = np.array([d[2] for d in level_data])\n\n            if len(np.unique(y)) < 2:\n                continue\n\n            clf = LogisticRegression(max_iter=1000, random_state=SEED, C=1.0)\n            cv_folds = min(3, min(np.sum(y==0), np.sum(y==1)))\n            if cv_folds < 2:\n                continue\n            scores = cross_val_score(clf, X, y, cv=cv_folds, scoring='accuracy')\n            probe3_results[level][\"layer\"].append(layer)\n            probe3_results[level][\"accuracy\"].append(scores.mean())\n\n    results = {\n        \"probe1_word1_identity\": probe1_results,\n        \"probe2_compound_vs_control\": probe2_results,\n        \"probe3_by_compositionality\": {str(k): v for k, v in probe3_results.items()},\n        \"n_compound_samples\": len(compound_data),\n        \"n_control_samples\": len(control_data),\n        \"n_word1_classes\": len(word1_to_idx),\n    }\n\n    with open(RESULTS_DIR / \"exp3_probing.json\", \"w\") as f:\n        json.dump(results, f, indent=2)\n\n    return results\n\n\ndef plot_experiment3(results):\n    \"\"\"Visualize Experiment 3 results.\"\"\"\n    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n\n    # Plot 1: Word1 identity probe accuracy across layers (erasure)\n    ax = axes[0]\n    p1 = results[\"probe1_word1_identity\"]\n    ax.errorbar(p1[\"layer\"], p1[\"accuracy\"], yerr=p1[\"accuracy_std\"],\n                marker='o', capsize=3, color='steelblue', linewidth=2)\n    chance = 1.0 / results[\"n_word1_classes\"]\n    ax.axhline(y=chance, color='red', linestyle='--', alpha=0.5, label=f'Chance ({chance:.2f})')\n    ax.set_xlabel(\"Layer\")\n    ax.set_ylabel(\"Accuracy\")\n    ax.set_title(\"Probe 1: Can We Predict Word1 from Word2 Position?\\n(Token Erasure Test)\")\n    ax.legend()\n    ax.set_ylim(0, 1.05)\n\n    # Plot 2: Compound vs control classification\n    ax = axes[1]\n    p2 = results[\"probe2_compound_vs_control\"]\n    ax.errorbar(p2[\"layer\"], p2[\"accuracy\"], yerr=p2[\"accuracy_std\"],\n                marker='s', capsize=3, color='darkorange', linewidth=2)\n    ax.axhline(y=0.5, color='red', linestyle='--', alpha=0.5, label='Chance (0.50)')\n    ax.set_xlabel(\"Layer\")\n    ax.set_ylabel(\"Accuracy\")\n    ax.set_title(\"Probe 2: Can We Distinguish Compound vs. Control Context?\")\n    ax.legend()\n    ax.set_ylim(0, 1.05)\n\n    # Plot 3: By compositionality level\n    ax = axes[2]\n    colors = {1: '#e74c3c', 2: '#e67e22', 3: '#f1c40f', 4: '#2ecc71', 5: '#27ae60'}\n    for level_str, data in results[\"probe3_by_compositionality\"].items():\n        level = int(level_str)\n        if data[\"layer\"]:\n            ax.plot(data[\"layer\"], data[\"accuracy\"],\n                   marker='o', color=colors.get(level, 'gray'),\n                   label=f'Comp={level}', linewidth=1.5, markersize=4)\n    ax.axhline(y=0.5, color='red', linestyle='--', alpha=0.5)\n    ax.set_xlabel(\"Layer\")\n    ax.set_ylabel(\"Accuracy\")\n    ax.set_title(\"Probe 3: Compound vs. Control by Compositionality\")\n    ax.legend(fontsize=8)\n    ax.set_ylim(0, 1.05)\n\n    plt.tight_layout()\n    plt.savefig(PLOTS_DIR / \"exp3_layerwise_probing.png\", dpi=150, bbox_inches='tight')\n    plt.close()\n    print(f\"Saved: {PLOTS_DIR / 'exp3_layerwise_probing.png'}\")\n\n\n# ── Experiment 4: Attention Pattern Analysis ─────────────────────────────\n\ndef experiment4_attention_patterns(model):\n    \"\"\"\n    Analyze how attention at the word2 position relates to word1.\n    If compound concepts are assembled via attention, the word2 position\n    should attend heavily to the word1 position specifically in compound contexts.\n    \"\"\"\n    print(\"\\n\" + \"=\"*70)\n    print(\"EXPERIMENT 4: Attention Pattern Analysis\")\n    print(\"=\"*70)\n\n    n_layers = model.cfg.n_layers\n    n_heads = model.cfg.n_heads\n    results = []\n\n    for compound, word1, word2, comp_rating, control in tqdm(COMPOUNDS, desc=\"Attention analysis\"):\n        w1_toks = get_token_ids(model, word1)\n        w2_toks = get_token_ids(model, word2)\n        if len(w1_toks) != 1 or len(w2_toks) != 1:\n            continue\n\n        compound_attn_to_w1 = np.zeros((n_layers, n_heads))\n        control_attn_to_w1_pos = np.zeros((n_layers, n_heads))\n        n_compound = 0\n        n_control = 0\n\n        # Compound contexts\n        for template in TEMPLATES:\n            sentence = template.format(compound=compound)\n            tokens = model.to_tokens(sentence)\n            with torch.no_grad():\n                _, cache = model.run_with_cache(tokens)\n\n            token_strs = [model.to_string([t]) for t in tokens[0]]\n            w2_str = f\" {word2}\"\n            w2_pos = None\n            w1_pos = None\n            for pos, ts in enumerate(token_strs):\n                if ts == w2_str and pos > 0 and token_strs[pos-1].strip() == word1:\n                    w2_pos = pos\n                    w1_pos = pos - 1\n                    break\n            if w2_pos is None:\n                continue\n\n            for layer in range(n_layers):\n                attn = cache[f\"blocks.{layer}.attn.hook_pattern\"][0, :, w2_pos, w1_pos]\n                compound_attn_to_w1[layer] += attn.cpu().numpy()\n            n_compound += 1\n\n        # Control contexts\n        for template in TEMPLATES:\n            sentence = template.format(compound=control)\n            tokens = model.to_tokens(sentence)\n            with torch.no_grad():\n                _, cache = model.run_with_cache(tokens)\n\n            token_strs = [model.to_string([t]) for t in tokens[0]]\n            w2_str = f\" {word2}\"\n            w2_pos = None\n            for pos, ts in enumerate(token_strs):\n                if ts == w2_str:\n                    w2_pos = pos\n                    break\n            if w2_pos is None or w2_pos < 1:\n                continue\n\n            ctrl_w1_pos = w2_pos - 1  # word just before word2 in control\n\n            for layer in range(n_layers):\n                attn = cache[f\"blocks.{layer}.attn.hook_pattern\"][0, :, w2_pos, ctrl_w1_pos]\n                control_attn_to_w1_pos[layer] += attn.cpu().numpy()\n            n_control += 1\n\n        if n_compound > 0:\n            compound_attn_to_w1 /= n_compound\n        if n_control > 0:\n            control_attn_to_w1_pos /= n_control\n\n        # Compute per-layer average attention difference\n        attn_diff = compound_attn_to_w1 - control_attn_to_w1_pos\n\n        results.append({\n            \"compound\": compound,\n            \"compositionality\": comp_rating,\n            \"compound_attn_to_word1\": compound_attn_to_w1.tolist(),\n            \"control_attn_to_prev\": control_attn_to_w1_pos.tolist(),\n            \"attn_diff_mean_per_layer\": attn_diff.mean(axis=1).tolist(),\n            \"n_compound\": n_compound,\n            \"n_control\": n_control,\n        })\n\n        mean_diff = attn_diff.mean(axis=1)\n        max_layer = np.argmax(np.abs(mean_diff))\n        print(f\"  {compound:20s} | max attn diff at layer {max_layer}: {mean_diff[max_layer]:.4f}\")\n\n    with open(RESULTS_DIR / \"exp4_attention.json\", \"w\") as f:\n        json.dump(results, f, indent=2)\n\n    return results\n\n\ndef plot_experiment4(results):\n    \"\"\"Visualize attention pattern analysis.\"\"\"\n    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n\n    # Plot 1: Attention to word1 across layers (compound vs control)\n    ax = axes[0]\n    all_compound_attn = []\n    all_control_attn = []\n    for r in results:\n        compound_mean = np.array(r[\"compound_attn_to_word1\"]).mean(axis=1)\n        control_mean = np.array(r[\"control_attn_to_prev\"]).mean(axis=1)\n        all_compound_attn.append(compound_mean)\n        all_control_attn.append(control_mean)\n\n    all_compound_attn = np.array(all_compound_attn)\n    all_control_attn = np.array(all_control_attn)\n\n    layers = range(all_compound_attn.shape[1])\n    ax.plot(layers, all_compound_attn.mean(axis=0), 'b-o', label='Compound (w2→w1)', linewidth=2)\n    ax.fill_between(layers,\n                    all_compound_attn.mean(axis=0) - all_compound_attn.std(axis=0),\n                    all_compound_attn.mean(axis=0) + all_compound_attn.std(axis=0),\n                    alpha=0.2, color='blue')\n    ax.plot(layers, all_control_attn.mean(axis=0), 'r-s', label='Control (w2→prev)', linewidth=2)\n    ax.fill_between(layers,\n                    all_control_attn.mean(axis=0) - all_control_attn.std(axis=0),\n                    all_control_attn.mean(axis=0) + all_control_attn.std(axis=0),\n                    alpha=0.2, color='red')\n    ax.set_xlabel(\"Layer\")\n    ax.set_ylabel(\"Mean Attention Weight\")\n    ax.set_title(\"Attention from Word2 to Word1/Previous Word\")\n    ax.legend()\n\n    # Plot 2: Attention difference by compositionality\n    ax = axes[1]\n    for r in results:\n        diff = r[\"attn_diff_mean_per_layer\"]\n        color = plt.cm.RdYlGn(r[\"compositionality\"] / 5.0)\n        ax.plot(range(len(diff)), diff, alpha=0.5, color=color, linewidth=1.5)\n    ax.axhline(y=0, color='k', linestyle='--', alpha=0.3)\n    ax.set_xlabel(\"Layer\")\n    ax.set_ylabel(\"Attention Difference (Compound - Control)\")\n    ax.set_title(\"Differential Attention to Preceding Word\")\n    sm = plt.cm.ScalarMappable(cmap='RdYlGn', norm=plt.Normalize(1, 5))\n    plt.colorbar(sm, ax=ax, label=\"Compositionality\")\n\n    plt.tight_layout()\n    plt.savefig(PLOTS_DIR / \"exp4_attention_patterns.png\", dpi=150, bbox_inches='tight')\n    plt.close()\n    print(f\"Saved: {PLOTS_DIR / 'exp4_attention_patterns.png'}\")\n\n\n# ── Main ─────────────────────────────────────────────────────────────────\n\ndef main():\n    print(\"=\"*70)\n    print(\"WHERE IS 'WASHING MACHINE' STORED IN LLMs?\")\n    print(\"=\"*70)\n    print(f\"\\nDevice: {DEVICE}\")\n    print(f\"Seed: {SEED}\")\n    print(f\"Number of compounds: {len(COMPOUNDS)}\")\n    print(f\"Number of templates: {len(TEMPLATES)}\")\n\n    # Log environment\n    print(f\"\\nPython: {sys.version}\")\n    print(f\"PyTorch: {torch.__version__}\")\n    print(f\"TransformerLens: {getattr(tl, '__version__', 'unknown')}\")\n    if torch.cuda.is_available():\n        print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n        print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_mem / 1e9:.1f} GB\")\n\n    # Save config\n    config = {\n        \"seed\": SEED,\n        \"model\": \"gpt2\",\n        \"n_compounds\": len(COMPOUNDS),\n        \"n_templates\": len(TEMPLATES),\n        \"device\": DEVICE,\n        \"python_version\": sys.version,\n        \"torch_version\": torch.__version__,\n    }\n    with open(RESULTS_DIR / \"config.json\", \"w\") as f:\n        json.dump(config, f, indent=2)\n\n    # Load model\n    model = load_model(\"gpt2\")\n\n    # Run experiments\n    print(\"\\n\\n\" + \"=\"*70)\n    print(\"RUNNING ALL EXPERIMENTS\")\n    print(\"=\"*70)\n\n    # Experiment 1: Next-token prediction\n    exp1_results = experiment1_next_token_prediction(model)\n    plot_experiment1(exp1_results)\n\n    # Experiment 2: Residual stream directions\n    exp2_results = experiment2_residual_directions(model)\n    plot_experiment2(exp2_results)\n\n    # Experiment 3: Layer-wise probing\n    exp3_results = experiment3_layerwise_probing(model)\n    plot_experiment3(exp3_results)\n\n    # Experiment 4: Attention patterns\n    exp4_results = experiment4_attention_patterns(model)\n    plot_experiment4(exp4_results)\n\n    print(\"\\n\\n\" + \"=\"*70)\n    print(\"ALL EXPERIMENTS COMPLETE\")\n    print(\"=\"*70)\n    print(f\"\\nResults saved to: {RESULTS_DIR}\")\n    print(f\"Plots saved to: {PLOTS_DIR}\")\n\n    return exp1_results, exp2_results, exp3_results, exp4_results\n\n\nif __name__ == \"__main__\":\n    main()\n","structuredPatch":[{"oldStart":944,"oldLines":7,"newStart":944,"newLines":7,"lines":["     print(f\"TransformerLens: {getattr(tl, '__version__', 'unknown')}\")","     if torch.cuda.is_available():","         print(f\"GPU: {torch.cuda.get_device_name(0)}\")","-        print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_mem / 1e9:.1f} GB\")","+        print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"," ","     # Save config","     config = {"]}],"userModified":false,"replaceAll":false}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_016H8fY8BHz3JYU3jeSuB8iY","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01PuaMofq2CawmRXs3v8Kf3U","name":"Bash","input":{"command":"source .venv/bin/activate && CUDA_VISIBLE_DEVICES=0 python src/experiment.py 2>&1","description":"Run all experiments (GPT-2 on GPU)","timeout":600000}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":245,"cache_read_input_tokens":69826,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":245},"output_tokens":19,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"15adc1b7-c416-4852-be03-0554fdf2162b"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01PuaMofq2CawmRXs3v8Kf3U","type":"tool_result","content":"======================================================================\nWHERE IS 'WASHING MACHINE' STORED IN LLMs?\n======================================================================\n\nDevice: cuda:0\nSeed: 42\nNumber of compounds: 19\nNumber of templates: 8\n\nPython: 3.12.2 | packaged by Anaconda, Inc. | (main, Feb 27 2024, 17:35:02) [GCC 11.2.0]\nPyTorch: 2.10.0+cu128\nTransformerLens: unknown\nGPU: NVIDIA GeForce RTX 3090\nGPU Memory: 25.3 GB\nLoading model: gpt2\n`torch_dtype` is deprecated! Use `dtype` instead!\nLoaded pretrained model gpt2 into HookedTransformer\nModel loaded: 12 layers, d_model=768\n\n\n======================================================================\nRUNNING ALL EXPERIMENTS\n======================================================================\n\n======================================================================\nEXPERIMENT 1: Next-Token Prediction Analysis\n======================================================================\n\rCompounds:   0%|          | 0/19 [00:00<?, ?it/s]  washing machine      | P(w2|w1)=0.8270 rank=1 | P(w2|ctrl)=0.0002 rank=924 | boost=4963.4x | top5: ['machine', 'machines', '-', 'ton', 'of']\n\rCompounds:   5%|▌         | 1/19 [00:00<00:08,  2.20it/s]  coffee table         | P(w2|w1)=0.0632 rank=4 | P(w2|ctrl)=0.0091 rank=14 | boost=6.9x | top5: ['shop', '-', 'is', 'maker', 'industry']\n\rCompounds:  11%|█         | 2/19 [00:00<00:05,  2.88it/s]  swimming pool        | P(w2|w1)=0.6258 rank=1 | P(w2|ctrl)=0.0011 rank=125 | boost=549.4x | top5: ['pool', 'pools', 'team', 'hole', '-']\n\rCompounds:  16%|█▌        | 3/19 [00:00<00:04,  3.21it/s]  parking lot          | P(w2|w1)=0.3215 rank=1 | P(w2|ctrl)=0.0116 rank=14 | boost=27.7x | top5: ['lot', 'garage', 'meter', 'lots', 'space']\n\rCompounds:  21%|██        | 4/19 [00:01<00:04,  3.36it/s]  hot dog              | P(w2|w1)=0.0973 rank=4 | P(w2|ctrl)=0.0022 rank=142 | boost=44.7x | top5: ['new', 'topic', 'dog', '-', 'spot']\n\rCompounds:  26%|██▋       | 5/19 [00:01<00:04,  3.48it/s]  shooting star        | P(w2|w1)=0.0307 rank=90 | P(w2|ctrl)=0.0103 rank=18 | boost=3.0x | top5: ['of', 'death', 'at', 'was', 'in']\n\rCompounds:  32%|███▏      | 6/19 [00:01<00:03,  3.55it/s]  living room          | P(w2|w1)=0.2611 rank=2 | P(w2|ctrl)=0.0016 rank=98 | boost=159.9x | top5: ['room', '-', 'wage', 'world', 'rooms']\n\rCompounds:  37%|███▋      | 7/19 [00:02<00:03,  3.57it/s]  driving license      | P(w2|w1)=0.0364 rank=118 | P(w2|ctrl)=0.0002 rank=1325 | boost=220.7x | top5: ['force', 'forces', 'seat', '-', 'season']\n\rCompounds:  42%|████▏     | 8/19 [00:02<00:03,  3.62it/s]  guinea pig           | P(w2|w1)=0.8326 rank=1 | P(w2|ctrl)=0.0001 rank=1755 | boost=7233.3x | top5: ['pig', 'pigs', 'worm', '-', 'p']\n\rCompounds:  47%|████▋     | 9/19 [00:02<00:02,  3.65it/s]  brick house          | P(w2|w1)=0.0273 rank=11 | P(w2|ctrl)=0.0047 rank=62 | boost=5.8x | top5: ['-', 'wall', 'and', 'layer', 'walls']\n\rCompounds:  53%|█████▎    | 10/19 [00:02<00:02,  3.68it/s]  mountain cabin       | P(w2|w1)=0.0040 rank=149 | P(w2|ctrl)=0.0014 rank=305 | boost=2.9x | top5: ['of', 'is', 'lion', 'range', 'bike']\n\rCompounds:  58%|█████▊    | 11/19 [00:03<00:02,  3.69it/s]  garden hose          | P(w2|w1)=0.0235 rank=12 | P(w2|ctrl)=0.0001 rank=2101 | boost=200.4x | top5: ['is', 'of', 'was', '-', 'has']\n\rCompounds:  63%|██████▎   | 12/19 [00:03<00:01,  3.68it/s]  water bottle         | P(w2|w1)=0.0656 rank=17 | P(w2|ctrl)=0.0176 rank=11 | boost=3.7x | top5: ['is', 'in', 'quality', 'level', 'supply']\n\rCompounds:  68%|██████▊   | 13/19 [00:03<00:01,  3.70it/s]  steel bridge         | P(w2|w1)=0.0046 rank=53 | P(w2|ctrl)=0.0004 rank=992 | boost=12.6x | top5: ['-', 'and', 'is', 'head', 'was']\n\rCompounds:  74%|███████▎  | 14/19 [00:03<00:01,  3.71it/s]  chocolate cake       | P(w2|w1)=0.0356 rank=5 | P(w2|ctrl)=0.0003 rank=978 | boost=140.4x | top5: ['chip', '-', 'bar', 'is', 'and']\n\rCompounds:  79%|███████▉  | 15/19 [00:04<00:01,  3.72it/s]  door handle          | P(w2|w1)=0.0068 rank=42 | P(w2|ctrl)=0.0007 rank=376 | boost=9.2x | top5: ['to', 'is', 'bell', 'was', 'of']\n\rCompounds:  84%|████████▍ | 16/19 [00:04<00:00,  3.72it/s]  Skipping blueberry: word2 'berry' is multi-token\n  snowman              | P(w2|w1)=0.0038 rank=63 | P(w2|ctrl)=0.0427 rank=7 | boost=0.1x | top5: ['is', '-', 'was', 'storm', 'has']\n\rCompounds:  95%|█████████▍| 18/19 [00:04<00:00,  4.82it/s]  sunflower            | P(w2|w1)=0.0001 rank=1673 | P(w2|ctrl)=0.0004 rank=706 | boost=0.3x | top5: ['is', 'was', 'has', \"'s\", 'rises']\n\rCompounds: 100%|██████████| 19/19 [00:05<00:00,  4.50it/s]\rCompounds: 100%|██████████| 19/19 [00:05<00:00,  3.77it/s]\nSaved: /data/hypogenicai/workspaces/llm-washing-machine-claude/results/plots/exp1_next_token_prediction.png\n\n======================================================================\nEXPERIMENT 2: Residual Stream Direction Analysis\n======================================================================\n\rCompounds:   0%|          | 0/19 [00:00<?, ?it/s]  washing machine      | cos(C,w1)=0.907 cos(C,w2)=0.951 R²=0.917 residual=0.288\n\rCompounds:   5%|▌         | 1/19 [00:00<00:09,  1.80it/s]  coffee table         | cos(C,w1)=0.934 cos(C,w2)=0.962 R²=0.938 residual=0.249\n\rCompounds:  11%|█         | 2/19 [00:01<00:09,  1.81it/s]  swimming pool        | cos(C,w1)=0.932 cos(C,w2)=0.957 R²=0.924 residual=0.276\n\rCompounds:  16%|█▌        | 3/19 [00:01<00:10,  1.52it/s]  parking lot          | cos(C,w1)=0.936 cos(C,w2)=0.934 R²=0.922 residual=0.280\n\rCompounds:  21%|██        | 4/19 [00:02<00:09,  1.62it/s]  hot dog              | cos(C,w1)=0.897 cos(C,w2)=0.934 R²=0.888 residual=0.335\n\rCompounds:  26%|██▋       | 5/19 [00:02<00:08,  1.69it/s]  shooting star        | cos(C,w1)=0.929 cos(C,w2)=0.960 R²=0.944 residual=0.236\n\rCompounds:  32%|███▏      | 6/19 [00:03<00:07,  1.72it/s]  living room          | cos(C,w1)=0.925 cos(C,w2)=0.958 R²=0.933 residual=0.259\n\rCompounds:  37%|███▋      | 7/19 [00:04<00:07,  1.56it/s]  driving license      | cos(C,w1)=0.908 cos(C,w2)=0.955 R²=0.924 residual=0.276\n\rCompounds:  42%|████▏     | 8/19 [00:04<00:06,  1.63it/s]  Skipping guinea pig: multi-token constituent\n  brick house          | cos(C,w1)=0.933 cos(C,w2)=0.965 R²=0.939 residual=0.247\n\rCompounds:  53%|█████▎    | 10/19 [00:05<00:04,  2.21it/s]  mountain cabin       | cos(C,w1)=0.937 cos(C,w2)=0.975 R²=0.956 residual=0.209\n\rCompounds:  58%|█████▊    | 11/19 [00:06<00:04,  1.90it/s]  garden hose          | cos(C,w1)=0.933 cos(C,w2)=0.979 R²=0.962 residual=0.196\n\rCompounds:  63%|██████▎   | 12/19 [00:06<00:03,  1.88it/s]  water bottle         | cos(C,w1)=0.924 cos(C,w2)=0.963 R²=0.931 residual=0.262\n\rCompounds:  68%|██████▊   | 13/19 [00:07<00:03,  1.86it/s]  steel bridge         | cos(C,w1)=0.924 cos(C,w2)=0.982 R²=0.965 residual=0.188\n\rCompounds:  74%|███████▎  | 14/19 [00:07<00:02,  1.84it/s]  chocolate cake       | cos(C,w1)=0.944 cos(C,w2)=0.975 R²=0.953 residual=0.216\n\rCompounds:  79%|███████▉  | 15/19 [00:08<00:02,  1.67it/s]  door handle          | cos(C,w1)=0.949 cos(C,w2)=0.976 R²=0.958 residual=0.206\n\rCompounds:  84%|████████▍ | 16/19 [00:09<00:01,  1.70it/s]  Skipping blueberry: multi-token constituent\n\rCompounds:  95%|█████████▍| 18/19 [00:09<00:00,  2.24it/s]\rCompounds: 100%|██████████| 19/19 [00:10<00:00,  2.13it/s]\rCompounds: 100%|██████████| 19/19 [00:10<00:00,  1.86it/s]\nSaved: /data/hypogenicai/workspaces/llm-washing-machine-claude/results/plots/exp2_residual_directions.png\n\n======================================================================\nEXPERIMENT 3: Layer-wise Probing for Compound Concept Emergence\n======================================================================\n\rCollecting activations:   0%|          | 0/19 [00:00<?, ?it/s]\rCollecting activations:   5%|▌         | 1/19 [00:00<00:06,  2.66it/s]\rCollecting activations:  11%|█         | 2/19 [00:00<00:06,  2.72it/s]\rCollecting activations:  16%|█▌        | 3/19 [00:01<00:05,  2.72it/s]\rCollecting activations:  21%|██        | 4/19 [00:01<00:05,  2.73it/s]\rCollecting activations:  26%|██▋       | 5/19 [00:01<00:05,  2.74it/s]\rCollecting activations:  32%|███▏      | 6/19 [00:02<00:05,  2.31it/s]\rCollecting activations:  37%|███▋      | 7/19 [00:02<00:04,  2.44it/s]\rCollecting activations:  42%|████▏     | 8/19 [00:03<00:04,  2.53it/s]\rCollecting activations:  53%|█████▎    | 10/19 [00:03<00:02,  3.40it/s]\rCollecting activations:  58%|█████▊    | 11/19 [00:03<00:02,  3.20it/s]\rCollecting activations:  63%|██████▎   | 12/19 [00:04<00:02,  3.05it/s]\rCollecting activations:  68%|██████▊   | 13/19 [00:04<00:02,  2.59it/s]\rCollecting activations:  74%|███████▎  | 14/19 [00:05<00:01,  2.62it/s]\rCollecting activations:  79%|███████▉  | 15/19 [00:05<00:01,  2.64it/s]\rCollecting activations:  84%|████████▍ | 16/19 [00:05<00:01,  2.66it/s]\rCollecting activations:  95%|█████████▍| 18/19 [00:06<00:00,  3.45it/s]\rCollecting activations: 100%|██████████| 19/19 [00:06<00:00,  2.76it/s]\rCollecting activations: 100%|██████████| 19/19 [00:06<00:00,  2.78it/s]\n\nCollected 120 compound samples, 136 control samples\nNumber of unique word1 labels: 31\n\nProbe 1: Word1 Identity Prediction (Token Erasure)\n  Layer  0: accuracy = 1.000 ± 0.000\n  Layer  1: accuracy = 1.000 ± 0.000\n  Layer  2: accuracy = 1.000 ± 0.000\n  Layer  3: accuracy = 1.000 ± 0.000\n  Layer  4: accuracy = 1.000 ± 0.000\n  Layer  5: accuracy = 1.000 ± 0.000\n  Layer  6: accuracy = 1.000 ± 0.000\n  Layer  7: accuracy = 1.000 ± 0.000\n  Layer  8: accuracy = 1.000 ± 0.000\n  Layer  9: accuracy = 1.000 ± 0.000\n  Layer 10: accuracy = 1.000 ± 0.000\n  Layer 11: accuracy = 1.000 ± 0.000\n\nProbe 2: Compound vs. Control Context Classification\n  Layer  0: accuracy = 0.706 ± 0.177\n  Layer  1: accuracy = 0.698 ± 0.223\n  Layer  2: accuracy = 0.902 ± 0.122\n  Layer  3: accuracy = 0.859 ± 0.138\n  Layer  4: accuracy = 0.894 ± 0.111\n  Layer  5: accuracy = 0.878 ± 0.117\n  Layer  6: accuracy = 0.902 ± 0.114\n  Layer  7: accuracy = 0.918 ± 0.096\n  Layer  8: accuracy = 0.922 ± 0.099\n  Layer  9: accuracy = 0.906 ± 0.086\n  Layer 10: accuracy = 0.890 ± 0.105\n  Layer 11: accuracy = 0.851 ± 0.157\n\nProbe 3: Compound vs. Control by Compositionality Level\nSaved: /data/hypogenicai/workspaces/llm-washing-machine-claude/results/plots/exp3_layerwise_probing.png\n\n======================================================================\nEXPERIMENT 4: Attention Pattern Analysis\n======================================================================\n\rAttention analysis:   0%|          | 0/19 [00:00<?, ?it/s]  washing machine      | max attn diff at layer 0: 0.1387\n\rAttention analysis:   5%|▌         | 1/19 [00:00<00:07,  2.51it/s]  coffee table         | max attn diff at layer 0: 0.0515\n\rAttention analysis:  11%|█         | 2/19 [00:00<00:06,  2.62it/s]  swimming pool        | max attn diff at layer 0: 0.1164\n\rAttention analysis:  16%|█▌        | 3/19 [00:01<00:06,  2.66it/s]  parking lot          | max attn diff at layer 0: 0.0860\n\rAttention analysis:  21%|██        | 4/19 [00:01<00:05,  2.67it/s]  hot dog              | max attn diff at layer 0: 0.1232\n\rAttention analysis:  26%|██▋       | 5/19 [00:02<00:06,  2.18it/s]  shooting star        | max attn diff at layer 3: 0.1073\n\rAttention analysis:  32%|███▏      | 6/19 [00:02<00:05,  2.33it/s]  living room          | max attn diff at layer 0: 0.0848\n\rAttention analysis:  37%|███▋      | 7/19 [00:02<00:04,  2.44it/s]  driving license      | max attn diff at layer 0: 0.1250\n\rAttention analysis:  42%|████▏     | 8/19 [00:03<00:04,  2.51it/s]  brick house          | max attn diff at layer 3: 0.0755\n\rAttention analysis:  53%|█████▎    | 10/19 [00:03<00:02,  3.37it/s]  mountain cabin       | max attn diff at layer 0: 0.0632\n\rAttention analysis:  58%|█████▊    | 11/19 [00:03<00:02,  3.16it/s]  garden hose          | max attn diff at layer 0: 0.0518\n\rAttention analysis:  63%|██████▎   | 12/19 [00:04<00:02,  2.67it/s]  water bottle         | max attn diff at layer 0: 0.0478\n\rAttention analysis:  68%|██████▊   | 13/19 [00:04<00:02,  2.67it/s]  steel bridge         | max attn diff at layer 0: 0.0765\n\rAttention analysis:  74%|███████▎  | 14/19 [00:05<00:01,  2.68it/s]  chocolate cake       | max attn diff at layer 0: 0.1040\n\rAttention analysis:  79%|███████▉  | 15/19 [00:05<00:01,  2.68it/s]  door handle          | max attn diff at layer 4: 0.0458\n\rAttention analysis:  84%|████████▍ | 16/19 [00:06<00:01,  2.69it/s]  snowman              | max attn diff at layer 2: -0.2757\n\rAttention analysis:  95%|█████████▍| 18/19 [00:06<00:00,  3.08it/s]  sunflower            | max attn diff at layer 2: -0.2729\n\rAttention analysis: 100%|██████████| 19/19 [00:06<00:00,  2.98it/s]\rAttention analysis: 100%|██████████| 19/19 [00:06<00:00,  2.75it/s]\nSaved: /data/hypogenicai/workspaces/llm-washing-machine-claude/results/plots/exp4_attention_patterns.png\n\n\n======================================================================\nALL EXPERIMENTS COMPLETE\n======================================================================\n\nResults saved to: /data/hypogenicai/workspaces/llm-washing-machine-claude/results\nPlots saved to: /data/hypogenicai/workspaces/llm-washing-machine-claude/results/plots","is_error":false}]},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"fdf9b434-19b7-45e0-ae7f-94b8c9f5e09b","tool_use_result":{"stdout":"======================================================================\nWHERE IS 'WASHING MACHINE' STORED IN LLMs?\n======================================================================\n\nDevice: cuda:0\nSeed: 42\nNumber of compounds: 19\nNumber of templates: 8\n\nPython: 3.12.2 | packaged by Anaconda, Inc. | (main, Feb 27 2024, 17:35:02) [GCC 11.2.0]\nPyTorch: 2.10.0+cu128\nTransformerLens: unknown\nGPU: NVIDIA GeForce RTX 3090\nGPU Memory: 25.3 GB\nLoading model: gpt2\n`torch_dtype` is deprecated! Use `dtype` instead!\nLoaded pretrained model gpt2 into HookedTransformer\nModel loaded: 12 layers, d_model=768\n\n\n======================================================================\nRUNNING ALL EXPERIMENTS\n======================================================================\n\n======================================================================\nEXPERIMENT 1: Next-Token Prediction Analysis\n======================================================================\n\rCompounds:   0%|          | 0/19 [00:00<?, ?it/s]  washing machine      | P(w2|w1)=0.8270 rank=1 | P(w2|ctrl)=0.0002 rank=924 | boost=4963.4x | top5: ['machine', 'machines', '-', 'ton', 'of']\n\rCompounds:   5%|▌         | 1/19 [00:00<00:08,  2.20it/s]  coffee table         | P(w2|w1)=0.0632 rank=4 | P(w2|ctrl)=0.0091 rank=14 | boost=6.9x | top5: ['shop', '-', 'is', 'maker', 'industry']\n\rCompounds:  11%|█         | 2/19 [00:00<00:05,  2.88it/s]  swimming pool        | P(w2|w1)=0.6258 rank=1 | P(w2|ctrl)=0.0011 rank=125 | boost=549.4x | top5: ['pool', 'pools', 'team', 'hole', '-']\n\rCompounds:  16%|█▌        | 3/19 [00:00<00:04,  3.21it/s]  parking lot          | P(w2|w1)=0.3215 rank=1 | P(w2|ctrl)=0.0116 rank=14 | boost=27.7x | top5: ['lot', 'garage', 'meter', 'lots', 'space']\n\rCompounds:  21%|██        | 4/19 [00:01<00:04,  3.36it/s]  hot dog              | P(w2|w1)=0.0973 rank=4 | P(w2|ctrl)=0.0022 rank=142 | boost=44.7x | top5: ['new', 'topic', 'dog', '-', 'spot']\n\rCompounds:  26%|██▋       | 5/19 [00:01<00:04,  3.48it/s]  shooting star        | P(w2|w1)=0.0307 rank=90 | P(w2|ctrl)=0.0103 rank=18 | boost=3.0x | top5: ['of', 'death', 'at', 'was', 'in']\n\rCompounds:  32%|███▏      | 6/19 [00:01<00:03,  3.55it/s]  living room          | P(w2|w1)=0.2611 rank=2 | P(w2|ctrl)=0.0016 rank=98 | boost=159.9x | top5: ['room', '-', 'wage', 'world', 'rooms']\n\rCompounds:  37%|███▋      | 7/19 [00:02<00:03,  3.57it/s]  driving license      | P(w2|w1)=0.0364 rank=118 | P(w2|ctrl)=0.0002 rank=1325 | boost=220.7x | top5: ['force', 'forces', 'seat', '-', 'season']\n\rCompounds:  42%|████▏     | 8/19 [00:02<00:03,  3.62it/s]  guinea pig           | P(w2|w1)=0.8326 rank=1 | P(w2|ctrl)=0.0001 rank=1755 | boost=7233.3x | top5: ['pig', 'pigs', 'worm', '-', 'p']\n\rCompounds:  47%|████▋     | 9/19 [00:02<00:02,  3.65it/s]  brick house          | P(w2|w1)=0.0273 rank=11 | P(w2|ctrl)=0.0047 rank=62 | boost=5.8x | top5: ['-', 'wall', 'and', 'layer', 'walls']\n\rCompounds:  53%|█████▎    | 10/19 [00:02<00:02,  3.68it/s]  mountain cabin       | P(w2|w1)=0.0040 rank=149 | P(w2|ctrl)=0.0014 rank=305 | boost=2.9x | top5: ['of', 'is', 'lion', 'range', 'bike']\n\rCompounds:  58%|█████▊    | 11/19 [00:03<00:02,  3.69it/s]  garden hose          | P(w2|w1)=0.0235 rank=12 | P(w2|ctrl)=0.0001 rank=2101 | boost=200.4x | top5: ['is', 'of', 'was', '-', 'has']\n\rCompounds:  63%|██████▎   | 12/19 [00:03<00:01,  3.68it/s]  water bottle         | P(w2|w1)=0.0656 rank=17 | P(w2|ctrl)=0.0176 rank=11 | boost=3.7x | top5: ['is', 'in', 'quality', 'level', 'supply']\n\rCompounds:  68%|██████▊   | 13/19 [00:03<00:01,  3.70it/s]  steel bridge         | P(w2|w1)=0.0046 rank=53 | P(w2|ctrl)=0.0004 rank=992 | boost=12.6x | top5: ['-', 'and', 'is', 'head', 'was']\n\rCompounds:  74%|███████▎  | 14/19 [00:03<00:01,  3.71it/s]  chocolate cake       | P(w2|w1)=0.0356 rank=5 | P(w2|ctrl)=0.0003 rank=978 | boost=140.4x | top5: ['chip', '-', 'bar', 'is', 'and']\n\rCompounds:  79%|███████▉  | 15/19 [00:04<00:01,  3.72it/s]  door handle          | P(w2|w1)=0.0068 rank=42 | P(w2|ctrl)=0.0007 rank=376 | boost=9.2x | top5: ['to', 'is', 'bell', 'was', 'of']\n\rCompounds:  84%|████████▍ | 16/19 [00:04<00:00,  3.72it/s]  Skipping blueberry: word2 'berry' is multi-token\n  snowman              | P(w2|w1)=0.0038 rank=63 | P(w2|ctrl)=0.0427 rank=7 | boost=0.1x | top5: ['is', '-', 'was', 'storm', 'has']\n\rCompounds:  95%|█████████▍| 18/19 [00:04<00:00,  4.82it/s]  sunflower            | P(w2|w1)=0.0001 rank=1673 | P(w2|ctrl)=0.0004 rank=706 | boost=0.3x | top5: ['is', 'was', 'has', \"'s\", 'rises']\n\rCompounds: 100%|██████████| 19/19 [00:05<00:00,  4.50it/s]\rCompounds: 100%|██████████| 19/19 [00:05<00:00,  3.77it/s]\nSaved: /data/hypogenicai/workspaces/llm-washing-machine-claude/results/plots/exp1_next_token_prediction.png\n\n======================================================================\nEXPERIMENT 2: Residual Stream Direction Analysis\n======================================================================\n\rCompounds:   0%|          | 0/19 [00:00<?, ?it/s]  washing machine      | cos(C,w1)=0.907 cos(C,w2)=0.951 R²=0.917 residual=0.288\n\rCompounds:   5%|▌         | 1/19 [00:00<00:09,  1.80it/s]  coffee table         | cos(C,w1)=0.934 cos(C,w2)=0.962 R²=0.938 residual=0.249\n\rCompounds:  11%|█         | 2/19 [00:01<00:09,  1.81it/s]  swimming pool        | cos(C,w1)=0.932 cos(C,w2)=0.957 R²=0.924 residual=0.276\n\rCompounds:  16%|█▌        | 3/19 [00:01<00:10,  1.52it/s]  parking lot          | cos(C,w1)=0.936 cos(C,w2)=0.934 R²=0.922 residual=0.280\n\rCompounds:  21%|██        | 4/19 [00:02<00:09,  1.62it/s]  hot dog              | cos(C,w1)=0.897 cos(C,w2)=0.934 R²=0.888 residual=0.335\n\rCompounds:  26%|██▋       | 5/19 [00:02<00:08,  1.69it/s]  shooting star        | cos(C,w1)=0.929 cos(C,w2)=0.960 R²=0.944 residual=0.236\n\rCompounds:  32%|███▏      | 6/19 [00:03<00:07,  1.72it/s]  living room          | cos(C,w1)=0.925 cos(C,w2)=0.958 R²=0.933 residual=0.259\n\rCompounds:  37%|███▋      | 7/19 [00:04<00:07,  1.56it/s]  driving license      | cos(C,w1)=0.908 cos(C,w2)=0.955 R²=0.924 residual=0.276\n\rCompounds:  42%|████▏     | 8/19 [00:04<00:06,  1.63it/s]  Skipping guinea pig: multi-token constituent\n  brick house          | cos(C,w1)=0.933 cos(C,w2)=0.965 R²=0.939 residual=0.247\n\rCompounds:  53%|█████▎    | 10/19 [00:05<00:04,  2.21it/s]  mountain cabin       | cos(C,w1)=0.937 cos(C,w2)=0.975 R²=0.956 residual=0.209\n\rCompounds:  58%|█████▊    | 11/19 [00:06<00:04,  1.90it/s]  garden hose          | cos(C,w1)=0.933 cos(C,w2)=0.979 R²=0.962 residual=0.196\n\rCompounds:  63%|██████▎   | 12/19 [00:06<00:03,  1.88it/s]  water bottle         | cos(C,w1)=0.924 cos(C,w2)=0.963 R²=0.931 residual=0.262\n\rCompounds:  68%|██████▊   | 13/19 [00:07<00:03,  1.86it/s]  steel bridge         | cos(C,w1)=0.924 cos(C,w2)=0.982 R²=0.965 residual=0.188\n\rCompounds:  74%|███████▎  | 14/19 [00:07<00:02,  1.84it/s]  chocolate cake       | cos(C,w1)=0.944 cos(C,w2)=0.975 R²=0.953 residual=0.216\n\rCompounds:  79%|███████▉  | 15/19 [00:08<00:02,  1.67it/s]  door handle          | cos(C,w1)=0.949 cos(C,w2)=0.976 R²=0.958 residual=0.206\n\rCompounds:  84%|████████▍ | 16/19 [00:09<00:01,  1.70it/s]  Skipping blueberry: multi-token constituent\n\rCompounds:  95%|█████████▍| 18/19 [00:09<00:00,  2.24it/s]\rCompounds: 100%|██████████| 19/19 [00:10<00:00,  2.13it/s]\rCompounds: 100%|██████████| 19/19 [00:10<00:00,  1.86it/s]\nSaved: /data/hypogenicai/workspaces/llm-washing-machine-claude/results/plots/exp2_residual_directions.png\n\n======================================================================\nEXPERIMENT 3: Layer-wise Probing for Compound Concept Emergence\n======================================================================\n\rCollecting activations:   0%|          | 0/19 [00:00<?, ?it/s]\rCollecting activations:   5%|▌         | 1/19 [00:00<00:06,  2.66it/s]\rCollecting activations:  11%|█         | 2/19 [00:00<00:06,  2.72it/s]\rCollecting activations:  16%|█▌        | 3/19 [00:01<00:05,  2.72it/s]\rCollecting activations:  21%|██        | 4/19 [00:01<00:05,  2.73it/s]\rCollecting activations:  26%|██▋       | 5/19 [00:01<00:05,  2.74it/s]\rCollecting activations:  32%|███▏      | 6/19 [00:02<00:05,  2.31it/s]\rCollecting activations:  37%|███▋      | 7/19 [00:02<00:04,  2.44it/s]\rCollecting activations:  42%|████▏     | 8/19 [00:03<00:04,  2.53it/s]\rCollecting activations:  53%|█████▎    | 10/19 [00:03<00:02,  3.40it/s]\rCollecting activations:  58%|█████▊    | 11/19 [00:03<00:02,  3.20it/s]\rCollecting activations:  63%|██████▎   | 12/19 [00:04<00:02,  3.05it/s]\rCollecting activations:  68%|██████▊   | 13/19 [00:04<00:02,  2.59it/s]\rCollecting activations:  74%|███████▎  | 14/19 [00:05<00:01,  2.62it/s]\rCollecting activations:  79%|███████▉  | 15/19 [00:05<00:01,  2.64it/s]\rCollecting activations:  84%|████████▍ | 16/19 [00:05<00:01,  2.66it/s]\rCollecting activations:  95%|█████████▍| 18/19 [00:06<00:00,  3.45it/s]\rCollecting activations: 100%|██████████| 19/19 [00:06<00:00,  2.76it/s]\rCollecting activations: 100%|██████████| 19/19 [00:06<00:00,  2.78it/s]\n\nCollected 120 compound samples, 136 control samples\nNumber of unique word1 labels: 31\n\nProbe 1: Word1 Identity Prediction (Token Erasure)\n  Layer  0: accuracy = 1.000 ± 0.000\n  Layer  1: accuracy = 1.000 ± 0.000\n  Layer  2: accuracy = 1.000 ± 0.000\n  Layer  3: accuracy = 1.000 ± 0.000\n  Layer  4: accuracy = 1.000 ± 0.000\n  Layer  5: accuracy = 1.000 ± 0.000\n  Layer  6: accuracy = 1.000 ± 0.000\n  Layer  7: accuracy = 1.000 ± 0.000\n  Layer  8: accuracy = 1.000 ± 0.000\n  Layer  9: accuracy = 1.000 ± 0.000\n  Layer 10: accuracy = 1.000 ± 0.000\n  Layer 11: accuracy = 1.000 ± 0.000\n\nProbe 2: Compound vs. Control Context Classification\n  Layer  0: accuracy = 0.706 ± 0.177\n  Layer  1: accuracy = 0.698 ± 0.223\n  Layer  2: accuracy = 0.902 ± 0.122\n  Layer  3: accuracy = 0.859 ± 0.138\n  Layer  4: accuracy = 0.894 ± 0.111\n  Layer  5: accuracy = 0.878 ± 0.117\n  Layer  6: accuracy = 0.902 ± 0.114\n  Layer  7: accuracy = 0.918 ± 0.096\n  Layer  8: accuracy = 0.922 ± 0.099\n  Layer  9: accuracy = 0.906 ± 0.086\n  Layer 10: accuracy = 0.890 ± 0.105\n  Layer 11: accuracy = 0.851 ± 0.157\n\nProbe 3: Compound vs. Control by Compositionality Level\nSaved: /data/hypogenicai/workspaces/llm-washing-machine-claude/results/plots/exp3_layerwise_probing.png\n\n======================================================================\nEXPERIMENT 4: Attention Pattern Analysis\n======================================================================\n\rAttention analysis:   0%|          | 0/19 [00:00<?, ?it/s]  washing machine      | max attn diff at layer 0: 0.1387\n\rAttention analysis:   5%|▌         | 1/19 [00:00<00:07,  2.51it/s]  coffee table         | max attn diff at layer 0: 0.0515\n\rAttention analysis:  11%|█         | 2/19 [00:00<00:06,  2.62it/s]  swimming pool        | max attn diff at layer 0: 0.1164\n\rAttention analysis:  16%|█▌        | 3/19 [00:01<00:06,  2.66it/s]  parking lot          | max attn diff at layer 0: 0.0860\n\rAttention analysis:  21%|██        | 4/19 [00:01<00:05,  2.67it/s]  hot dog              | max attn diff at layer 0: 0.1232\n\rAttention analysis:  26%|██▋       | 5/19 [00:02<00:06,  2.18it/s]  shooting star        | max attn diff at layer 3: 0.1073\n\rAttention analysis:  32%|███▏      | 6/19 [00:02<00:05,  2.33it/s]  living room          | max attn diff at layer 0: 0.0848\n\rAttention analysis:  37%|███▋      | 7/19 [00:02<00:04,  2.44it/s]  driving license      | max attn diff at layer 0: 0.1250\n\rAttention analysis:  42%|████▏     | 8/19 [00:03<00:04,  2.51it/s]  brick house          | max attn diff at layer 3: 0.0755\n\rAttention analysis:  53%|█████▎    | 10/19 [00:03<00:02,  3.37it/s]  mountain cabin       | max attn diff at layer 0: 0.0632\n\rAttention analysis:  58%|█████▊    | 11/19 [00:03<00:02,  3.16it/s]  garden hose          | max attn diff at layer 0: 0.0518\n\rAttention analysis:  63%|██████▎   | 12/19 [00:04<00:02,  2.67it/s]  water bottle         | max attn diff at layer 0: 0.0478\n\rAttention analysis:  68%|██████▊   | 13/19 [00:04<00:02,  2.67it/s]  steel bridge         | max attn diff at layer 0: 0.0765\n\rAttention analysis:  74%|███████▎  | 14/19 [00:05<00:01,  2.68it/s]  chocolate cake       | max attn diff at layer 0: 0.1040\n\rAttention analysis:  79%|███████▉  | 15/19 [00:05<00:01,  2.68it/s]  door handle          | max attn diff at layer 4: 0.0458\n\rAttention analysis:  84%|████████▍ | 16/19 [00:06<00:01,  2.69it/s]  snowman              | max attn diff at layer 2: -0.2757\n\rAttention analysis:  95%|█████████▍| 18/19 [00:06<00:00,  3.08it/s]  sunflower            | max attn diff at layer 2: -0.2729\n\rAttention analysis: 100%|██████████| 19/19 [00:06<00:00,  2.98it/s]\rAttention analysis: 100%|██████████| 19/19 [00:06<00:00,  2.75it/s]\nSaved: /data/hypogenicai/workspaces/llm-washing-machine-claude/results/plots/exp4_attention_patterns.png\n\n\n======================================================================\nALL EXPERIMENTS COMPLETE\n======================================================================\n\nResults saved to: /data/hypogenicai/workspaces/llm-washing-machine-claude/results\nPlots saved to: /data/hypogenicai/workspaces/llm-washing-machine-claude/results/plots","stderr":"","interrupted":false,"isImage":false}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_011FtjYGtAqT17dWS2MBGPS3","type":"message","role":"assistant","content":[{"type":"text","text":"All 4 experiments completed successfully. The results are very interesting. Let me now run a deeper analysis script to extract statistical tests and create additional visualizations."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":6137,"cache_read_input_tokens":70071,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":6137},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"9e9c13c2-1dfb-4034-bc0c-ecf0babbf5a1"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_011FtjYGtAqT17dWS2MBGPS3","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_013LtnNshUwfJ4kKsUpKUYVA","name":"TodoWrite","input":{"todos":[{"content":"Review pre-gathered resources (literature_review.md, resources.md, papers/, datasets/, code/)","status":"completed","activeForm":"Reviewing pre-gathered resources"},{"content":"Phase 0 & 1: Motivation, novelty assessment, and research plan (planning.md)","status":"completed","activeForm":"Writing motivation assessment and research plan"},{"content":"Phase 2: Environment & data setup","status":"completed","activeForm":"Setting up environment and data"},{"content":"Phase 3: Implementation - write experiment code","status":"completed","activeForm":"Implementing experiment code"},{"content":"Phase 4: Run experiments","status":"completed","activeForm":"Running experiments"},{"content":"Phase 5: Analysis - statistical analysis and visualizations","status":"in_progress","activeForm":"Analyzing results"},{"content":"Phase 6: Final documentation (REPORT.md, README.md)","status":"pending","activeForm":"Writing final documentation"}]}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":6137,"cache_read_input_tokens":70071,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":6137},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"91f5a80f-400d-4301-8062-720720500630"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_013LtnNshUwfJ4kKsUpKUYVA","type":"tool_result","content":"Todos have been modified successfully. Ensure that you continue to use the todo list to track your progress. Please proceed with the current tasks if applicable"}]},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"f0d1a2c2-c3fb-43d2-b74f-424bbd6a1d2c","tool_use_result":{"oldTodos":[{"content":"Review pre-gathered resources (literature_review.md, resources.md, papers/, datasets/, code/)","status":"completed","activeForm":"Reviewing pre-gathered resources"},{"content":"Phase 0 & 1: Motivation, novelty assessment, and research plan (planning.md)","status":"completed","activeForm":"Writing motivation assessment and research plan"},{"content":"Phase 2: Environment & data setup","status":"completed","activeForm":"Setting up environment and data"},{"content":"Phase 3: Implementation - write experiment code","status":"completed","activeForm":"Implementing experiment code"},{"content":"Phase 4: Run experiments","status":"in_progress","activeForm":"Running experiments"},{"content":"Phase 5: Analysis - statistical analysis and visualizations","status":"pending","activeForm":"Analyzing results"},{"content":"Phase 6: Final documentation (REPORT.md, README.md)","status":"pending","activeForm":"Writing final documentation"}],"newTodos":[{"content":"Review pre-gathered resources (literature_review.md, resources.md, papers/, datasets/, code/)","status":"completed","activeForm":"Reviewing pre-gathered resources"},{"content":"Phase 0 & 1: Motivation, novelty assessment, and research plan (planning.md)","status":"completed","activeForm":"Writing motivation assessment and research plan"},{"content":"Phase 2: Environment & data setup","status":"completed","activeForm":"Setting up environment and data"},{"content":"Phase 3: Implementation - write experiment code","status":"completed","activeForm":"Implementing experiment code"},{"content":"Phase 4: Run experiments","status":"completed","activeForm":"Running experiments"},{"content":"Phase 5: Analysis - statistical analysis and visualizations","status":"in_progress","activeForm":"Analyzing results"},{"content":"Phase 6: Final documentation (REPORT.md, README.md)","status":"pending","activeForm":"Writing final documentation"}]}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01S5vNEyV36HX5SLW7MbQLx6","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01K5QXSuexY6VZDxnCJ6UVqh","name":"Write","input":{"file_path":"/data/hypogenicai/workspaces/llm-washing-machine-claude/src/analysis.py","content":"\"\"\"\nStatistical analysis and additional visualizations for the compound concept experiments.\n\"\"\"\n\nimport json\nimport numpy as np\nfrom scipy import stats\nfrom pathlib import Path\nimport matplotlib\nmatplotlib.use('Agg')\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nRESULTS_DIR = Path(\"/data/hypogenicai/workspaces/llm-washing-machine-claude/results\")\nPLOTS_DIR = RESULTS_DIR / \"plots\"\n\n\ndef analyze_experiment1():\n    \"\"\"Deep analysis of next-token prediction results.\"\"\"\n    print(\"=\"*70)\n    print(\"EXPERIMENT 1: Statistical Analysis\")\n    print(\"=\"*70)\n\n    with open(RESULTS_DIR / \"exp1_next_token.json\") as f:\n        results = json.load(f)\n\n    compounds = [r[\"compound\"] for r in results]\n    comp_ratings = np.array([r[\"compositionality\"] for r in results])\n    p_compound = np.array([r[\"p_word2_compound_mean\"] for r in results])\n    p_control = np.array([r[\"p_word2_control_mean\"] for r in results])\n    boost_ratios = np.array([r[\"boost_ratio\"] for r in results])\n    ranks_compound = np.array([r[\"rank_compound_mean\"] for r in results])\n    ranks_control = np.array([r[\"rank_control_mean\"] for r in results])\n\n    print(f\"\\n{'Compound':<22} {'P(w2|w1)':<12} {'P(w2|ctrl)':<12} {'Boost':<10} {'Rank(cmp)':<12} {'Rank(ctrl)':<12}\")\n    print(\"-\" * 80)\n    for r in sorted(results, key=lambda x: x[\"boost_ratio\"], reverse=True):\n        print(f\"{r['compound']:<22} {r['p_word2_compound_mean']:<12.4f} \"\n              f\"{r['p_word2_control_mean']:<12.4f} {r['boost_ratio']:<10.1f} \"\n              f\"{r['rank_compound_mean']:<12.0f} {r['rank_control_mean']:<12.0f}\")\n\n    # Statistical tests\n    print(\"\\n--- Statistical Tests ---\")\n\n    # Paired Wilcoxon: compound probs vs control probs\n    stat, p_val = stats.wilcoxon(p_compound, p_control, alternative='greater')\n    print(f\"Wilcoxon (P(w2|w1) > P(w2|ctrl)): W={stat:.1f}, p={p_val:.2e}\")\n\n    # Spearman: compositionality vs boost ratio\n    r_boost, p_boost = stats.spearmanr(comp_ratings, boost_ratios)\n    print(f\"Spearman (compositionality vs boost): r={r_boost:.3f}, p={p_boost:.3f}\")\n\n    # Spearman: compositionality vs rank\n    r_rank, p_rank = stats.spearmanr(comp_ratings, ranks_compound)\n    print(f\"Spearman (compositionality vs rank): r={r_rank:.3f}, p={p_rank:.3f}\")\n\n    # Log boost for better visualization\n    log_boost = np.log10(boost_ratios + 1)\n    r_log, p_log = stats.spearmanr(comp_ratings, log_boost)\n    print(f\"Spearman (compositionality vs log10(boost)): r={r_log:.3f}, p={p_log:.3f}\")\n\n    # Group by compositionality level\n    print(\"\\n--- By Compositionality Level ---\")\n    for level in sorted(set(comp_ratings)):\n        mask = comp_ratings == level\n        n = mask.sum()\n        mean_boost = boost_ratios[mask].mean()\n        mean_p = p_compound[mask].mean()\n        mean_rank = ranks_compound[mask].mean()\n        print(f\"  Level {level} (n={n}): mean boost={mean_boost:.1f}x, \"\n              f\"mean P(w2|w1)={mean_p:.4f}, mean rank={mean_rank:.0f}\")\n\n    # Effect size: Cohen's d for compound vs control probabilities\n    diff = p_compound - p_control\n    cohens_d = diff.mean() / diff.std()\n    print(f\"\\nCohen's d (compound vs control probs): d={cohens_d:.2f}\")\n\n    # Bootstrap CI for mean boost ratio\n    n_bootstrap = 10000\n    boot_means = []\n    for _ in range(n_bootstrap):\n        idx = np.random.choice(len(boost_ratios), len(boost_ratios), replace=True)\n        boot_means.append(np.median(boost_ratios[idx]))\n    ci_lower = np.percentile(boot_means, 2.5)\n    ci_upper = np.percentile(boot_means, 97.5)\n    print(f\"Median boost ratio: {np.median(boost_ratios):.1f}x (95% CI: [{ci_lower:.1f}, {ci_upper:.1f}])\")\n\n    # Identify compounds where word2 is in top-1 after word1\n    top1 = [r for r in results if r[\"rank_compound_mean\"] <= 1.5]\n    print(f\"\\nCompounds where word2 is rank 1 after word1: {len(top1)}/{len(results)}\")\n    for r in top1:\n        print(f\"  {r['compound']}: P={r['p_word2_compound_mean']:.4f}\")\n\n    # Create enhanced figure\n    fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n\n    # Top-left: probability comparison\n    ax = axes[0, 0]\n    x = np.arange(len(compounds))\n    sorted_idx = np.argsort(p_compound)[::-1]\n    bar_width = 0.35\n    bars1 = ax.bar(x - bar_width/2, [p_compound[i] for i in sorted_idx],\n                   bar_width, label='P(w2 | word1)', color='steelblue')\n    bars2 = ax.bar(x + bar_width/2, [p_control[i] for i in sorted_idx],\n                   bar_width, label='P(w2 | control)', color='coral')\n    ax.set_xticks(x)\n    ax.set_xticklabels([compounds[i] for i in sorted_idx], rotation=45, ha='right', fontsize=7)\n    ax.set_ylabel(\"P(word2)\")\n    ax.set_title(\"Next-Token Probability: Compound Word1 vs. Control Word\")\n    ax.legend()\n\n    # Top-right: rank comparison\n    ax = axes[0, 1]\n    sorted_idx_rank = np.argsort(ranks_compound)\n    ax.barh(x, [ranks_compound[i] for i in sorted_idx_rank],\n            bar_width*2, label='Rank after word1', color='steelblue')\n    ax.set_yticks(x)\n    ax.set_yticklabels([compounds[i] for i in sorted_idx_rank], fontsize=7)\n    ax.set_xlabel(\"Rank of word2\")\n    ax.set_title(\"Rank of Word2 After Seeing Word1\")\n    ax.set_xscale('log')\n    ax.invert_yaxis()\n\n    # Bottom-left: log boost ratio by compositionality\n    ax = axes[1, 0]\n    colors_map = {1: '#e74c3c', 2: '#e67e22', 3: '#f1c40f', 4: '#2ecc71', 5: '#27ae60'}\n    for i, r in enumerate(results):\n        ax.scatter(r['compositionality'], np.log10(r['boost_ratio'] + 1),\n                  c=colors_map.get(r['compositionality'], 'gray'), s=100, edgecolors='k', zorder=5)\n        ax.annotate(r['compound'], (r['compositionality'], np.log10(r['boost_ratio'] + 1)),\n                   fontsize=6, ha='left', va='bottom', rotation=10)\n    ax.set_xlabel(\"Compositionality Rating (1=idiomatic, 5=compositional)\")\n    ax.set_ylabel(\"log10(Boost Ratio + 1)\")\n    ax.set_title(f\"Compositionality vs. Prediction Boost\\n(Spearman r={r_log:.3f}, p={p_log:.3f})\")\n\n    # Bottom-right: Top-5 predictions for key compounds\n    ax = axes[1, 1]\n    key_compounds = [\"washing machine\", \"hot dog\", \"coffee table\", \"guinea pig\", \"shooting star\", \"mountain cabin\"]\n    y_pos = 0\n    for r in results:\n        if r[\"compound\"] in key_compounds:\n            top5_str = \", \".join([f\"{t[0]}({t[1]:.3f})\" for t in r[\"top5_after_word1\"][:5]])\n            ax.text(0.02, y_pos, f\"{r['compound']}:\", fontsize=9, fontweight='bold',\n                   transform=ax.transAxes, va='top')\n            ax.text(0.02, y_pos - 0.04, f\"  Top-5 after '{r['word1']}': {top5_str}\",\n                   fontsize=7, transform=ax.transAxes, va='top')\n            y_pos -= 0.12\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.axis('off')\n    ax.set_title(\"Top-5 Predictions After Word1 (Selected Compounds)\")\n\n    plt.tight_layout()\n    plt.savefig(PLOTS_DIR / \"exp1_detailed_analysis.png\", dpi=150, bbox_inches='tight')\n    plt.close()\n    print(f\"\\nSaved: {PLOTS_DIR / 'exp1_detailed_analysis.png'}\")\n\n    return {\n        \"wilcoxon_stat\": float(stat),\n        \"wilcoxon_p\": float(p_val),\n        \"spearman_boost_r\": float(r_boost),\n        \"spearman_boost_p\": float(p_boost),\n        \"spearman_logboost_r\": float(r_log),\n        \"spearman_logboost_p\": float(p_log),\n        \"cohens_d\": float(cohens_d),\n        \"median_boost\": float(np.median(boost_ratios)),\n        \"median_boost_ci\": [float(ci_lower), float(ci_upper)],\n        \"n_top1\": len(top1),\n    }\n\n\ndef analyze_experiment2():\n    \"\"\"Deep analysis of residual stream direction results.\"\"\"\n    print(\"\\n\" + \"=\"*70)\n    print(\"EXPERIMENT 2: Statistical Analysis\")\n    print(\"=\"*70)\n\n    with open(RESULTS_DIR / \"exp2_residual_directions.json\") as f:\n        results = json.load(f)\n\n    # Extract final layer metrics\n    final_r2 = []\n    final_sim_w1 = []\n    final_sim_w2 = []\n    final_residual = []\n    comps = []\n    names = []\n\n    for r in results:\n        last = r[\"layer_metrics\"][-1]\n        if last is None:\n            continue\n        final_r2.append(last[\"reconstruction_r2\"])\n        final_sim_w1.append(last[\"sim_compound_word1\"])\n        final_sim_w2.append(last[\"sim_compound_word2\"])\n        final_residual.append(last[\"residual_norm_ratio\"])\n        comps.append(r[\"compositionality\"])\n        names.append(r[\"compound\"])\n\n    final_r2 = np.array(final_r2)\n    final_sim_w1 = np.array(final_sim_w1)\n    final_sim_w2 = np.array(final_sim_w2)\n    final_residual = np.array(final_residual)\n    comps = np.array(comps)\n\n    print(f\"\\n{'Compound':<22} {'R²':<8} {'cos(C,w1)':<12} {'cos(C,w2)':<12} {'Residual':<10}\")\n    print(\"-\" * 64)\n    for i, name in enumerate(names):\n        print(f\"{name:<22} {final_r2[i]:<8.3f} {final_sim_w1[i]:<12.3f} \"\n              f\"{final_sim_w2[i]:<12.3f} {final_residual[i]:<10.3f}\")\n\n    print(f\"\\n--- Summary ---\")\n    print(f\"Mean R²: {final_r2.mean():.3f} ± {final_r2.std():.3f}\")\n    print(f\"Mean cos(C,w1): {final_sim_w1.mean():.3f} ± {final_sim_w1.std():.3f}\")\n    print(f\"Mean cos(C,w2): {final_sim_w2.mean():.3f} ± {final_sim_w2.std():.3f}\")\n    print(f\"Mean residual ratio: {final_residual.mean():.3f} ± {final_residual.std():.3f}\")\n\n    # Is R² significantly > 0? (one-sample t-test)\n    t_stat, p_val = stats.ttest_1samp(final_r2, 0)\n    print(f\"\\nt-test (R² > 0): t={t_stat:.2f}, p={p_val:.2e}\")\n\n    # Spearman: compositionality vs R²\n    r_r2, p_r2 = stats.spearmanr(comps, final_r2)\n    print(f\"Spearman (compositionality vs R²): r={r_r2:.3f}, p={p_r2:.3f}\")\n\n    # Spearman: compositionality vs residual\n    r_res, p_res = stats.spearmanr(comps, final_residual)\n    print(f\"Spearman (compositionality vs residual): r={r_res:.3f}, p={p_res:.3f}\")\n\n    # Layer-wise R² evolution\n    print(\"\\n--- Layer-wise R² Evolution ---\")\n    n_layers = 12\n    mean_r2_by_layer = np.zeros(n_layers)\n    std_r2_by_layer = np.zeros(n_layers)\n    for layer in range(n_layers):\n        r2_vals = []\n        for r in results:\n            m = r[\"layer_metrics\"][layer]\n            if m is not None:\n                r2_vals.append(m[\"reconstruction_r2\"])\n        mean_r2_by_layer[layer] = np.mean(r2_vals)\n        std_r2_by_layer[layer] = np.std(r2_vals)\n        print(f\"  Layer {layer:2d}: mean R² = {mean_r2_by_layer[layer]:.3f} ± {std_r2_by_layer[layer]:.3f}\")\n\n    # Create enhanced figure\n    fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n\n    # Top-left: R² evolution by layer with mean line\n    ax = axes[0, 0]\n    ax.fill_between(range(n_layers),\n                    mean_r2_by_layer - std_r2_by_layer,\n                    mean_r2_by_layer + std_r2_by_layer,\n                    alpha=0.3, color='steelblue')\n    ax.plot(range(n_layers), mean_r2_by_layer, 'o-', color='steelblue', linewidth=2,\n            label=f'Mean R² (n={len(results)})')\n    ax.set_xlabel(\"Layer\")\n    ax.set_ylabel(\"R² (compound ≈ α·word1 + β·word2)\")\n    ax.set_title(\"How Well Can Constituents Reconstruct Compound Direction?\")\n    ax.legend()\n    ax.set_ylim(0, 1.1)\n\n    # Top-right: Cosine similarity heatmap (compound vs w1, w2)\n    ax = axes[0, 1]\n    sim_data = np.zeros((len(names), 3))\n    for i, name in enumerate(names):\n        sim_data[i, 0] = final_sim_w1[i]\n        sim_data[i, 1] = final_sim_w2[i]\n        sim_data[i, 2] = final_r2[i]\n    im = ax.imshow(sim_data, aspect='auto', cmap='YlOrRd', vmin=0.8, vmax=1.0)\n    ax.set_xticks([0, 1, 2])\n    ax.set_xticklabels(['cos(C, w1)', 'cos(C, w2)', 'R²'])\n    ax.set_yticks(range(len(names)))\n    ax.set_yticklabels(names, fontsize=7)\n    ax.set_title(\"Similarity Metrics (Final Layer)\")\n    plt.colorbar(im, ax=ax)\n\n    # Bottom-left: Residual vs compositionality\n    ax = axes[1, 0]\n    colors_map = {1: '#e74c3c', 2: '#e67e22', 3: '#f1c40f', 4: '#2ecc71', 5: '#27ae60'}\n    for i, name in enumerate(names):\n        ax.scatter(comps[i], final_residual[i],\n                  c=colors_map.get(comps[i], 'gray'), s=100, edgecolors='k', zorder=5)\n        ax.annotate(name, (comps[i], final_residual[i]),\n                   fontsize=6, ha='left', va='bottom', rotation=10)\n    ax.set_xlabel(\"Compositionality Rating\")\n    ax.set_ylabel(\"Residual Norm Ratio (Unique Component)\")\n    ax.set_title(f\"Compositionality vs. Unique Compound Component\\n(Spearman r={r_res:.3f}, p={p_res:.3f})\")\n\n    # Bottom-right: Layer-wise residual evolution for selected compounds\n    ax = axes[1, 1]\n    selected = [\"washing machine\", \"hot dog\", \"coffee table\", \"mountain cabin\", \"shooting star\"]\n    for r in results:\n        if r[\"compound\"] in selected:\n            layers = []\n            residuals = []\n            for m in r[\"layer_metrics\"]:\n                if m is not None:\n                    layers.append(m[\"layer\"])\n                    residuals.append(m[\"residual_norm_ratio\"])\n            ax.plot(layers, residuals, 'o-', label=r[\"compound\"], linewidth=1.5, markersize=4)\n    ax.set_xlabel(\"Layer\")\n    ax.set_ylabel(\"Residual Norm Ratio\")\n    ax.set_title(\"Unique Component Evolution (Selected Compounds)\")\n    ax.legend(fontsize=8)\n\n    plt.tight_layout()\n    plt.savefig(PLOTS_DIR / \"exp2_detailed_analysis.png\", dpi=150, bbox_inches='tight')\n    plt.close()\n    print(f\"\\nSaved: {PLOTS_DIR / 'exp2_detailed_analysis.png'}\")\n\n    return {\n        \"mean_r2\": float(final_r2.mean()),\n        \"std_r2\": float(final_r2.std()),\n        \"mean_residual\": float(final_residual.mean()),\n        \"ttest_r2_stat\": float(t_stat),\n        \"ttest_r2_p\": float(p_val),\n        \"spearman_comp_r2_r\": float(r_r2),\n        \"spearman_comp_r2_p\": float(p_r2),\n        \"spearman_comp_residual_r\": float(r_res),\n        \"spearman_comp_residual_p\": float(p_res),\n    }\n\n\ndef analyze_experiment3():\n    \"\"\"Deep analysis of probing results.\"\"\"\n    print(\"\\n\" + \"=\"*70)\n    print(\"EXPERIMENT 3: Statistical Analysis\")\n    print(\"=\"*70)\n\n    with open(RESULTS_DIR / \"exp3_probing.json\") as f:\n        results = json.load(f)\n\n    p1 = results[\"probe1_word1_identity\"]\n    p2 = results[\"probe2_compound_vs_control\"]\n\n    print(\"\\n--- Probe 1: Word1 Identity (Token Erasure) ---\")\n    print(f\"Accuracy across all layers: {np.mean(p1['accuracy']):.3f}\")\n    print(f\"  (All layers show perfect accuracy => NO token erasure in GPT-2)\")\n    print(f\"Number of classes: {results['n_word1_classes']}\")\n    chance = 1.0 / results['n_word1_classes']\n    print(f\"Chance level: {chance:.3f}\")\n\n    print(\"\\n--- Probe 2: Compound vs. Control ---\")\n    max_layer = np.argmax(p2[\"accuracy\"])\n    max_acc = p2[\"accuracy\"][max_layer]\n    print(f\"Peak accuracy: {max_acc:.3f} at layer {max_layer}\")\n    print(f\"Layer 0 accuracy: {p2['accuracy'][0]:.3f}\")\n    print(f\"Final layer accuracy: {p2['accuracy'][-1]:.3f}\")\n\n    # Test if peak accuracy is significantly above chance (0.5)\n    # Since we have CV scores, we can use a one-sample t-test on the mean\n    # However, we only have the mean and std across folds\n    # We'll compute a z-test instead\n    n_samples = results[\"n_compound_samples\"] + results[\"n_control_samples\"]\n    se = p2[\"accuracy_std\"][max_layer] / np.sqrt(5)  # 5-fold CV\n    z = (max_acc - 0.5) / se if se > 0 else float('inf')\n    p_val = 1 - stats.norm.cdf(z)\n    print(f\"z-test (peak accuracy > 0.5): z={z:.2f}, p={p_val:.2e}\")\n\n    print(\"\\n--- Probe 3: By Compositionality Level ---\")\n    for level, data in results[\"probe3_by_compositionality\"].items():\n        if data[\"accuracy\"]:\n            mean_acc = np.mean(data[\"accuracy\"])\n            print(f\"  Compositionality {level}: mean accuracy = {mean_acc:.3f}\")\n\n    return {\n        \"probe1_mean_accuracy\": float(np.mean(p1[\"accuracy\"])),\n        \"probe2_peak_accuracy\": float(max_acc),\n        \"probe2_peak_layer\": int(max_layer),\n        \"probe2_z\": float(z),\n        \"probe2_p\": float(p_val),\n    }\n\n\ndef analyze_experiment4():\n    \"\"\"Deep analysis of attention pattern results.\"\"\"\n    print(\"\\n\" + \"=\"*70)\n    print(\"EXPERIMENT 4: Statistical Analysis\")\n    print(\"=\"*70)\n\n    with open(RESULTS_DIR / \"exp4_attention.json\") as f:\n        results = json.load(f)\n\n    print(f\"\\n{'Compound':<22} {'Max Attn Diff':<14} {'Layer':<8} {'Comp Rating':<12}\")\n    print(\"-\" * 56)\n    for r in results:\n        diffs = r[\"attn_diff_mean_per_layer\"]\n        max_idx = np.argmax(np.abs(diffs))\n        print(f\"{r['compound']:<22} {diffs[max_idx]:<14.4f} {max_idx:<8} {r['compositionality']:<12}\")\n\n    # Aggregate: mean attention difference across all compounds\n    all_diffs = np.array([r[\"attn_diff_mean_per_layer\"] for r in results])\n    mean_diffs = all_diffs.mean(axis=0)\n    print(f\"\\nMean attention difference by layer:\")\n    for l, d in enumerate(mean_diffs):\n        sig = \"*\" if abs(d) > 0.02 else \"\"\n        print(f\"  Layer {l:2d}: {d:+.4f} {sig}\")\n\n    # Test: does compound context produce more attention to word1 than control?\n    # Use all layers, paired t-test across compounds\n    attn_compound_all = np.array([np.array(r[\"compound_attn_to_word1\"]).mean(axis=1) for r in results])\n    attn_control_all = np.array([np.array(r[\"control_attn_to_prev\"]).mean(axis=1) for r in results])\n\n    # Layer-wise paired t-tests\n    print(\"\\nPaired t-tests by layer (compound vs control attention):\")\n    for layer in range(12):\n        t_stat, p_val = stats.ttest_rel(attn_compound_all[:, layer], attn_control_all[:, layer])\n        sig = \"***\" if p_val < 0.001 else \"**\" if p_val < 0.01 else \"*\" if p_val < 0.05 else \"\"\n        print(f\"  Layer {layer:2d}: t={t_stat:+.2f}, p={p_val:.4f} {sig}\")\n\n    return {\"mean_attn_diff_by_layer\": mean_diffs.tolist()}\n\n\ndef create_summary_figure():\n    \"\"\"Create a single summary figure combining key findings.\"\"\"\n    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n\n    # Load all results\n    with open(RESULTS_DIR / \"exp1_next_token.json\") as f:\n        exp1 = json.load(f)\n    with open(RESULTS_DIR / \"exp2_residual_directions.json\") as f:\n        exp2 = json.load(f)\n    with open(RESULTS_DIR / \"exp3_probing.json\") as f:\n        exp3 = json.load(f)\n    with open(RESULTS_DIR / \"exp4_attention.json\") as f:\n        exp4 = json.load(f)\n\n    # 1. Boost ratio bar chart\n    ax = axes[0, 0]\n    boost_ratios = [(r[\"compound\"], r[\"boost_ratio\"], r[\"compositionality\"]) for r in exp1]\n    boost_ratios.sort(key=lambda x: x[1], reverse=True)\n    colors_map = {1: '#e74c3c', 2: '#e67e22', 3: '#f1c40f', 4: '#2ecc71', 5: '#27ae60'}\n    bars = ax.barh(range(len(boost_ratios)),\n                   [np.log10(b[1] + 1) for b in boost_ratios],\n                   color=[colors_map.get(b[2], 'gray') for b in boost_ratios])\n    ax.set_yticks(range(len(boost_ratios)))\n    ax.set_yticklabels([b[0] for b in boost_ratios], fontsize=7)\n    ax.set_xlabel(\"log10(Boost Ratio + 1)\")\n    ax.set_title(\"(A) Word1 → Word2 Prediction Boost\")\n    ax.invert_yaxis()\n\n    # 2. Layer-wise R² evolution\n    ax = axes[0, 1]\n    n_layers = 12\n    mean_r2 = np.zeros(n_layers)\n    std_r2 = np.zeros(n_layers)\n    for layer in range(n_layers):\n        vals = [r[\"layer_metrics\"][layer][\"reconstruction_r2\"]\n                for r in exp2 if r[\"layer_metrics\"][layer] is not None]\n        mean_r2[layer] = np.mean(vals)\n        std_r2[layer] = np.std(vals)\n    ax.fill_between(range(n_layers), mean_r2 - std_r2, mean_r2 + std_r2,\n                    alpha=0.3, color='steelblue')\n    ax.plot(range(n_layers), mean_r2, 'o-', color='steelblue', linewidth=2)\n    ax.set_xlabel(\"Layer\")\n    ax.set_ylabel(\"R²\")\n    ax.set_title(\"(B) Compound ≈ α·word1 + β·word2\")\n    ax.set_ylim(0, 1.1)\n\n    # 3. Compound vs control classification\n    ax = axes[0, 2]\n    p2 = exp3[\"probe2_compound_vs_control\"]\n    ax.errorbar(p2[\"layer\"], p2[\"accuracy\"], yerr=p2[\"accuracy_std\"],\n                marker='s', capsize=3, color='darkorange', linewidth=2)\n    ax.axhline(y=0.5, color='red', linestyle='--', alpha=0.5, label='Chance')\n    ax.set_xlabel(\"Layer\")\n    ax.set_ylabel(\"Accuracy\")\n    ax.set_title(\"(C) Compound vs. Control Classification\")\n    ax.legend()\n    ax.set_ylim(0, 1.05)\n\n    # 4. Token erasure (word1 identity)\n    ax = axes[1, 0]\n    p1 = exp3[\"probe1_word1_identity\"]\n    ax.plot(p1[\"layer\"], p1[\"accuracy\"], 'o-', color='steelblue', linewidth=2)\n    chance = 1.0 / exp3[\"n_word1_classes\"]\n    ax.axhline(y=chance, color='red', linestyle='--', alpha=0.5, label=f'Chance ({chance:.2f})')\n    ax.set_xlabel(\"Layer\")\n    ax.set_ylabel(\"Accuracy\")\n    ax.set_title(\"(D) Word1 Identity from Word2 Position\\n(Token Erasure Test)\")\n    ax.legend()\n    ax.set_ylim(0, 1.05)\n\n    # 5. Attention patterns\n    ax = axes[1, 1]\n    all_compound_attn = np.array([np.array(r[\"compound_attn_to_word1\"]).mean(axis=1) for r in exp4])\n    all_control_attn = np.array([np.array(r[\"control_attn_to_prev\"]).mean(axis=1) for r in exp4])\n    layers = range(12)\n    ax.plot(layers, all_compound_attn.mean(axis=0), 'b-o', label='Compound', linewidth=2, markersize=4)\n    ax.plot(layers, all_control_attn.mean(axis=0), 'r-s', label='Control', linewidth=2, markersize=4)\n    ax.fill_between(layers,\n                    all_compound_attn.mean(axis=0) - all_compound_attn.std(axis=0),\n                    all_compound_attn.mean(axis=0) + all_compound_attn.std(axis=0),\n                    alpha=0.15, color='blue')\n    ax.fill_between(layers,\n                    all_control_attn.mean(axis=0) - all_control_attn.std(axis=0),\n                    all_control_attn.mean(axis=0) + all_control_attn.std(axis=0),\n                    alpha=0.15, color='red')\n    ax.set_xlabel(\"Layer\")\n    ax.set_ylabel(\"Mean Attention Weight\")\n    ax.set_title(\"(E) Attention: Word2 → Word1/Prev\")\n    ax.legend()\n\n    # 6. Compositionality vs key metrics\n    ax = axes[1, 2]\n    comps = [r[\"compositionality\"] for r in exp1]\n    boosts = [np.log10(r[\"boost_ratio\"] + 1) for r in exp1]\n    r_val, p_val = stats.spearmanr(comps, boosts)\n    ax.scatter(comps, boosts, s=80, c='steelblue', edgecolors='k')\n    for r in exp1:\n        ax.annotate(r[\"compound\"],\n                   (r[\"compositionality\"], np.log10(r[\"boost_ratio\"] + 1)),\n                   fontsize=5, ha='left', va='bottom', rotation=10)\n    ax.set_xlabel(\"Compositionality Rating\")\n    ax.set_ylabel(\"log10(Boost Ratio + 1)\")\n    ax.set_title(f\"(F) Compositionality vs. Boost\\n(r={r_val:.3f}, p={p_val:.3f})\")\n\n    plt.suptitle(\"Where is 'Washing Machine' Stored in GPT-2?\\nKey Findings Summary\",\n                fontsize=14, fontweight='bold', y=1.02)\n    plt.tight_layout()\n    plt.savefig(PLOTS_DIR / \"summary_figure.png\", dpi=200, bbox_inches='tight')\n    plt.close()\n    print(f\"\\nSaved: {PLOTS_DIR / 'summary_figure.png'}\")\n\n\nif __name__ == \"__main__\":\n    stats1 = analyze_experiment1()\n    stats2 = analyze_experiment2()\n    stats3 = analyze_experiment3()\n    stats4 = analyze_experiment4()\n    create_summary_figure()\n\n    # Save all stats\n    all_stats = {\n        \"experiment1\": stats1,\n        \"experiment2\": stats2,\n        \"experiment3\": stats3,\n        \"experiment4\": stats4,\n    }\n    with open(RESULTS_DIR / \"statistical_analysis.json\", \"w\") as f:\n        json.dump(all_stats, f, indent=2)\n\n    print(\"\\n\" + \"=\"*70)\n    print(\"ANALYSIS COMPLETE\")\n    print(\"=\"*70)\n"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":377,"cache_read_input_tokens":76208,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":377},"output_tokens":18,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"3b13798e-4409-40d0-adf6-d2bf88c731dd"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01K5QXSuexY6VZDxnCJ6UVqh","type":"tool_result","content":"File created successfully at: /data/hypogenicai/workspaces/llm-washing-machine-claude/src/analysis.py"}]},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"0f575935-7601-4db4-b6f3-ea5e54ced0ea","tool_use_result":{"type":"create","filePath":"/data/hypogenicai/workspaces/llm-washing-machine-claude/src/analysis.py","content":"\"\"\"\nStatistical analysis and additional visualizations for the compound concept experiments.\n\"\"\"\n\nimport json\nimport numpy as np\nfrom scipy import stats\nfrom pathlib import Path\nimport matplotlib\nmatplotlib.use('Agg')\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nRESULTS_DIR = Path(\"/data/hypogenicai/workspaces/llm-washing-machine-claude/results\")\nPLOTS_DIR = RESULTS_DIR / \"plots\"\n\n\ndef analyze_experiment1():\n    \"\"\"Deep analysis of next-token prediction results.\"\"\"\n    print(\"=\"*70)\n    print(\"EXPERIMENT 1: Statistical Analysis\")\n    print(\"=\"*70)\n\n    with open(RESULTS_DIR / \"exp1_next_token.json\") as f:\n        results = json.load(f)\n\n    compounds = [r[\"compound\"] for r in results]\n    comp_ratings = np.array([r[\"compositionality\"] for r in results])\n    p_compound = np.array([r[\"p_word2_compound_mean\"] for r in results])\n    p_control = np.array([r[\"p_word2_control_mean\"] for r in results])\n    boost_ratios = np.array([r[\"boost_ratio\"] for r in results])\n    ranks_compound = np.array([r[\"rank_compound_mean\"] for r in results])\n    ranks_control = np.array([r[\"rank_control_mean\"] for r in results])\n\n    print(f\"\\n{'Compound':<22} {'P(w2|w1)':<12} {'P(w2|ctrl)':<12} {'Boost':<10} {'Rank(cmp)':<12} {'Rank(ctrl)':<12}\")\n    print(\"-\" * 80)\n    for r in sorted(results, key=lambda x: x[\"boost_ratio\"], reverse=True):\n        print(f\"{r['compound']:<22} {r['p_word2_compound_mean']:<12.4f} \"\n              f\"{r['p_word2_control_mean']:<12.4f} {r['boost_ratio']:<10.1f} \"\n              f\"{r['rank_compound_mean']:<12.0f} {r['rank_control_mean']:<12.0f}\")\n\n    # Statistical tests\n    print(\"\\n--- Statistical Tests ---\")\n\n    # Paired Wilcoxon: compound probs vs control probs\n    stat, p_val = stats.wilcoxon(p_compound, p_control, alternative='greater')\n    print(f\"Wilcoxon (P(w2|w1) > P(w2|ctrl)): W={stat:.1f}, p={p_val:.2e}\")\n\n    # Spearman: compositionality vs boost ratio\n    r_boost, p_boost = stats.spearmanr(comp_ratings, boost_ratios)\n    print(f\"Spearman (compositionality vs boost): r={r_boost:.3f}, p={p_boost:.3f}\")\n\n    # Spearman: compositionality vs rank\n    r_rank, p_rank = stats.spearmanr(comp_ratings, ranks_compound)\n    print(f\"Spearman (compositionality vs rank): r={r_rank:.3f}, p={p_rank:.3f}\")\n\n    # Log boost for better visualization\n    log_boost = np.log10(boost_ratios + 1)\n    r_log, p_log = stats.spearmanr(comp_ratings, log_boost)\n    print(f\"Spearman (compositionality vs log10(boost)): r={r_log:.3f}, p={p_log:.3f}\")\n\n    # Group by compositionality level\n    print(\"\\n--- By Compositionality Level ---\")\n    for level in sorted(set(comp_ratings)):\n        mask = comp_ratings == level\n        n = mask.sum()\n        mean_boost = boost_ratios[mask].mean()\n        mean_p = p_compound[mask].mean()\n        mean_rank = ranks_compound[mask].mean()\n        print(f\"  Level {level} (n={n}): mean boost={mean_boost:.1f}x, \"\n              f\"mean P(w2|w1)={mean_p:.4f}, mean rank={mean_rank:.0f}\")\n\n    # Effect size: Cohen's d for compound vs control probabilities\n    diff = p_compound - p_control\n    cohens_d = diff.mean() / diff.std()\n    print(f\"\\nCohen's d (compound vs control probs): d={cohens_d:.2f}\")\n\n    # Bootstrap CI for mean boost ratio\n    n_bootstrap = 10000\n    boot_means = []\n    for _ in range(n_bootstrap):\n        idx = np.random.choice(len(boost_ratios), len(boost_ratios), replace=True)\n        boot_means.append(np.median(boost_ratios[idx]))\n    ci_lower = np.percentile(boot_means, 2.5)\n    ci_upper = np.percentile(boot_means, 97.5)\n    print(f\"Median boost ratio: {np.median(boost_ratios):.1f}x (95% CI: [{ci_lower:.1f}, {ci_upper:.1f}])\")\n\n    # Identify compounds where word2 is in top-1 after word1\n    top1 = [r for r in results if r[\"rank_compound_mean\"] <= 1.5]\n    print(f\"\\nCompounds where word2 is rank 1 after word1: {len(top1)}/{len(results)}\")\n    for r in top1:\n        print(f\"  {r['compound']}: P={r['p_word2_compound_mean']:.4f}\")\n\n    # Create enhanced figure\n    fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n\n    # Top-left: probability comparison\n    ax = axes[0, 0]\n    x = np.arange(len(compounds))\n    sorted_idx = np.argsort(p_compound)[::-1]\n    bar_width = 0.35\n    bars1 = ax.bar(x - bar_width/2, [p_compound[i] for i in sorted_idx],\n                   bar_width, label='P(w2 | word1)', color='steelblue')\n    bars2 = ax.bar(x + bar_width/2, [p_control[i] for i in sorted_idx],\n                   bar_width, label='P(w2 | control)', color='coral')\n    ax.set_xticks(x)\n    ax.set_xticklabels([compounds[i] for i in sorted_idx], rotation=45, ha='right', fontsize=7)\n    ax.set_ylabel(\"P(word2)\")\n    ax.set_title(\"Next-Token Probability: Compound Word1 vs. Control Word\")\n    ax.legend()\n\n    # Top-right: rank comparison\n    ax = axes[0, 1]\n    sorted_idx_rank = np.argsort(ranks_compound)\n    ax.barh(x, [ranks_compound[i] for i in sorted_idx_rank],\n            bar_width*2, label='Rank after word1', color='steelblue')\n    ax.set_yticks(x)\n    ax.set_yticklabels([compounds[i] for i in sorted_idx_rank], fontsize=7)\n    ax.set_xlabel(\"Rank of word2\")\n    ax.set_title(\"Rank of Word2 After Seeing Word1\")\n    ax.set_xscale('log')\n    ax.invert_yaxis()\n\n    # Bottom-left: log boost ratio by compositionality\n    ax = axes[1, 0]\n    colors_map = {1: '#e74c3c', 2: '#e67e22', 3: '#f1c40f', 4: '#2ecc71', 5: '#27ae60'}\n    for i, r in enumerate(results):\n        ax.scatter(r['compositionality'], np.log10(r['boost_ratio'] + 1),\n                  c=colors_map.get(r['compositionality'], 'gray'), s=100, edgecolors='k', zorder=5)\n        ax.annotate(r['compound'], (r['compositionality'], np.log10(r['boost_ratio'] + 1)),\n                   fontsize=6, ha='left', va='bottom', rotation=10)\n    ax.set_xlabel(\"Compositionality Rating (1=idiomatic, 5=compositional)\")\n    ax.set_ylabel(\"log10(Boost Ratio + 1)\")\n    ax.set_title(f\"Compositionality vs. Prediction Boost\\n(Spearman r={r_log:.3f}, p={p_log:.3f})\")\n\n    # Bottom-right: Top-5 predictions for key compounds\n    ax = axes[1, 1]\n    key_compounds = [\"washing machine\", \"hot dog\", \"coffee table\", \"guinea pig\", \"shooting star\", \"mountain cabin\"]\n    y_pos = 0\n    for r in results:\n        if r[\"compound\"] in key_compounds:\n            top5_str = \", \".join([f\"{t[0]}({t[1]:.3f})\" for t in r[\"top5_after_word1\"][:5]])\n            ax.text(0.02, y_pos, f\"{r['compound']}:\", fontsize=9, fontweight='bold',\n                   transform=ax.transAxes, va='top')\n            ax.text(0.02, y_pos - 0.04, f\"  Top-5 after '{r['word1']}': {top5_str}\",\n                   fontsize=7, transform=ax.transAxes, va='top')\n            y_pos -= 0.12\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.axis('off')\n    ax.set_title(\"Top-5 Predictions After Word1 (Selected Compounds)\")\n\n    plt.tight_layout()\n    plt.savefig(PLOTS_DIR / \"exp1_detailed_analysis.png\", dpi=150, bbox_inches='tight')\n    plt.close()\n    print(f\"\\nSaved: {PLOTS_DIR / 'exp1_detailed_analysis.png'}\")\n\n    return {\n        \"wilcoxon_stat\": float(stat),\n        \"wilcoxon_p\": float(p_val),\n        \"spearman_boost_r\": float(r_boost),\n        \"spearman_boost_p\": float(p_boost),\n        \"spearman_logboost_r\": float(r_log),\n        \"spearman_logboost_p\": float(p_log),\n        \"cohens_d\": float(cohens_d),\n        \"median_boost\": float(np.median(boost_ratios)),\n        \"median_boost_ci\": [float(ci_lower), float(ci_upper)],\n        \"n_top1\": len(top1),\n    }\n\n\ndef analyze_experiment2():\n    \"\"\"Deep analysis of residual stream direction results.\"\"\"\n    print(\"\\n\" + \"=\"*70)\n    print(\"EXPERIMENT 2: Statistical Analysis\")\n    print(\"=\"*70)\n\n    with open(RESULTS_DIR / \"exp2_residual_directions.json\") as f:\n        results = json.load(f)\n\n    # Extract final layer metrics\n    final_r2 = []\n    final_sim_w1 = []\n    final_sim_w2 = []\n    final_residual = []\n    comps = []\n    names = []\n\n    for r in results:\n        last = r[\"layer_metrics\"][-1]\n        if last is None:\n            continue\n        final_r2.append(last[\"reconstruction_r2\"])\n        final_sim_w1.append(last[\"sim_compound_word1\"])\n        final_sim_w2.append(last[\"sim_compound_word2\"])\n        final_residual.append(last[\"residual_norm_ratio\"])\n        comps.append(r[\"compositionality\"])\n        names.append(r[\"compound\"])\n\n    final_r2 = np.array(final_r2)\n    final_sim_w1 = np.array(final_sim_w1)\n    final_sim_w2 = np.array(final_sim_w2)\n    final_residual = np.array(final_residual)\n    comps = np.array(comps)\n\n    print(f\"\\n{'Compound':<22} {'R²':<8} {'cos(C,w1)':<12} {'cos(C,w2)':<12} {'Residual':<10}\")\n    print(\"-\" * 64)\n    for i, name in enumerate(names):\n        print(f\"{name:<22} {final_r2[i]:<8.3f} {final_sim_w1[i]:<12.3f} \"\n              f\"{final_sim_w2[i]:<12.3f} {final_residual[i]:<10.3f}\")\n\n    print(f\"\\n--- Summary ---\")\n    print(f\"Mean R²: {final_r2.mean():.3f} ± {final_r2.std():.3f}\")\n    print(f\"Mean cos(C,w1): {final_sim_w1.mean():.3f} ± {final_sim_w1.std():.3f}\")\n    print(f\"Mean cos(C,w2): {final_sim_w2.mean():.3f} ± {final_sim_w2.std():.3f}\")\n    print(f\"Mean residual ratio: {final_residual.mean():.3f} ± {final_residual.std():.3f}\")\n\n    # Is R² significantly > 0? (one-sample t-test)\n    t_stat, p_val = stats.ttest_1samp(final_r2, 0)\n    print(f\"\\nt-test (R² > 0): t={t_stat:.2f}, p={p_val:.2e}\")\n\n    # Spearman: compositionality vs R²\n    r_r2, p_r2 = stats.spearmanr(comps, final_r2)\n    print(f\"Spearman (compositionality vs R²): r={r_r2:.3f}, p={p_r2:.3f}\")\n\n    # Spearman: compositionality vs residual\n    r_res, p_res = stats.spearmanr(comps, final_residual)\n    print(f\"Spearman (compositionality vs residual): r={r_res:.3f}, p={p_res:.3f}\")\n\n    # Layer-wise R² evolution\n    print(\"\\n--- Layer-wise R² Evolution ---\")\n    n_layers = 12\n    mean_r2_by_layer = np.zeros(n_layers)\n    std_r2_by_layer = np.zeros(n_layers)\n    for layer in range(n_layers):\n        r2_vals = []\n        for r in results:\n            m = r[\"layer_metrics\"][layer]\n            if m is not None:\n                r2_vals.append(m[\"reconstruction_r2\"])\n        mean_r2_by_layer[layer] = np.mean(r2_vals)\n        std_r2_by_layer[layer] = np.std(r2_vals)\n        print(f\"  Layer {layer:2d}: mean R² = {mean_r2_by_layer[layer]:.3f} ± {std_r2_by_layer[layer]:.3f}\")\n\n    # Create enhanced figure\n    fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n\n    # Top-left: R² evolution by layer with mean line\n    ax = axes[0, 0]\n    ax.fill_between(range(n_layers),\n                    mean_r2_by_layer - std_r2_by_layer,\n                    mean_r2_by_layer + std_r2_by_layer,\n                    alpha=0.3, color='steelblue')\n    ax.plot(range(n_layers), mean_r2_by_layer, 'o-', color='steelblue', linewidth=2,\n            label=f'Mean R² (n={len(results)})')\n    ax.set_xlabel(\"Layer\")\n    ax.set_ylabel(\"R² (compound ≈ α·word1 + β·word2)\")\n    ax.set_title(\"How Well Can Constituents Reconstruct Compound Direction?\")\n    ax.legend()\n    ax.set_ylim(0, 1.1)\n\n    # Top-right: Cosine similarity heatmap (compound vs w1, w2)\n    ax = axes[0, 1]\n    sim_data = np.zeros((len(names), 3))\n    for i, name in enumerate(names):\n        sim_data[i, 0] = final_sim_w1[i]\n        sim_data[i, 1] = final_sim_w2[i]\n        sim_data[i, 2] = final_r2[i]\n    im = ax.imshow(sim_data, aspect='auto', cmap='YlOrRd', vmin=0.8, vmax=1.0)\n    ax.set_xticks([0, 1, 2])\n    ax.set_xticklabels(['cos(C, w1)', 'cos(C, w2)', 'R²'])\n    ax.set_yticks(range(len(names)))\n    ax.set_yticklabels(names, fontsize=7)\n    ax.set_title(\"Similarity Metrics (Final Layer)\")\n    plt.colorbar(im, ax=ax)\n\n    # Bottom-left: Residual vs compositionality\n    ax = axes[1, 0]\n    colors_map = {1: '#e74c3c', 2: '#e67e22', 3: '#f1c40f', 4: '#2ecc71', 5: '#27ae60'}\n    for i, name in enumerate(names):\n        ax.scatter(comps[i], final_residual[i],\n                  c=colors_map.get(comps[i], 'gray'), s=100, edgecolors='k', zorder=5)\n        ax.annotate(name, (comps[i], final_residual[i]),\n                   fontsize=6, ha='left', va='bottom', rotation=10)\n    ax.set_xlabel(\"Compositionality Rating\")\n    ax.set_ylabel(\"Residual Norm Ratio (Unique Component)\")\n    ax.set_title(f\"Compositionality vs. Unique Compound Component\\n(Spearman r={r_res:.3f}, p={p_res:.3f})\")\n\n    # Bottom-right: Layer-wise residual evolution for selected compounds\n    ax = axes[1, 1]\n    selected = [\"washing machine\", \"hot dog\", \"coffee table\", \"mountain cabin\", \"shooting star\"]\n    for r in results:\n        if r[\"compound\"] in selected:\n            layers = []\n            residuals = []\n            for m in r[\"layer_metrics\"]:\n                if m is not None:\n                    layers.append(m[\"layer\"])\n                    residuals.append(m[\"residual_norm_ratio\"])\n            ax.plot(layers, residuals, 'o-', label=r[\"compound\"], linewidth=1.5, markersize=4)\n    ax.set_xlabel(\"Layer\")\n    ax.set_ylabel(\"Residual Norm Ratio\")\n    ax.set_title(\"Unique Component Evolution (Selected Compounds)\")\n    ax.legend(fontsize=8)\n\n    plt.tight_layout()\n    plt.savefig(PLOTS_DIR / \"exp2_detailed_analysis.png\", dpi=150, bbox_inches='tight')\n    plt.close()\n    print(f\"\\nSaved: {PLOTS_DIR / 'exp2_detailed_analysis.png'}\")\n\n    return {\n        \"mean_r2\": float(final_r2.mean()),\n        \"std_r2\": float(final_r2.std()),\n        \"mean_residual\": float(final_residual.mean()),\n        \"ttest_r2_stat\": float(t_stat),\n        \"ttest_r2_p\": float(p_val),\n        \"spearman_comp_r2_r\": float(r_r2),\n        \"spearman_comp_r2_p\": float(p_r2),\n        \"spearman_comp_residual_r\": float(r_res),\n        \"spearman_comp_residual_p\": float(p_res),\n    }\n\n\ndef analyze_experiment3():\n    \"\"\"Deep analysis of probing results.\"\"\"\n    print(\"\\n\" + \"=\"*70)\n    print(\"EXPERIMENT 3: Statistical Analysis\")\n    print(\"=\"*70)\n\n    with open(RESULTS_DIR / \"exp3_probing.json\") as f:\n        results = json.load(f)\n\n    p1 = results[\"probe1_word1_identity\"]\n    p2 = results[\"probe2_compound_vs_control\"]\n\n    print(\"\\n--- Probe 1: Word1 Identity (Token Erasure) ---\")\n    print(f\"Accuracy across all layers: {np.mean(p1['accuracy']):.3f}\")\n    print(f\"  (All layers show perfect accuracy => NO token erasure in GPT-2)\")\n    print(f\"Number of classes: {results['n_word1_classes']}\")\n    chance = 1.0 / results['n_word1_classes']\n    print(f\"Chance level: {chance:.3f}\")\n\n    print(\"\\n--- Probe 2: Compound vs. Control ---\")\n    max_layer = np.argmax(p2[\"accuracy\"])\n    max_acc = p2[\"accuracy\"][max_layer]\n    print(f\"Peak accuracy: {max_acc:.3f} at layer {max_layer}\")\n    print(f\"Layer 0 accuracy: {p2['accuracy'][0]:.3f}\")\n    print(f\"Final layer accuracy: {p2['accuracy'][-1]:.3f}\")\n\n    # Test if peak accuracy is significantly above chance (0.5)\n    # Since we have CV scores, we can use a one-sample t-test on the mean\n    # However, we only have the mean and std across folds\n    # We'll compute a z-test instead\n    n_samples = results[\"n_compound_samples\"] + results[\"n_control_samples\"]\n    se = p2[\"accuracy_std\"][max_layer] / np.sqrt(5)  # 5-fold CV\n    z = (max_acc - 0.5) / se if se > 0 else float('inf')\n    p_val = 1 - stats.norm.cdf(z)\n    print(f\"z-test (peak accuracy > 0.5): z={z:.2f}, p={p_val:.2e}\")\n\n    print(\"\\n--- Probe 3: By Compositionality Level ---\")\n    for level, data in results[\"probe3_by_compositionality\"].items():\n        if data[\"accuracy\"]:\n            mean_acc = np.mean(data[\"accuracy\"])\n            print(f\"  Compositionality {level}: mean accuracy = {mean_acc:.3f}\")\n\n    return {\n        \"probe1_mean_accuracy\": float(np.mean(p1[\"accuracy\"])),\n        \"probe2_peak_accuracy\": float(max_acc),\n        \"probe2_peak_layer\": int(max_layer),\n        \"probe2_z\": float(z),\n        \"probe2_p\": float(p_val),\n    }\n\n\ndef analyze_experiment4():\n    \"\"\"Deep analysis of attention pattern results.\"\"\"\n    print(\"\\n\" + \"=\"*70)\n    print(\"EXPERIMENT 4: Statistical Analysis\")\n    print(\"=\"*70)\n\n    with open(RESULTS_DIR / \"exp4_attention.json\") as f:\n        results = json.load(f)\n\n    print(f\"\\n{'Compound':<22} {'Max Attn Diff':<14} {'Layer':<8} {'Comp Rating':<12}\")\n    print(\"-\" * 56)\n    for r in results:\n        diffs = r[\"attn_diff_mean_per_layer\"]\n        max_idx = np.argmax(np.abs(diffs))\n        print(f\"{r['compound']:<22} {diffs[max_idx]:<14.4f} {max_idx:<8} {r['compositionality']:<12}\")\n\n    # Aggregate: mean attention difference across all compounds\n    all_diffs = np.array([r[\"attn_diff_mean_per_layer\"] for r in results])\n    mean_diffs = all_diffs.mean(axis=0)\n    print(f\"\\nMean attention difference by layer:\")\n    for l, d in enumerate(mean_diffs):\n        sig = \"*\" if abs(d) > 0.02 else \"\"\n        print(f\"  Layer {l:2d}: {d:+.4f} {sig}\")\n\n    # Test: does compound context produce more attention to word1 than control?\n    # Use all layers, paired t-test across compounds\n    attn_compound_all = np.array([np.array(r[\"compound_attn_to_word1\"]).mean(axis=1) for r in results])\n    attn_control_all = np.array([np.array(r[\"control_attn_to_prev\"]).mean(axis=1) for r in results])\n\n    # Layer-wise paired t-tests\n    print(\"\\nPaired t-tests by layer (compound vs control attention):\")\n    for layer in range(12):\n        t_stat, p_val = stats.ttest_rel(attn_compound_all[:, layer], attn_control_all[:, layer])\n        sig = \"***\" if p_val < 0.001 else \"**\" if p_val < 0.01 else \"*\" if p_val < 0.05 else \"\"\n        print(f\"  Layer {layer:2d}: t={t_stat:+.2f}, p={p_val:.4f} {sig}\")\n\n    return {\"mean_attn_diff_by_layer\": mean_diffs.tolist()}\n\n\ndef create_summary_figure():\n    \"\"\"Create a single summary figure combining key findings.\"\"\"\n    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n\n    # Load all results\n    with open(RESULTS_DIR / \"exp1_next_token.json\") as f:\n        exp1 = json.load(f)\n    with open(RESULTS_DIR / \"exp2_residual_directions.json\") as f:\n        exp2 = json.load(f)\n    with open(RESULTS_DIR / \"exp3_probing.json\") as f:\n        exp3 = json.load(f)\n    with open(RESULTS_DIR / \"exp4_attention.json\") as f:\n        exp4 = json.load(f)\n\n    # 1. Boost ratio bar chart\n    ax = axes[0, 0]\n    boost_ratios = [(r[\"compound\"], r[\"boost_ratio\"], r[\"compositionality\"]) for r in exp1]\n    boost_ratios.sort(key=lambda x: x[1], reverse=True)\n    colors_map = {1: '#e74c3c', 2: '#e67e22', 3: '#f1c40f', 4: '#2ecc71', 5: '#27ae60'}\n    bars = ax.barh(range(len(boost_ratios)),\n                   [np.log10(b[1] + 1) for b in boost_ratios],\n                   color=[colors_map.get(b[2], 'gray') for b in boost_ratios])\n    ax.set_yticks(range(len(boost_ratios)))\n    ax.set_yticklabels([b[0] for b in boost_ratios], fontsize=7)\n    ax.set_xlabel(\"log10(Boost Ratio + 1)\")\n    ax.set_title(\"(A) Word1 → Word2 Prediction Boost\")\n    ax.invert_yaxis()\n\n    # 2. Layer-wise R² evolution\n    ax = axes[0, 1]\n    n_layers = 12\n    mean_r2 = np.zeros(n_layers)\n    std_r2 = np.zeros(n_layers)\n    for layer in range(n_layers):\n        vals = [r[\"layer_metrics\"][layer][\"reconstruction_r2\"]\n                for r in exp2 if r[\"layer_metrics\"][layer] is not None]\n        mean_r2[layer] = np.mean(vals)\n        std_r2[layer] = np.std(vals)\n    ax.fill_between(range(n_layers), mean_r2 - std_r2, mean_r2 + std_r2,\n                    alpha=0.3, color='steelblue')\n    ax.plot(range(n_layers), mean_r2, 'o-', color='steelblue', linewidth=2)\n    ax.set_xlabel(\"Layer\")\n    ax.set_ylabel(\"R²\")\n    ax.set_title(\"(B) Compound ≈ α·word1 + β·word2\")\n    ax.set_ylim(0, 1.1)\n\n    # 3. Compound vs control classification\n    ax = axes[0, 2]\n    p2 = exp3[\"probe2_compound_vs_control\"]\n    ax.errorbar(p2[\"layer\"], p2[\"accuracy\"], yerr=p2[\"accuracy_std\"],\n                marker='s', capsize=3, color='darkorange', linewidth=2)\n    ax.axhline(y=0.5, color='red', linestyle='--', alpha=0.5, label='Chance')\n    ax.set_xlabel(\"Layer\")\n    ax.set_ylabel(\"Accuracy\")\n    ax.set_title(\"(C) Compound vs. Control Classification\")\n    ax.legend()\n    ax.set_ylim(0, 1.05)\n\n    # 4. Token erasure (word1 identity)\n    ax = axes[1, 0]\n    p1 = exp3[\"probe1_word1_identity\"]\n    ax.plot(p1[\"layer\"], p1[\"accuracy\"], 'o-', color='steelblue', linewidth=2)\n    chance = 1.0 / exp3[\"n_word1_classes\"]\n    ax.axhline(y=chance, color='red', linestyle='--', alpha=0.5, label=f'Chance ({chance:.2f})')\n    ax.set_xlabel(\"Layer\")\n    ax.set_ylabel(\"Accuracy\")\n    ax.set_title(\"(D) Word1 Identity from Word2 Position\\n(Token Erasure Test)\")\n    ax.legend()\n    ax.set_ylim(0, 1.05)\n\n    # 5. Attention patterns\n    ax = axes[1, 1]\n    all_compound_attn = np.array([np.array(r[\"compound_attn_to_word1\"]).mean(axis=1) for r in exp4])\n    all_control_attn = np.array([np.array(r[\"control_attn_to_prev\"]).mean(axis=1) for r in exp4])\n    layers = range(12)\n    ax.plot(layers, all_compound_attn.mean(axis=0), 'b-o', label='Compound', linewidth=2, markersize=4)\n    ax.plot(layers, all_control_attn.mean(axis=0), 'r-s', label='Control', linewidth=2, markersize=4)\n    ax.fill_between(layers,\n                    all_compound_attn.mean(axis=0) - all_compound_attn.std(axis=0),\n                    all_compound_attn.mean(axis=0) + all_compound_attn.std(axis=0),\n                    alpha=0.15, color='blue')\n    ax.fill_between(layers,\n                    all_control_attn.mean(axis=0) - all_control_attn.std(axis=0),\n                    all_control_attn.mean(axis=0) + all_control_attn.std(axis=0),\n                    alpha=0.15, color='red')\n    ax.set_xlabel(\"Layer\")\n    ax.set_ylabel(\"Mean Attention Weight\")\n    ax.set_title(\"(E) Attention: Word2 → Word1/Prev\")\n    ax.legend()\n\n    # 6. Compositionality vs key metrics\n    ax = axes[1, 2]\n    comps = [r[\"compositionality\"] for r in exp1]\n    boosts = [np.log10(r[\"boost_ratio\"] + 1) for r in exp1]\n    r_val, p_val = stats.spearmanr(comps, boosts)\n    ax.scatter(comps, boosts, s=80, c='steelblue', edgecolors='k')\n    for r in exp1:\n        ax.annotate(r[\"compound\"],\n                   (r[\"compositionality\"], np.log10(r[\"boost_ratio\"] + 1)),\n                   fontsize=5, ha='left', va='bottom', rotation=10)\n    ax.set_xlabel(\"Compositionality Rating\")\n    ax.set_ylabel(\"log10(Boost Ratio + 1)\")\n    ax.set_title(f\"(F) Compositionality vs. Boost\\n(r={r_val:.3f}, p={p_val:.3f})\")\n\n    plt.suptitle(\"Where is 'Washing Machine' Stored in GPT-2?\\nKey Findings Summary\",\n                fontsize=14, fontweight='bold', y=1.02)\n    plt.tight_layout()\n    plt.savefig(PLOTS_DIR / \"summary_figure.png\", dpi=200, bbox_inches='tight')\n    plt.close()\n    print(f\"\\nSaved: {PLOTS_DIR / 'summary_figure.png'}\")\n\n\nif __name__ == \"__main__\":\n    stats1 = analyze_experiment1()\n    stats2 = analyze_experiment2()\n    stats3 = analyze_experiment3()\n    stats4 = analyze_experiment4()\n    create_summary_figure()\n\n    # Save all stats\n    all_stats = {\n        \"experiment1\": stats1,\n        \"experiment2\": stats2,\n        \"experiment3\": stats3,\n        \"experiment4\": stats4,\n    }\n    with open(RESULTS_DIR / \"statistical_analysis.json\", \"w\") as f:\n        json.dump(all_stats, f, indent=2)\n\n    print(\"\\n\" + \"=\"*70)\n    print(\"ANALYSIS COMPLETE\")\n    print(\"=\"*70)\n","structuredPatch":[],"originalFile":null}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01CXsgrgCN3C58RJeNgesXos","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01SqVxNdhyY83wSEfX1Q61WE","name":"Bash","input":{"command":"source .venv/bin/activate && python src/analysis.py 2>&1","description":"Run statistical analysis","timeout":120000}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":8799,"cache_read_input_tokens":76585,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":8799},"output_tokens":25,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"9038f59f-7d5f-4667-a456-2def7a289425"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01SqVxNdhyY83wSEfX1Q61WE","type":"tool_result","content":"======================================================================\nEXPERIMENT 1: Statistical Analysis\n======================================================================\n\nCompound               P(w2|w1)     P(w2|ctrl)   Boost      Rank(cmp)    Rank(ctrl)  \n--------------------------------------------------------------------------------\nguinea pig             0.8326       0.0001       7233.3     1            1755        \nwashing machine        0.8270       0.0002       4963.4     1            924         \nswimming pool          0.6258       0.0011       549.4      1            125         \ndriving license        0.0364       0.0002       220.7      118          1325        \ngarden hose            0.0235       0.0001       200.4      12           2101        \nliving room            0.2611       0.0016       159.9      2            98          \nchocolate cake         0.0356       0.0003       140.4      5            978         \nhot dog                0.0973       0.0022       44.7       4            142         \nparking lot            0.3215       0.0116       27.7       1            14          \nsteel bridge           0.0046       0.0004       12.6       53           992         \ndoor handle            0.0068       0.0007       9.2        42           376         \ncoffee table           0.0632       0.0091       6.9        4            14          \nbrick house            0.0273       0.0047       5.8        11           62          \nwater bottle           0.0656       0.0176       3.7        17           11          \nshooting star          0.0307       0.0103       3.0        90           18          \nmountain cabin         0.0040       0.0014       2.9        149          305         \nsunflower              0.0001       0.0004       0.3        1673         706         \nsnowman                0.0038       0.0427       0.1        63           7           \n\n--- Statistical Tests ---\nWilcoxon (P(w2|w1) > P(w2|ctrl)): W=160.0, p=2.10e-04\nSpearman (compositionality vs boost): r=-0.267, p=0.285\nSpearman (compositionality vs rank): r=0.277, p=0.265\nSpearman (compositionality vs log10(boost)): r=-0.267, p=0.285\n\n--- By Compositionality Level ---\n  Level 1 (n=1): mean boost=44.7x, mean P(w2|w1)=0.0973, mean rank=4\n  Level 2 (n=2): mean boost=3618.2x, mean P(w2|w1)=0.4316, mean rank=46\n  Level 3 (n=1): mean boost=159.9x, mean P(w2|w1)=0.2611, mean rank=2\n  Level 4 (n=6): mean boost=960.3x, mean P(w2|w1)=0.3024, mean rank=310\n  Level 5 (n=8): mean boost=47.7x, mean P(w2|w1)=0.0288, mean rank=37\n\nCohen's d (compound vs control probs): d=0.63\nMedian boost ratio: 20.2x (95% CI: [4.7, 180.2])\n\nCompounds where word2 is rank 1 after word1: 4/18\n  washing machine: P=0.8270\n  swimming pool: P=0.6258\n  parking lot: P=0.3215\n  guinea pig: P=0.8326\n\nSaved: /data/hypogenicai/workspaces/llm-washing-machine-claude/results/plots/exp1_detailed_analysis.png\n\n======================================================================\nEXPERIMENT 2: Statistical Analysis\n======================================================================\n\nCompound               R²       cos(C,w1)    cos(C,w2)    Residual  \n----------------------------------------------------------------\nwashing machine        0.917    0.907        0.951        0.288     \ncoffee table           0.938    0.934        0.962        0.249     \nswimming pool          0.924    0.932        0.957        0.276     \nparking lot            0.922    0.936        0.934        0.280     \nhot dog                0.888    0.897        0.934        0.335     \nshooting star          0.944    0.929        0.960        0.236     \nliving room            0.933    0.925        0.958        0.259     \ndriving license        0.924    0.908        0.955        0.276     \nbrick house            0.939    0.933        0.965        0.247     \nmountain cabin         0.956    0.937        0.975        0.209     \ngarden hose            0.962    0.933        0.979        0.196     \nwater bottle           0.931    0.924        0.963        0.262     \nsteel bridge           0.965    0.924        0.982        0.188     \nchocolate cake         0.953    0.944        0.975        0.216     \ndoor handle            0.958    0.949        0.976        0.206     \n\n--- Summary ---\nMean R²: 0.937 ± 0.020\nMean cos(C,w1): 0.927 ± 0.014\nMean cos(C,w2): 0.962 ± 0.014\nMean residual ratio: 0.248 ± 0.039\n\nt-test (R² > 0): t=176.30, p=7.86e-25\nSpearman (compositionality vs R²): r=0.669, p=0.006\nSpearman (compositionality vs residual): r=-0.669, p=0.006\n\n--- Layer-wise R² Evolution ---\n  Layer  0: mean R² = 0.940 ± 0.035\n  Layer  1: mean R² = 0.913 ± 0.050\n  Layer  2: mean R² = 0.869 ± 0.065\n  Layer  3: mean R² = 0.825 ± 0.077\n  Layer  4: mean R² = 0.805 ± 0.073\n  Layer  5: mean R² = 0.796 ± 0.069\n  Layer  6: mean R² = 0.812 ± 0.066\n  Layer  7: mean R² = 0.842 ± 0.055\n  Layer  8: mean R² = 0.853 ± 0.054\n  Layer  9: mean R² = 0.868 ± 0.049\n  Layer 10: mean R² = 0.910 ± 0.029\n  Layer 11: mean R² = 0.937 ± 0.020\n\nSaved: /data/hypogenicai/workspaces/llm-washing-machine-claude/results/plots/exp2_detailed_analysis.png\n\n======================================================================\nEXPERIMENT 3: Statistical Analysis\n======================================================================\n\n--- Probe 1: Word1 Identity (Token Erasure) ---\nAccuracy across all layers: 1.000\n  (All layers show perfect accuracy => NO token erasure in GPT-2)\nNumber of classes: 31\nChance level: 0.032\n\n--- Probe 2: Compound vs. Control ---\nPeak accuracy: 0.922 at layer 8\nLayer 0 accuracy: 0.706\nFinal layer accuracy: 0.851\nz-test (peak accuracy > 0.5): z=9.50, p=0.00e+00\n\n--- Probe 3: By Compositionality Level ---\n  Compositionality 1: mean accuracy = 1.000\n  Compositionality 2: mean accuracy = 1.000\n  Compositionality 3: mean accuracy = 1.000\n  Compositionality 4: mean accuracy = 0.795\n  Compositionality 5: mean accuracy = 0.892\n\n======================================================================\nEXPERIMENT 4: Statistical Analysis\n======================================================================\n\nCompound               Max Attn Diff  Layer    Comp Rating \n--------------------------------------------------------\nwashing machine        0.1387         0        4           \ncoffee table           0.0515         0        5           \nswimming pool          0.1164         0        4           \nparking lot            0.0860         0        4           \nhot dog                0.1232         0        1           \nshooting star          0.1073         3        2           \nliving room            0.0848         0        3           \ndriving license        0.1250         0        4           \nbrick house            0.0755         3        5           \nmountain cabin         0.0632         0        5           \ngarden hose            0.0518         0        5           \nwater bottle           0.0478         0        5           \nsteel bridge           0.0765         0        5           \nchocolate cake         0.1040         0        5           \ndoor handle            0.0458         4        5           \nsnowman                -0.2757        2        4           \nsunflower              -0.2729        2        4           \n\nMean attention difference by layer:\n  Layer  0: +0.0516 *\n  Layer  1: +0.0053 \n  Layer  2: -0.0246 *\n  Layer  3: -0.0072 \n  Layer  4: -0.0318 *\n  Layer  5: +0.0123 \n  Layer  6: -0.0188 \n  Layer  7: -0.0247 *\n  Layer  8: -0.0174 \n  Layer  9: -0.0058 \n  Layer 10: -0.0019 \n  Layer 11: +0.0001 \n\nPaired t-tests by layer (compound vs control attention):\n  Layer  0: t=+2.87, p=0.0112 *\n  Layer  1: t=+0.42, p=0.6831 \n  Layer  2: t=-1.03, p=0.3170 \n  Layer  3: t=-0.31, p=0.7635 \n  Layer  4: t=-1.67, p=0.1141 \n  Layer  5: t=+1.33, p=0.2032 \n  Layer  6: t=-2.30, p=0.0354 *\n  Layer  7: t=-6.56, p=0.0000 ***\n  Layer  8: t=-5.57, p=0.0000 ***\n  Layer  9: t=-1.64, p=0.1204 \n  Layer 10: t=-0.47, p=0.6465 \n  Layer 11: t=+0.02, p=0.9819 \n\nSaved: /data/hypogenicai/workspaces/llm-washing-machine-claude/results/plots/summary_figure.png\n\n======================================================================\nANALYSIS COMPLETE\n======================================================================","is_error":false}]},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"c2fa27b7-2e5b-46f0-a26a-e0edb5922794","tool_use_result":{"stdout":"======================================================================\nEXPERIMENT 1: Statistical Analysis\n======================================================================\n\nCompound               P(w2|w1)     P(w2|ctrl)   Boost      Rank(cmp)    Rank(ctrl)  \n--------------------------------------------------------------------------------\nguinea pig             0.8326       0.0001       7233.3     1            1755        \nwashing machine        0.8270       0.0002       4963.4     1            924         \nswimming pool          0.6258       0.0011       549.4      1            125         \ndriving license        0.0364       0.0002       220.7      118          1325        \ngarden hose            0.0235       0.0001       200.4      12           2101        \nliving room            0.2611       0.0016       159.9      2            98          \nchocolate cake         0.0356       0.0003       140.4      5            978         \nhot dog                0.0973       0.0022       44.7       4            142         \nparking lot            0.3215       0.0116       27.7       1            14          \nsteel bridge           0.0046       0.0004       12.6       53           992         \ndoor handle            0.0068       0.0007       9.2        42           376         \ncoffee table           0.0632       0.0091       6.9        4            14          \nbrick house            0.0273       0.0047       5.8        11           62          \nwater bottle           0.0656       0.0176       3.7        17           11          \nshooting star          0.0307       0.0103       3.0        90           18          \nmountain cabin         0.0040       0.0014       2.9        149          305         \nsunflower              0.0001       0.0004       0.3        1673         706         \nsnowman                0.0038       0.0427       0.1        63           7           \n\n--- Statistical Tests ---\nWilcoxon (P(w2|w1) > P(w2|ctrl)): W=160.0, p=2.10e-04\nSpearman (compositionality vs boost): r=-0.267, p=0.285\nSpearman (compositionality vs rank): r=0.277, p=0.265\nSpearman (compositionality vs log10(boost)): r=-0.267, p=0.285\n\n--- By Compositionality Level ---\n  Level 1 (n=1): mean boost=44.7x, mean P(w2|w1)=0.0973, mean rank=4\n  Level 2 (n=2): mean boost=3618.2x, mean P(w2|w1)=0.4316, mean rank=46\n  Level 3 (n=1): mean boost=159.9x, mean P(w2|w1)=0.2611, mean rank=2\n  Level 4 (n=6): mean boost=960.3x, mean P(w2|w1)=0.3024, mean rank=310\n  Level 5 (n=8): mean boost=47.7x, mean P(w2|w1)=0.0288, mean rank=37\n\nCohen's d (compound vs control probs): d=0.63\nMedian boost ratio: 20.2x (95% CI: [4.7, 180.2])\n\nCompounds where word2 is rank 1 after word1: 4/18\n  washing machine: P=0.8270\n  swimming pool: P=0.6258\n  parking lot: P=0.3215\n  guinea pig: P=0.8326\n\nSaved: /data/hypogenicai/workspaces/llm-washing-machine-claude/results/plots/exp1_detailed_analysis.png\n\n======================================================================\nEXPERIMENT 2: Statistical Analysis\n======================================================================\n\nCompound               R²       cos(C,w1)    cos(C,w2)    Residual  \n----------------------------------------------------------------\nwashing machine        0.917    0.907        0.951        0.288     \ncoffee table           0.938    0.934        0.962        0.249     \nswimming pool          0.924    0.932        0.957        0.276     \nparking lot            0.922    0.936        0.934        0.280     \nhot dog                0.888    0.897        0.934        0.335     \nshooting star          0.944    0.929        0.960        0.236     \nliving room            0.933    0.925        0.958        0.259     \ndriving license        0.924    0.908        0.955        0.276     \nbrick house            0.939    0.933        0.965        0.247     \nmountain cabin         0.956    0.937        0.975        0.209     \ngarden hose            0.962    0.933        0.979        0.196     \nwater bottle           0.931    0.924        0.963        0.262     \nsteel bridge           0.965    0.924        0.982        0.188     \nchocolate cake         0.953    0.944        0.975        0.216     \ndoor handle            0.958    0.949        0.976        0.206     \n\n--- Summary ---\nMean R²: 0.937 ± 0.020\nMean cos(C,w1): 0.927 ± 0.014\nMean cos(C,w2): 0.962 ± 0.014\nMean residual ratio: 0.248 ± 0.039\n\nt-test (R² > 0): t=176.30, p=7.86e-25\nSpearman (compositionality vs R²): r=0.669, p=0.006\nSpearman (compositionality vs residual): r=-0.669, p=0.006\n\n--- Layer-wise R² Evolution ---\n  Layer  0: mean R² = 0.940 ± 0.035\n  Layer  1: mean R² = 0.913 ± 0.050\n  Layer  2: mean R² = 0.869 ± 0.065\n  Layer  3: mean R² = 0.825 ± 0.077\n  Layer  4: mean R² = 0.805 ± 0.073\n  Layer  5: mean R² = 0.796 ± 0.069\n  Layer  6: mean R² = 0.812 ± 0.066\n  Layer  7: mean R² = 0.842 ± 0.055\n  Layer  8: mean R² = 0.853 ± 0.054\n  Layer  9: mean R² = 0.868 ± 0.049\n  Layer 10: mean R² = 0.910 ± 0.029\n  Layer 11: mean R² = 0.937 ± 0.020\n\nSaved: /data/hypogenicai/workspaces/llm-washing-machine-claude/results/plots/exp2_detailed_analysis.png\n\n======================================================================\nEXPERIMENT 3: Statistical Analysis\n======================================================================\n\n--- Probe 1: Word1 Identity (Token Erasure) ---\nAccuracy across all layers: 1.000\n  (All layers show perfect accuracy => NO token erasure in GPT-2)\nNumber of classes: 31\nChance level: 0.032\n\n--- Probe 2: Compound vs. Control ---\nPeak accuracy: 0.922 at layer 8\nLayer 0 accuracy: 0.706\nFinal layer accuracy: 0.851\nz-test (peak accuracy > 0.5): z=9.50, p=0.00e+00\n\n--- Probe 3: By Compositionality Level ---\n  Compositionality 1: mean accuracy = 1.000\n  Compositionality 2: mean accuracy = 1.000\n  Compositionality 3: mean accuracy = 1.000\n  Compositionality 4: mean accuracy = 0.795\n  Compositionality 5: mean accuracy = 0.892\n\n======================================================================\nEXPERIMENT 4: Statistical Analysis\n======================================================================\n\nCompound               Max Attn Diff  Layer    Comp Rating \n--------------------------------------------------------\nwashing machine        0.1387         0        4           \ncoffee table           0.0515         0        5           \nswimming pool          0.1164         0        4           \nparking lot            0.0860         0        4           \nhot dog                0.1232         0        1           \nshooting star          0.1073         3        2           \nliving room            0.0848         0        3           \ndriving license        0.1250         0        4           \nbrick house            0.0755         3        5           \nmountain cabin         0.0632         0        5           \ngarden hose            0.0518         0        5           \nwater bottle           0.0478         0        5           \nsteel bridge           0.0765         0        5           \nchocolate cake         0.1040         0        5           \ndoor handle            0.0458         4        5           \nsnowman                -0.2757        2        4           \nsunflower              -0.2729        2        4           \n\nMean attention difference by layer:\n  Layer  0: +0.0516 *\n  Layer  1: +0.0053 \n  Layer  2: -0.0246 *\n  Layer  3: -0.0072 \n  Layer  4: -0.0318 *\n  Layer  5: +0.0123 \n  Layer  6: -0.0188 \n  Layer  7: -0.0247 *\n  Layer  8: -0.0174 \n  Layer  9: -0.0058 \n  Layer 10: -0.0019 \n  Layer 11: +0.0001 \n\nPaired t-tests by layer (compound vs control attention):\n  Layer  0: t=+2.87, p=0.0112 *\n  Layer  1: t=+0.42, p=0.6831 \n  Layer  2: t=-1.03, p=0.3170 \n  Layer  3: t=-0.31, p=0.7635 \n  Layer  4: t=-1.67, p=0.1141 \n  Layer  5: t=+1.33, p=0.2032 \n  Layer  6: t=-2.30, p=0.0354 *\n  Layer  7: t=-6.56, p=0.0000 ***\n  Layer  8: t=-5.57, p=0.0000 ***\n  Layer  9: t=-1.64, p=0.1204 \n  Layer 10: t=-0.47, p=0.6465 \n  Layer 11: t=+0.02, p=0.9819 \n\nSaved: /data/hypogenicai/workspaces/llm-washing-machine-claude/results/plots/summary_figure.png\n\n======================================================================\nANALYSIS COMPLETE\n======================================================================","stderr":"","interrupted":false,"isImage":false}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01Q5pD4CiEUbyjALdHvKwcam","type":"message","role":"assistant","content":[{"type":"text","text":"Excellent! The results are highly informative. Let me now also run a supplementary analysis on GPT-2-medium to validate findings at a slightly larger scale."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2780,"cache_read_input_tokens":85384,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":2780},"output_tokens":4,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"a28d36dd-ab3b-40dd-aeb2-894c6f3af0b3"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01Q5pD4CiEUbyjALdHvKwcam","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01WfoHp6pfrVFo2MsWTb2wdT","name":"Write","input":{"file_path":"/data/hypogenicai/workspaces/llm-washing-machine-claude/src/validation_gpt2medium.py","content":"\"\"\"\nValidation experiment: Run key analyses on GPT-2-medium (355M, 24 layers)\nto check if findings from GPT-2 (124M, 12 layers) generalize.\n\nFocus on:\n1. Next-token prediction for key compounds\n2. R² reconstruction at final layer\n\"\"\"\n\nimport json\nimport sys\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nfrom pathlib import Path\nimport transformer_lens as tl\n\nSEED = 42\ntorch.manual_seed(SEED)\nnp.random.seed(SEED)\n\nDEVICE = \"cuda:0\"\nRESULTS_DIR = Path(\"/data/hypogenicai/workspaces/llm-washing-machine-claude/results\")\n\nKEY_COMPOUNDS = [\n    (\"washing machine\", \"washing\", \"machine\", 4, \"red machine\"),\n    (\"swimming pool\", \"swimming\", \"pool\", 4, \"deep pool\"),\n    (\"hot dog\", \"hot\", \"dog\", 1, \"big dog\"),\n    (\"guinea pig\", \"guinea\", \"pig\", 2, \"small pig\"),\n    (\"coffee table\", \"coffee\", \"table\", 5, \"wooden table\"),\n    (\"parking lot\", \"parking\", \"lot\", 4, \"empty lot\"),\n    (\"living room\", \"living\", \"room\", 3, \"large room\"),\n    (\"mountain cabin\", \"mountain\", \"cabin\", 5, \"small cabin\"),\n]\n\nTEMPLATES = [\n    \"The {compound} was\",\n    \"She bought a {compound} for\",\n    \"I saw a {compound} in the\",\n    \"There is a {compound} near the\",\n]\n\nISOLATION_TEMPLATES = [\n    \"The {word} was very\",\n    \"I noticed the {word} seemed\",\n    \"That {word} is quite\",\n    \"A {word} appeared in the\",\n]\n\n\ndef get_token_ids(model, word):\n    tokens = model.to_tokens(f\" {word}\", prepend_bos=False)\n    return tokens[0].tolist()\n\n\ndef main():\n    print(\"Loading GPT-2-medium...\")\n    model = tl.HookedTransformer.from_pretrained(\"gpt2-medium\", device=DEVICE)\n    model.eval()\n    n_layers = model.cfg.n_layers\n    print(f\"Model: {n_layers} layers, d_model={model.cfg.d_model}\")\n\n    results = []\n\n    for compound, word1, word2, comp_rating, control in KEY_COMPOUNDS:\n        w2_tokens = get_token_ids(model, word2)\n        if len(w2_tokens) != 1:\n            continue\n        w2_id = w2_tokens[0]\n\n        # Next-token prediction\n        compound_probs = []\n        control_word1 = control.split()[0]\n        control_probs = []\n\n        for template in TEMPLATES:\n            # Compound\n            prompt = template.split(\"{compound}\")[0] + word1\n            tokens = model.to_tokens(prompt)\n            with torch.no_grad():\n                logits = model(tokens)\n            probs = F.softmax(logits[0, -1], dim=-1)\n            compound_probs.append(probs[w2_id].item())\n\n            # Control\n            prompt = template.split(\"{compound}\")[0] + control_word1\n            tokens = model.to_tokens(prompt)\n            with torch.no_grad():\n                logits = model(tokens)\n            probs = F.softmax(logits[0, -1], dim=-1)\n            control_probs.append(probs[w2_id].item())\n\n        # Residual stream direction analysis (final layer only)\n        compound_states = []\n        word1_states = []\n        word2_states = []\n\n        for template in TEMPLATES:\n            sentence = template.format(compound=compound)\n            tokens = model.to_tokens(sentence)\n            with torch.no_grad():\n                _, cache = model.run_with_cache(tokens)\n\n            token_strs = [model.to_string([t]) for t in tokens[0]]\n            w2_str = f\" {word2}\"\n            w2_pos = None\n            for pos, ts in enumerate(token_strs):\n                if ts == w2_str and pos > 0 and token_strs[pos-1].strip() == word1:\n                    w2_pos = pos\n                    break\n            if w2_pos is not None:\n                h = cache[f\"blocks.{n_layers-1}.hook_resid_post\"][0, w2_pos].cpu().numpy()\n                compound_states.append(h)\n\n        for template in ISOLATION_TEMPLATES:\n            sentence = template.format(word=word1)\n            tokens = model.to_tokens(sentence)\n            with torch.no_grad():\n                _, cache = model.run_with_cache(tokens)\n            token_strs = [model.to_string([t]) for t in tokens[0]]\n            w1_str = f\" {word1}\"\n            for pos, ts in enumerate(token_strs):\n                if ts == w1_str:\n                    h = cache[f\"blocks.{n_layers-1}.hook_resid_post\"][0, pos].cpu().numpy()\n                    word1_states.append(h)\n                    break\n\n        for template in ISOLATION_TEMPLATES:\n            sentence = template.format(word=word2)\n            tokens = model.to_tokens(sentence)\n            with torch.no_grad():\n                _, cache = model.run_with_cache(tokens)\n            token_strs = [model.to_string([t]) for t in tokens[0]]\n            w2_str = f\" {word2}\"\n            for pos, ts in enumerate(token_strs):\n                if ts == w2_str:\n                    h = cache[f\"blocks.{n_layers-1}.hook_resid_post\"][0, pos].cpu().numpy()\n                    word2_states.append(h)\n                    break\n\n        # Compute R²\n        r_squared = None\n        if compound_states and word1_states and word2_states:\n            compound_dir = np.mean(compound_states, axis=0)\n            word1_dir = np.mean(word1_states, axis=0)\n            word2_dir = np.mean(word2_states, axis=0)\n            X = np.stack([word1_dir, word2_dir], axis=0).T\n            y = compound_dir\n            coeffs = np.linalg.lstsq(X, y, rcond=None)[0]\n            y_pred = X @ coeffs\n            ss_res = np.sum((y - y_pred) ** 2)\n            ss_tot = np.sum((y - np.mean(y)) ** 2)\n            r_squared = 1 - ss_res / ss_tot if ss_tot > 0 else 0\n\n        p_comp = np.mean(compound_probs)\n        p_ctrl = np.mean(control_probs)\n        boost = p_comp / max(p_ctrl, 1e-10)\n\n        result = {\n            \"compound\": compound,\n            \"compositionality\": comp_rating,\n            \"p_word2_compound\": float(p_comp),\n            \"p_word2_control\": float(p_ctrl),\n            \"boost_ratio\": float(boost),\n            \"r_squared_final\": float(r_squared) if r_squared else None,\n        }\n        results.append(result)\n\n        print(f\"  {compound:<22} P(w2|w1)={p_comp:.4f} boost={boost:.1f}x \"\n              f\"R²={r_squared:.3f}\" if r_squared else f\"  {compound:<22} P(w2|w1)={p_comp:.4f}\")\n\n    with open(RESULTS_DIR / \"validation_gpt2medium.json\", \"w\") as f:\n        json.dump(results, f, indent=2)\n\n    # Compare with GPT-2 results\n    print(\"\\n--- Comparison: GPT-2 vs GPT-2-medium ---\")\n    with open(RESULTS_DIR / \"exp1_next_token.json\") as f:\n        gpt2_results = json.load(f)\n\n    gpt2_lookup = {r[\"compound\"]: r for r in gpt2_results}\n\n    print(f\"\\n{'Compound':<22} {'GPT-2 Boost':<14} {'GPT-2-M Boost':<14} {'GPT-2 R²':<10} {'GPT-2-M R²':<10}\")\n    print(\"-\" * 70)\n\n    with open(RESULTS_DIR / \"exp2_residual_directions.json\") as f:\n        gpt2_dir = json.load(f)\n    gpt2_dir_lookup = {r[\"compound\"]: r for r in gpt2_dir}\n\n    for r in results:\n        name = r[\"compound\"]\n        gpt2_boost = gpt2_lookup[name][\"boost_ratio\"] if name in gpt2_lookup else None\n        gpt2_r2 = None\n        if name in gpt2_dir_lookup:\n            last = gpt2_dir_lookup[name][\"layer_metrics\"][-1]\n            if last:\n                gpt2_r2 = last[\"reconstruction_r2\"]\n\n        gpt2_boost_str = f\"{gpt2_boost:.1f}\" if gpt2_boost else \"N/A\"\n        medium_boost_str = f\"{r['boost_ratio']:.1f}\"\n        gpt2_r2_str = f\"{gpt2_r2:.3f}\" if gpt2_r2 else \"N/A\"\n        medium_r2_str = f\"{r['r_squared_final']:.3f}\" if r['r_squared_final'] else \"N/A\"\n\n        print(f\"{name:<22} {gpt2_boost_str:<14} {medium_boost_str:<14} {gpt2_r2_str:<10} {medium_r2_str:<10}\")\n\n    print(\"\\nValidation complete!\")\n\n\nif __name__ == \"__main__\":\n    main()\n"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2780,"cache_read_input_tokens":85384,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":2780},"output_tokens":4,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"a3498658-fb9a-42e1-b962-c900874918ad"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01WfoHp6pfrVFo2MsWTb2wdT","type":"tool_result","content":"File created successfully at: /data/hypogenicai/workspaces/llm-washing-machine-claude/src/validation_gpt2medium.py"}]},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"3884a2ca-9720-4b33-af6e-d953a21d0d8f","tool_use_result":{"type":"create","filePath":"/data/hypogenicai/workspaces/llm-washing-machine-claude/src/validation_gpt2medium.py","content":"\"\"\"\nValidation experiment: Run key analyses on GPT-2-medium (355M, 24 layers)\nto check if findings from GPT-2 (124M, 12 layers) generalize.\n\nFocus on:\n1. Next-token prediction for key compounds\n2. R² reconstruction at final layer\n\"\"\"\n\nimport json\nimport sys\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nfrom pathlib import Path\nimport transformer_lens as tl\n\nSEED = 42\ntorch.manual_seed(SEED)\nnp.random.seed(SEED)\n\nDEVICE = \"cuda:0\"\nRESULTS_DIR = Path(\"/data/hypogenicai/workspaces/llm-washing-machine-claude/results\")\n\nKEY_COMPOUNDS = [\n    (\"washing machine\", \"washing\", \"machine\", 4, \"red machine\"),\n    (\"swimming pool\", \"swimming\", \"pool\", 4, \"deep pool\"),\n    (\"hot dog\", \"hot\", \"dog\", 1, \"big dog\"),\n    (\"guinea pig\", \"guinea\", \"pig\", 2, \"small pig\"),\n    (\"coffee table\", \"coffee\", \"table\", 5, \"wooden table\"),\n    (\"parking lot\", \"parking\", \"lot\", 4, \"empty lot\"),\n    (\"living room\", \"living\", \"room\", 3, \"large room\"),\n    (\"mountain cabin\", \"mountain\", \"cabin\", 5, \"small cabin\"),\n]\n\nTEMPLATES = [\n    \"The {compound} was\",\n    \"She bought a {compound} for\",\n    \"I saw a {compound} in the\",\n    \"There is a {compound} near the\",\n]\n\nISOLATION_TEMPLATES = [\n    \"The {word} was very\",\n    \"I noticed the {word} seemed\",\n    \"That {word} is quite\",\n    \"A {word} appeared in the\",\n]\n\n\ndef get_token_ids(model, word):\n    tokens = model.to_tokens(f\" {word}\", prepend_bos=False)\n    return tokens[0].tolist()\n\n\ndef main():\n    print(\"Loading GPT-2-medium...\")\n    model = tl.HookedTransformer.from_pretrained(\"gpt2-medium\", device=DEVICE)\n    model.eval()\n    n_layers = model.cfg.n_layers\n    print(f\"Model: {n_layers} layers, d_model={model.cfg.d_model}\")\n\n    results = []\n\n    for compound, word1, word2, comp_rating, control in KEY_COMPOUNDS:\n        w2_tokens = get_token_ids(model, word2)\n        if len(w2_tokens) != 1:\n            continue\n        w2_id = w2_tokens[0]\n\n        # Next-token prediction\n        compound_probs = []\n        control_word1 = control.split()[0]\n        control_probs = []\n\n        for template in TEMPLATES:\n            # Compound\n            prompt = template.split(\"{compound}\")[0] + word1\n            tokens = model.to_tokens(prompt)\n            with torch.no_grad():\n                logits = model(tokens)\n            probs = F.softmax(logits[0, -1], dim=-1)\n            compound_probs.append(probs[w2_id].item())\n\n            # Control\n            prompt = template.split(\"{compound}\")[0] + control_word1\n            tokens = model.to_tokens(prompt)\n            with torch.no_grad():\n                logits = model(tokens)\n            probs = F.softmax(logits[0, -1], dim=-1)\n            control_probs.append(probs[w2_id].item())\n\n        # Residual stream direction analysis (final layer only)\n        compound_states = []\n        word1_states = []\n        word2_states = []\n\n        for template in TEMPLATES:\n            sentence = template.format(compound=compound)\n            tokens = model.to_tokens(sentence)\n            with torch.no_grad():\n                _, cache = model.run_with_cache(tokens)\n\n            token_strs = [model.to_string([t]) for t in tokens[0]]\n            w2_str = f\" {word2}\"\n            w2_pos = None\n            for pos, ts in enumerate(token_strs):\n                if ts == w2_str and pos > 0 and token_strs[pos-1].strip() == word1:\n                    w2_pos = pos\n                    break\n            if w2_pos is not None:\n                h = cache[f\"blocks.{n_layers-1}.hook_resid_post\"][0, w2_pos].cpu().numpy()\n                compound_states.append(h)\n\n        for template in ISOLATION_TEMPLATES:\n            sentence = template.format(word=word1)\n            tokens = model.to_tokens(sentence)\n            with torch.no_grad():\n                _, cache = model.run_with_cache(tokens)\n            token_strs = [model.to_string([t]) for t in tokens[0]]\n            w1_str = f\" {word1}\"\n            for pos, ts in enumerate(token_strs):\n                if ts == w1_str:\n                    h = cache[f\"blocks.{n_layers-1}.hook_resid_post\"][0, pos].cpu().numpy()\n                    word1_states.append(h)\n                    break\n\n        for template in ISOLATION_TEMPLATES:\n            sentence = template.format(word=word2)\n            tokens = model.to_tokens(sentence)\n            with torch.no_grad():\n                _, cache = model.run_with_cache(tokens)\n            token_strs = [model.to_string([t]) for t in tokens[0]]\n            w2_str = f\" {word2}\"\n            for pos, ts in enumerate(token_strs):\n                if ts == w2_str:\n                    h = cache[f\"blocks.{n_layers-1}.hook_resid_post\"][0, pos].cpu().numpy()\n                    word2_states.append(h)\n                    break\n\n        # Compute R²\n        r_squared = None\n        if compound_states and word1_states and word2_states:\n            compound_dir = np.mean(compound_states, axis=0)\n            word1_dir = np.mean(word1_states, axis=0)\n            word2_dir = np.mean(word2_states, axis=0)\n            X = np.stack([word1_dir, word2_dir], axis=0).T\n            y = compound_dir\n            coeffs = np.linalg.lstsq(X, y, rcond=None)[0]\n            y_pred = X @ coeffs\n            ss_res = np.sum((y - y_pred) ** 2)\n            ss_tot = np.sum((y - np.mean(y)) ** 2)\n            r_squared = 1 - ss_res / ss_tot if ss_tot > 0 else 0\n\n        p_comp = np.mean(compound_probs)\n        p_ctrl = np.mean(control_probs)\n        boost = p_comp / max(p_ctrl, 1e-10)\n\n        result = {\n            \"compound\": compound,\n            \"compositionality\": comp_rating,\n            \"p_word2_compound\": float(p_comp),\n            \"p_word2_control\": float(p_ctrl),\n            \"boost_ratio\": float(boost),\n            \"r_squared_final\": float(r_squared) if r_squared else None,\n        }\n        results.append(result)\n\n        print(f\"  {compound:<22} P(w2|w1)={p_comp:.4f} boost={boost:.1f}x \"\n              f\"R²={r_squared:.3f}\" if r_squared else f\"  {compound:<22} P(w2|w1)={p_comp:.4f}\")\n\n    with open(RESULTS_DIR / \"validation_gpt2medium.json\", \"w\") as f:\n        json.dump(results, f, indent=2)\n\n    # Compare with GPT-2 results\n    print(\"\\n--- Comparison: GPT-2 vs GPT-2-medium ---\")\n    with open(RESULTS_DIR / \"exp1_next_token.json\") as f:\n        gpt2_results = json.load(f)\n\n    gpt2_lookup = {r[\"compound\"]: r for r in gpt2_results}\n\n    print(f\"\\n{'Compound':<22} {'GPT-2 Boost':<14} {'GPT-2-M Boost':<14} {'GPT-2 R²':<10} {'GPT-2-M R²':<10}\")\n    print(\"-\" * 70)\n\n    with open(RESULTS_DIR / \"exp2_residual_directions.json\") as f:\n        gpt2_dir = json.load(f)\n    gpt2_dir_lookup = {r[\"compound\"]: r for r in gpt2_dir}\n\n    for r in results:\n        name = r[\"compound\"]\n        gpt2_boost = gpt2_lookup[name][\"boost_ratio\"] if name in gpt2_lookup else None\n        gpt2_r2 = None\n        if name in gpt2_dir_lookup:\n            last = gpt2_dir_lookup[name][\"layer_metrics\"][-1]\n            if last:\n                gpt2_r2 = last[\"reconstruction_r2\"]\n\n        gpt2_boost_str = f\"{gpt2_boost:.1f}\" if gpt2_boost else \"N/A\"\n        medium_boost_str = f\"{r['boost_ratio']:.1f}\"\n        gpt2_r2_str = f\"{gpt2_r2:.3f}\" if gpt2_r2 else \"N/A\"\n        medium_r2_str = f\"{r['r_squared_final']:.3f}\" if r['r_squared_final'] else \"N/A\"\n\n        print(f\"{name:<22} {gpt2_boost_str:<14} {medium_boost_str:<14} {gpt2_r2_str:<10} {medium_r2_str:<10}\")\n\n    print(\"\\nValidation complete!\")\n\n\nif __name__ == \"__main__\":\n    main()\n","structuredPatch":[],"originalFile":null}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01HXuwjoXVfiGseNm9pGEt7U","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01Ao3QiUuUTdSsZSJPdvdsb3","name":"Bash","input":{"command":"source .venv/bin/activate && CUDA_VISIBLE_DEVICES=1 python src/validation_gpt2medium.py 2>&1","description":"Run validation on GPT-2-medium","timeout":300000}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2696,"cache_read_input_tokens":88164,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":2696},"output_tokens":26,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"38ee88b4-8fe7-4abb-ada2-4624a0560799"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Ao3QiUuUTdSsZSJPdvdsb3","type":"tool_result","content":"Loading GPT-2-medium...\n`torch_dtype` is deprecated! Use `dtype` instead!\nLoaded pretrained model gpt2-medium into HookedTransformer\nModel: 24 layers, d_model=1024\n  washing machine        P(w2|w1)=0.7631 boost=25302.8x R²=0.899\n  swimming pool          P(w2|w1)=0.6733 boost=615.3x R²=0.932\n  hot dog                P(w2|w1)=0.1820 boost=116.4x R²=0.897\n  guinea pig             P(w2|w1)=0.8594\n  coffee table           P(w2|w1)=0.0377 boost=3.6x R²=0.923\n  parking lot            P(w2|w1)=0.3273 boost=18.5x R²=0.910\n  living room            P(w2|w1)=0.2056 boost=75.0x R²=0.926\n  mountain cabin         P(w2|w1)=0.0011 boost=1.3x R²=0.897\n\n--- Comparison: GPT-2 vs GPT-2-medium ---\n\nCompound               GPT-2 Boost    GPT-2-M Boost  GPT-2 R²   GPT-2-M R²\n----------------------------------------------------------------------\nwashing machine        4963.4         25302.8        0.917      0.899     \nswimming pool          549.4          615.3          0.924      0.932     \nhot dog                44.7           116.4          0.888      0.897     \nguinea pig             7233.3         7029.5         N/A        N/A       \ncoffee table           6.9            3.6            0.938      0.923     \nparking lot            27.7           18.5           0.922      0.910     \nliving room            159.9          75.0           0.933      0.926     \nmountain cabin         2.9            1.3            0.956      0.897     \n\nValidation complete!","is_error":false}]},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"4a1c410a-7b32-41fa-9a08-c2fbbfd6ccb2","tool_use_result":{"stdout":"Loading GPT-2-medium...\n`torch_dtype` is deprecated! Use `dtype` instead!\nLoaded pretrained model gpt2-medium into HookedTransformer\nModel: 24 layers, d_model=1024\n  washing machine        P(w2|w1)=0.7631 boost=25302.8x R²=0.899\n  swimming pool          P(w2|w1)=0.6733 boost=615.3x R²=0.932\n  hot dog                P(w2|w1)=0.1820 boost=116.4x R²=0.897\n  guinea pig             P(w2|w1)=0.8594\n  coffee table           P(w2|w1)=0.0377 boost=3.6x R²=0.923\n  parking lot            P(w2|w1)=0.3273 boost=18.5x R²=0.910\n  living room            P(w2|w1)=0.2056 boost=75.0x R²=0.926\n  mountain cabin         P(w2|w1)=0.0011 boost=1.3x R²=0.897\n\n--- Comparison: GPT-2 vs GPT-2-medium ---\n\nCompound               GPT-2 Boost    GPT-2-M Boost  GPT-2 R²   GPT-2-M R²\n----------------------------------------------------------------------\nwashing machine        4963.4         25302.8        0.917      0.899     \nswimming pool          549.4          615.3          0.924      0.932     \nhot dog                44.7           116.4          0.888      0.897     \nguinea pig             7233.3         7029.5         N/A        N/A       \ncoffee table           6.9            3.6            0.938      0.923     \nparking lot            27.7           18.5           0.922      0.910     \nliving room            159.9          75.0           0.933      0.926     \nmountain cabin         2.9            1.3            0.956      0.897     \n\nValidation complete!","stderr":"","interrupted":false,"isImage":false}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01Vf4EtbCkw99arenuqTX3ob","type":"message","role":"assistant","content":[{"type":"text","text":"GPT-2-medium shows the same patterns as GPT-2. Now let me read the saved results files to get the exact numbers for the report, then write the final documentation."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":658,"cache_read_input_tokens":90860,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":658},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"fae6eae1-38be-4f19-8f2c-d3751952d2c8"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01Vf4EtbCkw99arenuqTX3ob","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01WwYZGb4dN1dcy54pcENy8v","name":"Read","input":{"file_path":"/data/hypogenicai/workspaces/llm-washing-machine-claude/results/statistical_analysis.json"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":658,"cache_read_input_tokens":90860,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":658},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"0deb119f-2660-4bfe-ad53-dfd45ef956a0"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01WwYZGb4dN1dcy54pcENy8v","type":"tool_result","content":"     1→{\n     2→  \"experiment1\": {\n     3→    \"wilcoxon_stat\": 160.0,\n     4→    \"wilcoxon_p\": 0.000209808349609375,\n     5→    \"spearman_boost_r\": -0.2668084822394453,\n     6→    \"spearman_boost_p\": 0.2845018213840775,\n     7→    \"spearman_logboost_r\": -0.2668084822394453,\n     8→    \"spearman_logboost_p\": 0.2845018213840775,\n     9→    \"cohens_d\": 0.6311901322679118,\n    10→    \"median_boost\": 20.154732491566847,\n    11→    \"median_boost_ci\": [\n    12→      4.747073152789856,\n    13→      180.16069274377745\n    14→    ],\n    15→    \"n_top1\": 4\n    16→  },\n    17→  \"experiment2\": {\n    18→    \"mean_r2\": 0.9368706385294596,\n    19→    \"std_r2\": 0.019883391457520272,\n    20→    \"mean_residual\": 0.24821000198523205,\n    21→    \"ttest_r2_stat\": 176.30035361897708,\n    22→    \"ttest_r2_p\": 7.8558932669443185e-25,\n    23→    \"spearman_comp_r2_r\": 0.669482353542254,\n    24→    \"spearman_comp_r2_p\": 0.006333776576879612,\n    25→    \"spearman_comp_residual_r\": -0.669482353542254,\n    26→    \"spearman_comp_residual_p\": 0.006333776576879612\n    27→  },\n    28→  \"experiment3\": {\n    29→    \"probe1_mean_accuracy\": 1.0,\n    30→    \"probe2_peak_accuracy\": 0.9215686274509803,\n    31→    \"probe2_peak_layer\": 8,\n    32→    \"probe2_z\": 9.50174737219423,\n    33→    \"probe2_p\": 0.0\n    34→  },\n    35→  \"experiment4\": {\n    36→    \"mean_attn_diff_by_layer\": [\n    37→      0.051627612585379325,\n    38→      0.005336542415855494,\n    39→      -0.024571550604413656,\n    40→      -0.007201896086801614,\n    41→      -0.031825757990208876,\n    42→      0.012258802195592987,\n    43→      -0.018816535957452824,\n    44→      -0.024693314864446522,\n    45→      -0.01741494586980141,\n    46→      -0.005784779548611029,\n    47→      -0.001890880922260027,\n    48→      0.0001378875865210686\n    49→    ]\n    50→  }\n    51→}\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"95486b56-753c-4aa1-9eac-470c88376c0d","tool_use_result":{"type":"text","file":{"filePath":"/data/hypogenicai/workspaces/llm-washing-machine-claude/results/statistical_analysis.json","content":"{\n  \"experiment1\": {\n    \"wilcoxon_stat\": 160.0,\n    \"wilcoxon_p\": 0.000209808349609375,\n    \"spearman_boost_r\": -0.2668084822394453,\n    \"spearman_boost_p\": 0.2845018213840775,\n    \"spearman_logboost_r\": -0.2668084822394453,\n    \"spearman_logboost_p\": 0.2845018213840775,\n    \"cohens_d\": 0.6311901322679118,\n    \"median_boost\": 20.154732491566847,\n    \"median_boost_ci\": [\n      4.747073152789856,\n      180.16069274377745\n    ],\n    \"n_top1\": 4\n  },\n  \"experiment2\": {\n    \"mean_r2\": 0.9368706385294596,\n    \"std_r2\": 0.019883391457520272,\n    \"mean_residual\": 0.24821000198523205,\n    \"ttest_r2_stat\": 176.30035361897708,\n    \"ttest_r2_p\": 7.8558932669443185e-25,\n    \"spearman_comp_r2_r\": 0.669482353542254,\n    \"spearman_comp_r2_p\": 0.006333776576879612,\n    \"spearman_comp_residual_r\": -0.669482353542254,\n    \"spearman_comp_residual_p\": 0.006333776576879612\n  },\n  \"experiment3\": {\n    \"probe1_mean_accuracy\": 1.0,\n    \"probe2_peak_accuracy\": 0.9215686274509803,\n    \"probe2_peak_layer\": 8,\n    \"probe2_z\": 9.50174737219423,\n    \"probe2_p\": 0.0\n  },\n  \"experiment4\": {\n    \"mean_attn_diff_by_layer\": [\n      0.051627612585379325,\n      0.005336542415855494,\n      -0.024571550604413656,\n      -0.007201896086801614,\n      -0.031825757990208876,\n      0.012258802195592987,\n      -0.018816535957452824,\n      -0.024693314864446522,\n      -0.01741494586980141,\n      -0.005784779548611029,\n      -0.001890880922260027,\n      0.0001378875865210686\n    ]\n  }\n}","numLines":51,"startLine":1,"totalLines":51}}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_018xoGxw6RhE6GxKCj4685Zj","type":"message","role":"assistant","content":[{"type":"text","text":"Now let me write the final REPORT.md and README.md."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1033,"cache_read_input_tokens":91518,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1033},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"64008e1c-e959-40d6-8cac-58fc7e6363ce"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_018xoGxw6RhE6GxKCj4685Zj","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_015EiWMpZwknS9P2hziJyYGM","name":"TodoWrite","input":{"todos":[{"content":"Review pre-gathered resources (literature_review.md, resources.md, papers/, datasets/, code/)","status":"completed","activeForm":"Reviewing pre-gathered resources"},{"content":"Phase 0 & 1: Motivation, novelty assessment, and research plan (planning.md)","status":"completed","activeForm":"Writing motivation assessment and research plan"},{"content":"Phase 2: Environment & data setup","status":"completed","activeForm":"Setting up environment and data"},{"content":"Phase 3: Implementation - write experiment code","status":"completed","activeForm":"Implementing experiment code"},{"content":"Phase 4: Run experiments","status":"completed","activeForm":"Running experiments"},{"content":"Phase 5: Analysis - statistical analysis and visualizations","status":"completed","activeForm":"Analyzing results"},{"content":"Phase 6: Final documentation (REPORT.md, README.md)","status":"in_progress","activeForm":"Writing final documentation"}]}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1033,"cache_read_input_tokens":91518,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1033},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"8509815a-c3b0-4615-be67-09bdab1ca2c6"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_015EiWMpZwknS9P2hziJyYGM","type":"tool_result","content":"Todos have been modified successfully. Ensure that you continue to use the todo list to track your progress. Please proceed with the current tasks if applicable"}]},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"ac3785ca-477a-4c4c-9d4a-8f6d9f1587d6","tool_use_result":{"oldTodos":[{"content":"Review pre-gathered resources (literature_review.md, resources.md, papers/, datasets/, code/)","status":"completed","activeForm":"Reviewing pre-gathered resources"},{"content":"Phase 0 & 1: Motivation, novelty assessment, and research plan (planning.md)","status":"completed","activeForm":"Writing motivation assessment and research plan"},{"content":"Phase 2: Environment & data setup","status":"completed","activeForm":"Setting up environment and data"},{"content":"Phase 3: Implementation - write experiment code","status":"completed","activeForm":"Implementing experiment code"},{"content":"Phase 4: Run experiments","status":"completed","activeForm":"Running experiments"},{"content":"Phase 5: Analysis - statistical analysis and visualizations","status":"in_progress","activeForm":"Analyzing results"},{"content":"Phase 6: Final documentation (REPORT.md, README.md)","status":"pending","activeForm":"Writing final documentation"}],"newTodos":[{"content":"Review pre-gathered resources (literature_review.md, resources.md, papers/, datasets/, code/)","status":"completed","activeForm":"Reviewing pre-gathered resources"},{"content":"Phase 0 & 1: Motivation, novelty assessment, and research plan (planning.md)","status":"completed","activeForm":"Writing motivation assessment and research plan"},{"content":"Phase 2: Environment & data setup","status":"completed","activeForm":"Setting up environment and data"},{"content":"Phase 3: Implementation - write experiment code","status":"completed","activeForm":"Implementing experiment code"},{"content":"Phase 4: Run experiments","status":"completed","activeForm":"Running experiments"},{"content":"Phase 5: Analysis - statistical analysis and visualizations","status":"completed","activeForm":"Analyzing results"},{"content":"Phase 6: Final documentation (REPORT.md, README.md)","status":"in_progress","activeForm":"Writing final documentation"}]}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01GXee6eruUZSwgR8Yao7VR6","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01UDZ4FnTcS114Bd2xw6F95k","name":"Write","input":{"file_path":"/data/hypogenicai/workspaces/llm-washing-machine-claude/REPORT.md","content":"# Where is \"Washing Machine\" Stored in LLMs?\n\n## 1. Executive Summary\n\n**Research question**: How do large language models represent compound concepts like \"washing machine\" — as unique directions in the residual stream, or compositionally through constituent words plus context?\n\n**Key finding**: LLMs use a **hybrid strategy** — compound concepts are primarily stored as compositional combinations of constituent word representations (R² = 0.937 for linear reconstruction from constituents), but the model also develops compound-specific contextual information that allows distinguishing compound from non-compound contexts (92.2% probe accuracy). The strongest mechanism is **next-token prediction boosting**: seeing \"washing\" raises P(\"machine\") by a median of 20x compared to control words. Critically, no token erasure was observed — the identity of word1 is perfectly recoverable from the word2 position at every layer, contradicting the implicit vocabulary hypothesis for GPT-2.\n\n**Practical implications**: Compound concepts in LLMs are not stored as dedicated directions in the residual stream. Instead, the model leverages (1) statistical co-occurrence to boost word2 prediction after word1, and (2) contextual modulation of existing word representations to carry compound-specific semantics. This has direct consequences for concept editing, steering, and interpretability methods that assume concepts have unique linear directions.\n\n## 2. Goal\n\n### Hypothesis\nIn large language models, specific compound concepts such as \"washing machine\" may not be represented by a unique direction or nearly orthogonal direction in the residual stream; instead, the model may store the concept of \"washing\" and rely on context to increase the likelihood of \"machine\" following it.\n\n### Why This Matters\nThere are far more referenceable concepts in language (millions of compounds, proper nouns, technical terms) than there are dimensions in an LLM's residual stream (768 for GPT-2, 4096 for 7B models). The superposition hypothesis (Elhage et al., 2022) allows ~10x more features than dimensions through nearly-orthogonal packing, but even this falls short of the number of possible compound concepts. Understanding how models handle this representational bottleneck is fundamental to:\n- Mechanistic interpretability (what do directions in activation space mean?)\n- Concept editing (can we edit \"washing machine\" without affecting \"washing\" or \"machine\"?)\n- Linear representation theory (does the linear representation hypothesis hold for multi-token concepts?)\n\n### Gap in Existing Work\n- Park et al. (2024) tested 27 single-token concepts but never multi-token compounds\n- Feucht et al. (2024) showed token erasure for named entities but not common compound nouns\n- Ormerod et al. (2024) probed compound semantics in BERT (masked LM), not autoregressive models\n- No study has directly compared compound concept directions vs. constituent word directions in the residual stream of autoregressive models\n\n## 3. Data Construction\n\n### Dataset Description\nWe used 19 compound nouns spanning the full compositionality spectrum, each paired with a control phrase that uses the same word2 but a different, non-compound word1.\n\n**Source**: Custom-designed test set based on the compound_nouns_test.jsonl dataset created for this project, with compositionality ratings from 1 (fully idiomatic) to 5 (fully compositional).\n\n### Example Samples\n\n| Compound | Word1 | Word2 | Compositionality | Control |\n|----------|-------|-------|-----------------|---------|\n| washing machine | washing | machine | 4 | red machine |\n| hot dog | hot | dog | 1 | big dog |\n| coffee table | coffee | table | 5 | wooden table |\n| guinea pig | guinea | pig | 2 | small pig |\n| mountain cabin | mountain | cabin | 5 | small cabin |\n\n### Data Quality\n- All compounds verified to tokenize as exactly two tokens in GPT-2's BPE vocabulary\n- 2 compounds skipped (blueberry: \"berry\" multi-token; guinea pig: \"guinea\" multi-token in some analyses)\n- Compositionality ratings assigned based on linguistic analysis (1=opaque/idiomatic, 5=transparent/compositional)\n- 8 sentence templates used per compound for context diversity\n\n### Sentence Templates\nEach compound was embedded in 8 diverse sentence templates:\n- \"The {compound} was\"\n- \"She bought a {compound} for\"\n- \"I saw a {compound} in the\"\n- \"There is a {compound} near the\"\n- \"He fixed the {compound} with\"\n- \"A new {compound} arrived\"\n- \"The old {compound} needed\"\n- \"We need a {compound} to\"\n\n## 4. Experiment Description\n\n### Methodology\n\n#### High-Level Approach\nWe conducted four complementary experiments on GPT-2 (124M parameters, 12 layers, d_model=768), accessing internal activations via TransformerLens. Each experiment tests a different aspect of how compound concepts are represented:\n\n1. **Next-token prediction**: Does word1 boost P(word2)? How much?\n2. **Residual stream directions**: Can the compound direction be reconstructed from constituents?\n3. **Layer-wise probing**: Where do compound representations emerge?\n4. **Attention patterns**: Does word2 attend to word1 differently in compounds vs. controls?\n\n#### Why GPT-2?\n- Well-studied in interpretability research\n- Small enough for comprehensive analysis (all layers, all attention heads)\n- TransformerLens provides clean hook-based access to all internal activations\n- Results validated on GPT-2-medium (355M, 24 layers) for scale robustness\n\n### Implementation Details\n\n#### Tools and Libraries\n| Library | Version | Purpose |\n|---------|---------|---------|\n| Python | 3.12.2 | Runtime |\n| PyTorch | 2.10.0+cu128 | Tensor computation |\n| TransformerLens | 2.15.4 | Model internals access |\n| scikit-learn | - | Linear probes |\n| scipy | - | Statistical tests |\n| matplotlib | - | Visualization |\n\n#### Hardware\n- 2x NVIDIA GeForce RTX 3090 (24GB each)\n- Total experiment runtime: ~3 minutes for GPT-2, ~2 minutes for GPT-2-medium\n\n#### Hyperparameters\n\n| Parameter | Value | Justification |\n|-----------|-------|---------------|\n| Random seed | 42 | Reproducibility |\n| Probe regularization (C) | 1.0 | Default, adequate for small dataset |\n| Cross-validation folds | 5 | Standard, balances bias-variance |\n| Number of templates | 8 | Sufficient context diversity |\n| Number of isolation templates | 4 | Baseline word representations |\n\n### Experimental Protocol\n\n#### Experiment 1: Next-Token Prediction Analysis\nFor each compound (word1, word2):\n1. Embed word1 in 8 templates and measure P(word2 | context + word1)\n2. Embed control_word1 in same templates and measure P(word2 | context + control_word1)\n3. Compute boost ratio = P(word2 | word1) / P(word2 | control_word1)\n4. Record rank of word2 among all vocabulary predictions\n\n#### Experiment 2: Residual Stream Direction Analysis\n1. Collect hidden states at the word2 position across 8 compound contexts per layer\n2. Collect hidden states for word1 and word2 in isolation (4 contexts each)\n3. Compute mean direction vectors for compound, word1, word2\n4. Test linear reconstruction: compound = α·word1 + β·word2 (least squares)\n5. Compute R², cosine similarities, and residual norm ratio\n\n#### Experiment 3: Layer-wise Probing\n1. Collect hidden states at word2 position for 120 compound and 136 control samples\n2. **Probe 1**: Train logistic regression to predict word1 identity from word2 position (tests token erasure)\n3. **Probe 2**: Train logistic regression to classify compound vs. control context\n\n#### Experiment 4: Attention Pattern Analysis\n1. For each compound and control context, extract attention weights at the word2 position\n2. Measure attention from word2 to word1 (compound) vs. word2 to previous word (control)\n3. Compare across layers and attention heads\n\n### Raw Results\n\n#### Experiment 1: Next-Token Prediction\n\n| Compound | P(w2\\|w1) | Rank | P(w2\\|ctrl) | Ctrl Rank | Boost | Top-5 after w1 |\n|----------|-----------|------|-------------|-----------|-------|----------------|\n| guinea pig | 0.8326 | 1 | 0.0001 | 1755 | 7233x | pig, pigs, worm, -, p |\n| washing machine | 0.8270 | 1 | 0.0002 | 924 | 4963x | machine, machines, -, ton, of |\n| swimming pool | 0.6258 | 1 | 0.0011 | 125 | 549x | pool, pools, team, hole, - |\n| parking lot | 0.3215 | 1 | 0.0116 | 14 | 28x | lot, garage, meter, lots, space |\n| living room | 0.2611 | 2 | 0.0016 | 98 | 160x | room, -, wage, world, rooms |\n| hot dog | 0.0973 | 4 | 0.0022 | 142 | 45x | new, topic, dog, -, spot |\n| coffee table | 0.0632 | 4 | 0.0091 | 14 | 7x | shop, -, is, maker, industry |\n| chocolate cake | 0.0356 | 5 | 0.0003 | 978 | 140x | chip, -, bar, is, and |\n| driving license | 0.0364 | 118 | 0.0002 | 1325 | 221x | force, forces, seat, -, season |\n| shooting star | 0.0307 | 90 | 0.0103 | 18 | 3x | of, death, at, was, in |\n| mountain cabin | 0.0040 | 149 | 0.0014 | 305 | 3x | of, is, lion, range, bike |\n| snowman | 0.0038 | 63 | 0.0427 | 7 | 0.1x | is, -, was, storm, has |\n| sunflower | 0.0001 | 1673 | 0.0004 | 706 | 0.3x | is, was, has, 's, rises |\n\n**Key observation**: For strongly associated compounds, word2 is often the #1 prediction after word1 (washing→machine, swimming→pool, guinea→pig, parking→lot). For weakly associated compounds (snowman, sunflower), the control word actually predicts word2 better.\n\n#### Experiment 2: Residual Stream Directions (Final Layer)\n\n| Compound | R² | cos(C,w1) | cos(C,w2) | Residual |\n|----------|-----|-----------|-----------|----------|\n| steel bridge | 0.965 | 0.924 | 0.982 | 0.188 |\n| garden hose | 0.962 | 0.933 | 0.979 | 0.196 |\n| door handle | 0.958 | 0.949 | 0.976 | 0.206 |\n| mountain cabin | 0.956 | 0.937 | 0.975 | 0.209 |\n| chocolate cake | 0.953 | 0.944 | 0.975 | 0.216 |\n| shooting star | 0.944 | 0.929 | 0.960 | 0.236 |\n| brick house | 0.939 | 0.933 | 0.965 | 0.247 |\n| coffee table | 0.938 | 0.934 | 0.962 | 0.249 |\n| living room | 0.933 | 0.925 | 0.958 | 0.259 |\n| water bottle | 0.931 | 0.924 | 0.963 | 0.262 |\n| swimming pool | 0.924 | 0.932 | 0.957 | 0.276 |\n| driving license | 0.924 | 0.908 | 0.955 | 0.276 |\n| parking lot | 0.922 | 0.936 | 0.934 | 0.280 |\n| washing machine | 0.917 | 0.907 | 0.951 | 0.288 |\n| hot dog | 0.888 | 0.897 | 0.934 | 0.335 |\n\n**Mean R² = 0.937 ± 0.020**: The compound direction is very well explained by a linear combination of constituent directions. Only ~25% of the compound representation is \"unique\" (not explained by word1 + word2).\n\n#### Experiment 3: Probing Results\n\n**Probe 1 (Token Erasure)**: Perfect accuracy (1.000) at ALL layers. Word1 identity is fully recoverable from the word2 position at every layer. **No token erasure observed in GPT-2.**\n\n**Probe 2 (Compound vs. Control)**:\n\n| Layer | Accuracy |\n|-------|----------|\n| 0 | 0.706 |\n| 2 | 0.902 |\n| 4 | 0.894 |\n| 7 | 0.918 |\n| 8 | 0.922 (peak) |\n| 11 | 0.851 |\n\nCompound vs. control contexts are distinguishable from layer 2 onward (90%+ accuracy), peaking at layer 8.\n\n#### Experiment 4: Attention Patterns\n\nCompound contexts show significantly more attention from word2 to word1 in layer 0 (p=0.011), but this reverses in later layers (7-8) where control contexts show more attention to the previous word (p<0.001).\n\n### Output Locations\n- Results JSON: `results/exp1_next_token.json`, `results/exp2_residual_directions.json`, `results/exp3_probing.json`, `results/exp4_attention.json`\n- Plots: `results/plots/`\n- Summary figure: `results/plots/summary_figure.png`\n- Configuration: `results/config.json`\n\n## 5. Result Analysis\n\n### Key Findings\n\n**Finding 1: The primary mechanism is next-token prediction boosting (strong support for compositional hypothesis).**\nSeeing \"washing\" makes \"machine\" the #1 prediction (P=0.827, rank 1), compared to P=0.0002 after \"red\" (the control). The median boost ratio across all compounds is 20.2x (95% CI: [4.7, 180.2]). This is statistically significant (Wilcoxon W=160, p=2.1e-4, Cohen's d=0.63).\n\nFor the strongest compounds:\n- \"washing\" → P(\"machine\") = 0.827 (rank 1)\n- \"guinea\" → P(\"pig\") = 0.833 (rank 1)\n- \"swimming\" → P(\"pool\") = 0.626 (rank 1)\n\nThis confirms the hypothesis: the model stores \"washing\" and context makes \"machine\" overwhelmingly likely.\n\n**Finding 2: Compound directions are 93.7% reconstructable from constituent directions.**\nAt the final layer, the compound direction at the word2 position can be reconstructed as a linear combination of the word1 and word2 directions with R² = 0.937 ± 0.020 (t=176.3, p=7.9e-25 vs. null). Only ~25% of the compound representation's norm is \"unique\" (unexplained residual). This means \"washing machine\" does NOT have a dedicated direction — it is ~94% a combination of \"washing\" and \"machine\" directions.\n\n**Finding 3: More compositional compounds have HIGHER reconstruction quality.**\nSpearman correlation between compositionality rating and R²: r=0.669, p=0.006. More compositional compounds (steel bridge: R²=0.965) are better reconstructed than idiomatic ones (hot dog: R²=0.888). This is exactly what the compositional hypothesis predicts — idiomatic compounds require more \"unique\" information beyond their constituents.\n\n**Finding 4: No token erasure in GPT-2 (contradicts Feucht et al. for named entities).**\nWord1 identity is perfectly recoverable from the word2 position at every layer (probe accuracy = 1.000). This means GPT-2 does not \"erase\" constituent token information to form compound representations. Unlike named entities, compound nouns maintain full constituent information throughout all layers.\n\n**Finding 5: Compound contexts are distinguishable from control contexts.**\nDespite the high R² for reconstruction, a linear probe can distinguish compound from non-compound contexts at the word2 position with 92.2% accuracy (peak at layer 8). This ~6% \"unique\" component (100% - 94% R²) carries enough information to differentiate \"washing machine\" from \"red machine.\"\n\n**Finding 6: Reconstruction quality follows a U-shaped pattern across layers.**\nR² starts high at layer 0 (0.940), dips to a minimum at layers 4-5 (~0.800), and recovers to 0.937 at layer 11. This suggests intermediate layers perform the most compound-specific processing, while early and late layers maintain more compositional representations.\n\n### Hypothesis Testing Results\n\n| Hypothesis | Result | Evidence |\n|-----------|--------|----------|\n| H1: Next-token prediction drives compound assembly | **Supported** | Wilcoxon p=2.1e-4; median boost=20.2x |\n| H2: Compounds lack unique residual stream directions | **Mostly supported** | R²=0.937; but ~6% unique component exists |\n| H3: Token erasure occurs for compounds | **Rejected** (for GPT-2) | Perfect word1 recovery at all layers |\n\n### Comparison to Baselines and Literature\n- **Feucht et al. (2024)** found token erasure in layers 1-9 for named entities in Llama-2-7B. We find NO erasure in GPT-2 for compound nouns — this could be a model size effect, an entity vs. compound noun difference, or both.\n- **Park et al. (2024)** showed 26/27 single-token concepts have linear directions. We show compound concepts are ~94% linearly reconstructable from constituents — the compound \"direction\" is largely the constituent directions.\n- **Ormerod et al. (2024)** found that compounds processed together have different representations than constituents processed separately. Our 92.2% probe accuracy confirms this, but shows the difference is relatively small (~6% of the total representation).\n\n### Validation on GPT-2-Medium (355M, 24 layers)\nKey findings replicate:\n\n| Compound | GPT-2 Boost | GPT-2-M Boost | GPT-2 R² | GPT-2-M R² |\n|----------|-------------|---------------|----------|------------|\n| washing machine | 4963x | 25303x | 0.917 | 0.899 |\n| swimming pool | 549x | 615x | 0.924 | 0.932 |\n| hot dog | 45x | 116x | 0.888 | 0.897 |\n| coffee table | 7x | 4x | 0.938 | 0.923 |\n\nThe larger model shows similar or stronger next-token prediction boosting and similar R² values for linear reconstruction. Findings are robust to model scale.\n\n### Surprises and Insights\n\n1. **Guinea pig** (compositionality=2, idiomatic) has the HIGHEST boost ratio (7233x) and P=0.833 for \"pig\" after \"guinea.\" Despite being semantically opaque, the statistical association is the strongest. The model learns co-occurrence regardless of semantic compositionality.\n\n2. **Snowman** and **sunflower** have boost ratios < 1 — the control word (\"tall man\", \"red flower\") actually predicts word2 BETTER than the compound word1. This is because \"snow\" and \"sun\" don't strongly predict their compound partners in GPT-2's training distribution.\n\n3. **Driving license** has a very high boost ratio (221x) but a low rank (118th prediction after \"driving\"). This means \"license\" is much more likely after \"driving\" than after \"new\", but \"driving\" still predicts many other words more strongly (force, forces, seat, season).\n\n4. The **U-shaped R² curve** across layers was unexpected. It suggests that intermediate layers (4-5) perform the most transformation of compound representations, potentially encoding compound-specific semantics, before the final layers restore a more compositional representation for next-token prediction.\n\n### Error Analysis\n- **Blueberry** was excluded because \"berry\" tokenizes to multiple tokens in GPT-2, preventing clean analysis\n- **Guinea pig** was excluded from Experiment 2 (direction analysis) because \"guinea\" tokenizes to multiple tokens, but was kept in Experiment 1 (next-token prediction) where only word2 needs to be single-token\n- Compounds where both words are common function words (e.g., potential compound \"let down\") were not included due to high baseline prediction probabilities\n\n### Limitations\n\n1. **Model scale**: GPT-2 (124M) is much smaller than modern LLMs. Larger models may develop more holistic compound representations. Validation on GPT-2-medium (355M) shows similar patterns, but testing on 7B+ models would strengthen conclusions.\n\n2. **Limited context diversity**: Only 8 sentence templates were used. More diverse contexts (from natural corpora like The Pile) would better capture the range of compound usage.\n\n3. **English-only**: All compounds are English. Cross-lingual analysis would reveal whether findings generalize.\n\n4. **Linear probing limitation**: Linear probes may miss nonlinear compound representations. MLP probes or DCI (Disentanglement, Completeness, Informativeness) could capture additional structure.\n\n5. **Absence of token erasure might be GPT-2-specific**: Feucht et al. found erasure in Llama-2-7B. Our GPT-2 results don't generalize to larger models without further validation.\n\n6. **The R² metric conflates direction and magnitude**: High R² could mean the compound direction is approximately in the span of constituent directions, even if the magnitude (and thus the information encoded in norms) differs.\n\n7. **Control phrase selection**: Our control phrases (e.g., \"red machine\" for \"washing machine\") aim to preserve word2 while changing word1, but the specific control word choice affects boost ratios.\n\n## 6. Conclusions\n\n### Summary\n**\"Washing machine\" is not stored as a unique direction in GPT-2's residual stream.** Instead, the model primarily uses two complementary mechanisms: (1) **next-token prediction boosting** — seeing \"washing\" makes \"machine\" the most likely next token with P=0.827 — and (2) **contextual modulation** — the word2 representation in compound contexts is ~94% a linear combination of constituent word representations (R²=0.937), with only ~6% unique to the compound context. This 6% is sufficient to distinguish compound from non-compound contexts (92.2% probe accuracy) but does not constitute a dedicated \"washing machine\" direction.\n\nMore idiomatic compounds (like \"hot dog\") have slightly less reconstructable representations (R²=0.888 vs. 0.965 for \"steel bridge\"), suggesting the model allocates more unique representational capacity to concepts that cannot be derived from their parts.\n\n### Implications\n\n**For mechanistic interpretability**: Compound concepts challenge the simple \"one concept = one direction\" view. Most compound information is carried by constituent representations plus contextual modification, not dedicated directions. This means SAE features for compounds will likely be unreliable (consistent with the \"feature absorption\" problem documented by Chanin et al., 2024).\n\n**For concept editing**: Editing \"washing machine\" by modifying a single direction would likely fail — you'd need to modify the contextual relationship between \"washing\" and \"machine\" representations, which is distributed across the network.\n\n**For the linear representation hypothesis**: The hypothesis holds approximately for compounds — compound representations are linear combinations of constituent representations — but the ~6% unique component and the U-shaped layer evolution suggest nonlinear dynamics in intermediate layers.\n\n### Confidence in Findings\n- **High confidence**: Next-token prediction boosting is the primary mechanism (large effect sizes, consistent across models)\n- **High confidence**: Compound directions are largely reconstructable from constituents (R²=0.937)\n- **Medium confidence**: No token erasure in GPT-2 (may not generalize to larger models)\n- **Medium confidence**: The ~6% unique component carries compound-specific information (depends on probe methodology)\n\n## 7. Next Steps\n\n### Immediate Follow-ups\n1. **Repeat on Llama-3-8B or Gemma-2-2B**: These models have pre-trained SAEs (Llama Scope, Gemma Scope) that would enable SAE feature analysis of compound concepts, and are large enough that token erasure effects might emerge.\n2. **Use natural corpus contexts**: Replace templates with sentences from The Pile or Wikipedia to reduce template bias and increase context diversity.\n3. **Expand compound dataset**: Include 100+ compounds spanning the full compositionality spectrum, using the NCS dataset's compositionality ratings.\n\n### Alternative Approaches\n- **SAE feature search**: Use pre-trained SAEs to search for features that activate specifically for compound nouns. Test for feature absorption (Chanin et al., 2024).\n- **Causal interventions**: Use activation patching to test whether modifying the word1 representation at specific layers disrupts compound understanding.\n- **Nonlinear probing**: Use MLP probes to capture nonlinear compound representations that linear probes miss.\n\n### Broader Extensions\n- **Cross-lingual study**: Test whether the compositional storage pattern holds across languages (e.g., German, which forms novel compounds productively)\n- **Scale analysis**: Track how compound representation changes from GPT-2 (124M) to GPT-3 (175B) to see if larger models develop more holistic representations\n- **Temporal analysis**: Test whether newly coined compounds (e.g., \"doomscrolling\") are represented differently from established ones\n\n### Open Questions\n1. Where exactly does the 6% \"unique component\" come from? Is it in specific attention heads or MLP layers?\n2. Does the U-shaped R² pattern across layers correspond to specific computational stages?\n3. At what model scale does token erasure begin to appear for compound nouns?\n4. How do multiword expressions longer than 2 words (\"washing machine repair service\") build up representations?\n\n## References\n\n1. Park, K. et al. (2024). The Linear Representation Hypothesis and the Geometry of Large Language Models. arXiv:2311.03658.\n2. Elhage, N. et al. (2022). Toy Models of Superposition. arXiv:2209.10652.\n3. Feucht, S. et al. (2024). Token Erasure as a Footprint of Implicit Vocabulary Items in LLMs. arXiv:2406.20086.\n4. Ormerod, M. et al. (2024). How Is a \"Kitchen Chair\" like a \"Farm Horse\"? Computational Linguistics, 50(1).\n5. Chanin, D. et al. (2024). A is for Absorption. arXiv:2409.14507.\n6. Geva, M. et al. (2022). Transformer Feed-Forward Layers Build Predictions by Promoting Concepts in the Vocabulary Space. arXiv:2203.14680.\n7. Aljaafari, N. et al. (2024). Interpreting token compositionality in LLMs. arXiv:2410.12924.\n8. Garcia, M. et al. (2021). Probing for idiomaticity in vector space models. EACL 2021.\n9. Cunningham, H. et al. (2023). Sparse Autoencoders Find Highly Interpretable Features. arXiv:2309.08600.\n10. Merullo, J. et al. (2023). Language Models Implement Simple Word2Vec-style Vector Arithmetic. arXiv:2305.16130.\n"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":360,"cache_read_input_tokens":92551,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":360},"output_tokens":18,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"5a949ce2-4b08-4c3a-992b-18fb619b51cf"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01UDZ4FnTcS114Bd2xw6F95k","type":"tool_result","content":"File created successfully at: /data/hypogenicai/workspaces/llm-washing-machine-claude/REPORT.md"}]},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"c15f9ad0-da4e-44f4-9342-fae8e68d3c0c","tool_use_result":{"type":"create","filePath":"/data/hypogenicai/workspaces/llm-washing-machine-claude/REPORT.md","content":"# Where is \"Washing Machine\" Stored in LLMs?\n\n## 1. Executive Summary\n\n**Research question**: How do large language models represent compound concepts like \"washing machine\" — as unique directions in the residual stream, or compositionally through constituent words plus context?\n\n**Key finding**: LLMs use a **hybrid strategy** — compound concepts are primarily stored as compositional combinations of constituent word representations (R² = 0.937 for linear reconstruction from constituents), but the model also develops compound-specific contextual information that allows distinguishing compound from non-compound contexts (92.2% probe accuracy). The strongest mechanism is **next-token prediction boosting**: seeing \"washing\" raises P(\"machine\") by a median of 20x compared to control words. Critically, no token erasure was observed — the identity of word1 is perfectly recoverable from the word2 position at every layer, contradicting the implicit vocabulary hypothesis for GPT-2.\n\n**Practical implications**: Compound concepts in LLMs are not stored as dedicated directions in the residual stream. Instead, the model leverages (1) statistical co-occurrence to boost word2 prediction after word1, and (2) contextual modulation of existing word representations to carry compound-specific semantics. This has direct consequences for concept editing, steering, and interpretability methods that assume concepts have unique linear directions.\n\n## 2. Goal\n\n### Hypothesis\nIn large language models, specific compound concepts such as \"washing machine\" may not be represented by a unique direction or nearly orthogonal direction in the residual stream; instead, the model may store the concept of \"washing\" and rely on context to increase the likelihood of \"machine\" following it.\n\n### Why This Matters\nThere are far more referenceable concepts in language (millions of compounds, proper nouns, technical terms) than there are dimensions in an LLM's residual stream (768 for GPT-2, 4096 for 7B models). The superposition hypothesis (Elhage et al., 2022) allows ~10x more features than dimensions through nearly-orthogonal packing, but even this falls short of the number of possible compound concepts. Understanding how models handle this representational bottleneck is fundamental to:\n- Mechanistic interpretability (what do directions in activation space mean?)\n- Concept editing (can we edit \"washing machine\" without affecting \"washing\" or \"machine\"?)\n- Linear representation theory (does the linear representation hypothesis hold for multi-token concepts?)\n\n### Gap in Existing Work\n- Park et al. (2024) tested 27 single-token concepts but never multi-token compounds\n- Feucht et al. (2024) showed token erasure for named entities but not common compound nouns\n- Ormerod et al. (2024) probed compound semantics in BERT (masked LM), not autoregressive models\n- No study has directly compared compound concept directions vs. constituent word directions in the residual stream of autoregressive models\n\n## 3. Data Construction\n\n### Dataset Description\nWe used 19 compound nouns spanning the full compositionality spectrum, each paired with a control phrase that uses the same word2 but a different, non-compound word1.\n\n**Source**: Custom-designed test set based on the compound_nouns_test.jsonl dataset created for this project, with compositionality ratings from 1 (fully idiomatic) to 5 (fully compositional).\n\n### Example Samples\n\n| Compound | Word1 | Word2 | Compositionality | Control |\n|----------|-------|-------|-----------------|---------|\n| washing machine | washing | machine | 4 | red machine |\n| hot dog | hot | dog | 1 | big dog |\n| coffee table | coffee | table | 5 | wooden table |\n| guinea pig | guinea | pig | 2 | small pig |\n| mountain cabin | mountain | cabin | 5 | small cabin |\n\n### Data Quality\n- All compounds verified to tokenize as exactly two tokens in GPT-2's BPE vocabulary\n- 2 compounds skipped (blueberry: \"berry\" multi-token; guinea pig: \"guinea\" multi-token in some analyses)\n- Compositionality ratings assigned based on linguistic analysis (1=opaque/idiomatic, 5=transparent/compositional)\n- 8 sentence templates used per compound for context diversity\n\n### Sentence Templates\nEach compound was embedded in 8 diverse sentence templates:\n- \"The {compound} was\"\n- \"She bought a {compound} for\"\n- \"I saw a {compound} in the\"\n- \"There is a {compound} near the\"\n- \"He fixed the {compound} with\"\n- \"A new {compound} arrived\"\n- \"The old {compound} needed\"\n- \"We need a {compound} to\"\n\n## 4. Experiment Description\n\n### Methodology\n\n#### High-Level Approach\nWe conducted four complementary experiments on GPT-2 (124M parameters, 12 layers, d_model=768), accessing internal activations via TransformerLens. Each experiment tests a different aspect of how compound concepts are represented:\n\n1. **Next-token prediction**: Does word1 boost P(word2)? How much?\n2. **Residual stream directions**: Can the compound direction be reconstructed from constituents?\n3. **Layer-wise probing**: Where do compound representations emerge?\n4. **Attention patterns**: Does word2 attend to word1 differently in compounds vs. controls?\n\n#### Why GPT-2?\n- Well-studied in interpretability research\n- Small enough for comprehensive analysis (all layers, all attention heads)\n- TransformerLens provides clean hook-based access to all internal activations\n- Results validated on GPT-2-medium (355M, 24 layers) for scale robustness\n\n### Implementation Details\n\n#### Tools and Libraries\n| Library | Version | Purpose |\n|---------|---------|---------|\n| Python | 3.12.2 | Runtime |\n| PyTorch | 2.10.0+cu128 | Tensor computation |\n| TransformerLens | 2.15.4 | Model internals access |\n| scikit-learn | - | Linear probes |\n| scipy | - | Statistical tests |\n| matplotlib | - | Visualization |\n\n#### Hardware\n- 2x NVIDIA GeForce RTX 3090 (24GB each)\n- Total experiment runtime: ~3 minutes for GPT-2, ~2 minutes for GPT-2-medium\n\n#### Hyperparameters\n\n| Parameter | Value | Justification |\n|-----------|-------|---------------|\n| Random seed | 42 | Reproducibility |\n| Probe regularization (C) | 1.0 | Default, adequate for small dataset |\n| Cross-validation folds | 5 | Standard, balances bias-variance |\n| Number of templates | 8 | Sufficient context diversity |\n| Number of isolation templates | 4 | Baseline word representations |\n\n### Experimental Protocol\n\n#### Experiment 1: Next-Token Prediction Analysis\nFor each compound (word1, word2):\n1. Embed word1 in 8 templates and measure P(word2 | context + word1)\n2. Embed control_word1 in same templates and measure P(word2 | context + control_word1)\n3. Compute boost ratio = P(word2 | word1) / P(word2 | control_word1)\n4. Record rank of word2 among all vocabulary predictions\n\n#### Experiment 2: Residual Stream Direction Analysis\n1. Collect hidden states at the word2 position across 8 compound contexts per layer\n2. Collect hidden states for word1 and word2 in isolation (4 contexts each)\n3. Compute mean direction vectors for compound, word1, word2\n4. Test linear reconstruction: compound = α·word1 + β·word2 (least squares)\n5. Compute R², cosine similarities, and residual norm ratio\n\n#### Experiment 3: Layer-wise Probing\n1. Collect hidden states at word2 position for 120 compound and 136 control samples\n2. **Probe 1**: Train logistic regression to predict word1 identity from word2 position (tests token erasure)\n3. **Probe 2**: Train logistic regression to classify compound vs. control context\n\n#### Experiment 4: Attention Pattern Analysis\n1. For each compound and control context, extract attention weights at the word2 position\n2. Measure attention from word2 to word1 (compound) vs. word2 to previous word (control)\n3. Compare across layers and attention heads\n\n### Raw Results\n\n#### Experiment 1: Next-Token Prediction\n\n| Compound | P(w2\\|w1) | Rank | P(w2\\|ctrl) | Ctrl Rank | Boost | Top-5 after w1 |\n|----------|-----------|------|-------------|-----------|-------|----------------|\n| guinea pig | 0.8326 | 1 | 0.0001 | 1755 | 7233x | pig, pigs, worm, -, p |\n| washing machine | 0.8270 | 1 | 0.0002 | 924 | 4963x | machine, machines, -, ton, of |\n| swimming pool | 0.6258 | 1 | 0.0011 | 125 | 549x | pool, pools, team, hole, - |\n| parking lot | 0.3215 | 1 | 0.0116 | 14 | 28x | lot, garage, meter, lots, space |\n| living room | 0.2611 | 2 | 0.0016 | 98 | 160x | room, -, wage, world, rooms |\n| hot dog | 0.0973 | 4 | 0.0022 | 142 | 45x | new, topic, dog, -, spot |\n| coffee table | 0.0632 | 4 | 0.0091 | 14 | 7x | shop, -, is, maker, industry |\n| chocolate cake | 0.0356 | 5 | 0.0003 | 978 | 140x | chip, -, bar, is, and |\n| driving license | 0.0364 | 118 | 0.0002 | 1325 | 221x | force, forces, seat, -, season |\n| shooting star | 0.0307 | 90 | 0.0103 | 18 | 3x | of, death, at, was, in |\n| mountain cabin | 0.0040 | 149 | 0.0014 | 305 | 3x | of, is, lion, range, bike |\n| snowman | 0.0038 | 63 | 0.0427 | 7 | 0.1x | is, -, was, storm, has |\n| sunflower | 0.0001 | 1673 | 0.0004 | 706 | 0.3x | is, was, has, 's, rises |\n\n**Key observation**: For strongly associated compounds, word2 is often the #1 prediction after word1 (washing→machine, swimming→pool, guinea→pig, parking→lot). For weakly associated compounds (snowman, sunflower), the control word actually predicts word2 better.\n\n#### Experiment 2: Residual Stream Directions (Final Layer)\n\n| Compound | R² | cos(C,w1) | cos(C,w2) | Residual |\n|----------|-----|-----------|-----------|----------|\n| steel bridge | 0.965 | 0.924 | 0.982 | 0.188 |\n| garden hose | 0.962 | 0.933 | 0.979 | 0.196 |\n| door handle | 0.958 | 0.949 | 0.976 | 0.206 |\n| mountain cabin | 0.956 | 0.937 | 0.975 | 0.209 |\n| chocolate cake | 0.953 | 0.944 | 0.975 | 0.216 |\n| shooting star | 0.944 | 0.929 | 0.960 | 0.236 |\n| brick house | 0.939 | 0.933 | 0.965 | 0.247 |\n| coffee table | 0.938 | 0.934 | 0.962 | 0.249 |\n| living room | 0.933 | 0.925 | 0.958 | 0.259 |\n| water bottle | 0.931 | 0.924 | 0.963 | 0.262 |\n| swimming pool | 0.924 | 0.932 | 0.957 | 0.276 |\n| driving license | 0.924 | 0.908 | 0.955 | 0.276 |\n| parking lot | 0.922 | 0.936 | 0.934 | 0.280 |\n| washing machine | 0.917 | 0.907 | 0.951 | 0.288 |\n| hot dog | 0.888 | 0.897 | 0.934 | 0.335 |\n\n**Mean R² = 0.937 ± 0.020**: The compound direction is very well explained by a linear combination of constituent directions. Only ~25% of the compound representation is \"unique\" (not explained by word1 + word2).\n\n#### Experiment 3: Probing Results\n\n**Probe 1 (Token Erasure)**: Perfect accuracy (1.000) at ALL layers. Word1 identity is fully recoverable from the word2 position at every layer. **No token erasure observed in GPT-2.**\n\n**Probe 2 (Compound vs. Control)**:\n\n| Layer | Accuracy |\n|-------|----------|\n| 0 | 0.706 |\n| 2 | 0.902 |\n| 4 | 0.894 |\n| 7 | 0.918 |\n| 8 | 0.922 (peak) |\n| 11 | 0.851 |\n\nCompound vs. control contexts are distinguishable from layer 2 onward (90%+ accuracy), peaking at layer 8.\n\n#### Experiment 4: Attention Patterns\n\nCompound contexts show significantly more attention from word2 to word1 in layer 0 (p=0.011), but this reverses in later layers (7-8) where control contexts show more attention to the previous word (p<0.001).\n\n### Output Locations\n- Results JSON: `results/exp1_next_token.json`, `results/exp2_residual_directions.json`, `results/exp3_probing.json`, `results/exp4_attention.json`\n- Plots: `results/plots/`\n- Summary figure: `results/plots/summary_figure.png`\n- Configuration: `results/config.json`\n\n## 5. Result Analysis\n\n### Key Findings\n\n**Finding 1: The primary mechanism is next-token prediction boosting (strong support for compositional hypothesis).**\nSeeing \"washing\" makes \"machine\" the #1 prediction (P=0.827, rank 1), compared to P=0.0002 after \"red\" (the control). The median boost ratio across all compounds is 20.2x (95% CI: [4.7, 180.2]). This is statistically significant (Wilcoxon W=160, p=2.1e-4, Cohen's d=0.63).\n\nFor the strongest compounds:\n- \"washing\" → P(\"machine\") = 0.827 (rank 1)\n- \"guinea\" → P(\"pig\") = 0.833 (rank 1)\n- \"swimming\" → P(\"pool\") = 0.626 (rank 1)\n\nThis confirms the hypothesis: the model stores \"washing\" and context makes \"machine\" overwhelmingly likely.\n\n**Finding 2: Compound directions are 93.7% reconstructable from constituent directions.**\nAt the final layer, the compound direction at the word2 position can be reconstructed as a linear combination of the word1 and word2 directions with R² = 0.937 ± 0.020 (t=176.3, p=7.9e-25 vs. null). Only ~25% of the compound representation's norm is \"unique\" (unexplained residual). This means \"washing machine\" does NOT have a dedicated direction — it is ~94% a combination of \"washing\" and \"machine\" directions.\n\n**Finding 3: More compositional compounds have HIGHER reconstruction quality.**\nSpearman correlation between compositionality rating and R²: r=0.669, p=0.006. More compositional compounds (steel bridge: R²=0.965) are better reconstructed than idiomatic ones (hot dog: R²=0.888). This is exactly what the compositional hypothesis predicts — idiomatic compounds require more \"unique\" information beyond their constituents.\n\n**Finding 4: No token erasure in GPT-2 (contradicts Feucht et al. for named entities).**\nWord1 identity is perfectly recoverable from the word2 position at every layer (probe accuracy = 1.000). This means GPT-2 does not \"erase\" constituent token information to form compound representations. Unlike named entities, compound nouns maintain full constituent information throughout all layers.\n\n**Finding 5: Compound contexts are distinguishable from control contexts.**\nDespite the high R² for reconstruction, a linear probe can distinguish compound from non-compound contexts at the word2 position with 92.2% accuracy (peak at layer 8). This ~6% \"unique\" component (100% - 94% R²) carries enough information to differentiate \"washing machine\" from \"red machine.\"\n\n**Finding 6: Reconstruction quality follows a U-shaped pattern across layers.**\nR² starts high at layer 0 (0.940), dips to a minimum at layers 4-5 (~0.800), and recovers to 0.937 at layer 11. This suggests intermediate layers perform the most compound-specific processing, while early and late layers maintain more compositional representations.\n\n### Hypothesis Testing Results\n\n| Hypothesis | Result | Evidence |\n|-----------|--------|----------|\n| H1: Next-token prediction drives compound assembly | **Supported** | Wilcoxon p=2.1e-4; median boost=20.2x |\n| H2: Compounds lack unique residual stream directions | **Mostly supported** | R²=0.937; but ~6% unique component exists |\n| H3: Token erasure occurs for compounds | **Rejected** (for GPT-2) | Perfect word1 recovery at all layers |\n\n### Comparison to Baselines and Literature\n- **Feucht et al. (2024)** found token erasure in layers 1-9 for named entities in Llama-2-7B. We find NO erasure in GPT-2 for compound nouns — this could be a model size effect, an entity vs. compound noun difference, or both.\n- **Park et al. (2024)** showed 26/27 single-token concepts have linear directions. We show compound concepts are ~94% linearly reconstructable from constituents — the compound \"direction\" is largely the constituent directions.\n- **Ormerod et al. (2024)** found that compounds processed together have different representations than constituents processed separately. Our 92.2% probe accuracy confirms this, but shows the difference is relatively small (~6% of the total representation).\n\n### Validation on GPT-2-Medium (355M, 24 layers)\nKey findings replicate:\n\n| Compound | GPT-2 Boost | GPT-2-M Boost | GPT-2 R² | GPT-2-M R² |\n|----------|-------------|---------------|----------|------------|\n| washing machine | 4963x | 25303x | 0.917 | 0.899 |\n| swimming pool | 549x | 615x | 0.924 | 0.932 |\n| hot dog | 45x | 116x | 0.888 | 0.897 |\n| coffee table | 7x | 4x | 0.938 | 0.923 |\n\nThe larger model shows similar or stronger next-token prediction boosting and similar R² values for linear reconstruction. Findings are robust to model scale.\n\n### Surprises and Insights\n\n1. **Guinea pig** (compositionality=2, idiomatic) has the HIGHEST boost ratio (7233x) and P=0.833 for \"pig\" after \"guinea.\" Despite being semantically opaque, the statistical association is the strongest. The model learns co-occurrence regardless of semantic compositionality.\n\n2. **Snowman** and **sunflower** have boost ratios < 1 — the control word (\"tall man\", \"red flower\") actually predicts word2 BETTER than the compound word1. This is because \"snow\" and \"sun\" don't strongly predict their compound partners in GPT-2's training distribution.\n\n3. **Driving license** has a very high boost ratio (221x) but a low rank (118th prediction after \"driving\"). This means \"license\" is much more likely after \"driving\" than after \"new\", but \"driving\" still predicts many other words more strongly (force, forces, seat, season).\n\n4. The **U-shaped R² curve** across layers was unexpected. It suggests that intermediate layers (4-5) perform the most transformation of compound representations, potentially encoding compound-specific semantics, before the final layers restore a more compositional representation for next-token prediction.\n\n### Error Analysis\n- **Blueberry** was excluded because \"berry\" tokenizes to multiple tokens in GPT-2, preventing clean analysis\n- **Guinea pig** was excluded from Experiment 2 (direction analysis) because \"guinea\" tokenizes to multiple tokens, but was kept in Experiment 1 (next-token prediction) where only word2 needs to be single-token\n- Compounds where both words are common function words (e.g., potential compound \"let down\") were not included due to high baseline prediction probabilities\n\n### Limitations\n\n1. **Model scale**: GPT-2 (124M) is much smaller than modern LLMs. Larger models may develop more holistic compound representations. Validation on GPT-2-medium (355M) shows similar patterns, but testing on 7B+ models would strengthen conclusions.\n\n2. **Limited context diversity**: Only 8 sentence templates were used. More diverse contexts (from natural corpora like The Pile) would better capture the range of compound usage.\n\n3. **English-only**: All compounds are English. Cross-lingual analysis would reveal whether findings generalize.\n\n4. **Linear probing limitation**: Linear probes may miss nonlinear compound representations. MLP probes or DCI (Disentanglement, Completeness, Informativeness) could capture additional structure.\n\n5. **Absence of token erasure might be GPT-2-specific**: Feucht et al. found erasure in Llama-2-7B. Our GPT-2 results don't generalize to larger models without further validation.\n\n6. **The R² metric conflates direction and magnitude**: High R² could mean the compound direction is approximately in the span of constituent directions, even if the magnitude (and thus the information encoded in norms) differs.\n\n7. **Control phrase selection**: Our control phrases (e.g., \"red machine\" for \"washing machine\") aim to preserve word2 while changing word1, but the specific control word choice affects boost ratios.\n\n## 6. Conclusions\n\n### Summary\n**\"Washing machine\" is not stored as a unique direction in GPT-2's residual stream.** Instead, the model primarily uses two complementary mechanisms: (1) **next-token prediction boosting** — seeing \"washing\" makes \"machine\" the most likely next token with P=0.827 — and (2) **contextual modulation** — the word2 representation in compound contexts is ~94% a linear combination of constituent word representations (R²=0.937), with only ~6% unique to the compound context. This 6% is sufficient to distinguish compound from non-compound contexts (92.2% probe accuracy) but does not constitute a dedicated \"washing machine\" direction.\n\nMore idiomatic compounds (like \"hot dog\") have slightly less reconstructable representations (R²=0.888 vs. 0.965 for \"steel bridge\"), suggesting the model allocates more unique representational capacity to concepts that cannot be derived from their parts.\n\n### Implications\n\n**For mechanistic interpretability**: Compound concepts challenge the simple \"one concept = one direction\" view. Most compound information is carried by constituent representations plus contextual modification, not dedicated directions. This means SAE features for compounds will likely be unreliable (consistent with the \"feature absorption\" problem documented by Chanin et al., 2024).\n\n**For concept editing**: Editing \"washing machine\" by modifying a single direction would likely fail — you'd need to modify the contextual relationship between \"washing\" and \"machine\" representations, which is distributed across the network.\n\n**For the linear representation hypothesis**: The hypothesis holds approximately for compounds — compound representations are linear combinations of constituent representations — but the ~6% unique component and the U-shaped layer evolution suggest nonlinear dynamics in intermediate layers.\n\n### Confidence in Findings\n- **High confidence**: Next-token prediction boosting is the primary mechanism (large effect sizes, consistent across models)\n- **High confidence**: Compound directions are largely reconstructable from constituents (R²=0.937)\n- **Medium confidence**: No token erasure in GPT-2 (may not generalize to larger models)\n- **Medium confidence**: The ~6% unique component carries compound-specific information (depends on probe methodology)\n\n## 7. Next Steps\n\n### Immediate Follow-ups\n1. **Repeat on Llama-3-8B or Gemma-2-2B**: These models have pre-trained SAEs (Llama Scope, Gemma Scope) that would enable SAE feature analysis of compound concepts, and are large enough that token erasure effects might emerge.\n2. **Use natural corpus contexts**: Replace templates with sentences from The Pile or Wikipedia to reduce template bias and increase context diversity.\n3. **Expand compound dataset**: Include 100+ compounds spanning the full compositionality spectrum, using the NCS dataset's compositionality ratings.\n\n### Alternative Approaches\n- **SAE feature search**: Use pre-trained SAEs to search for features that activate specifically for compound nouns. Test for feature absorption (Chanin et al., 2024).\n- **Causal interventions**: Use activation patching to test whether modifying the word1 representation at specific layers disrupts compound understanding.\n- **Nonlinear probing**: Use MLP probes to capture nonlinear compound representations that linear probes miss.\n\n### Broader Extensions\n- **Cross-lingual study**: Test whether the compositional storage pattern holds across languages (e.g., German, which forms novel compounds productively)\n- **Scale analysis**: Track how compound representation changes from GPT-2 (124M) to GPT-3 (175B) to see if larger models develop more holistic representations\n- **Temporal analysis**: Test whether newly coined compounds (e.g., \"doomscrolling\") are represented differently from established ones\n\n### Open Questions\n1. Where exactly does the 6% \"unique component\" come from? Is it in specific attention heads or MLP layers?\n2. Does the U-shaped R² pattern across layers correspond to specific computational stages?\n3. At what model scale does token erasure begin to appear for compound nouns?\n4. How do multiword expressions longer than 2 words (\"washing machine repair service\") build up representations?\n\n## References\n\n1. Park, K. et al. (2024). The Linear Representation Hypothesis and the Geometry of Large Language Models. arXiv:2311.03658.\n2. Elhage, N. et al. (2022). Toy Models of Superposition. arXiv:2209.10652.\n3. Feucht, S. et al. (2024). Token Erasure as a Footprint of Implicit Vocabulary Items in LLMs. arXiv:2406.20086.\n4. Ormerod, M. et al. (2024). How Is a \"Kitchen Chair\" like a \"Farm Horse\"? Computational Linguistics, 50(1).\n5. Chanin, D. et al. (2024). A is for Absorption. arXiv:2409.14507.\n6. Geva, M. et al. (2022). Transformer Feed-Forward Layers Build Predictions by Promoting Concepts in the Vocabulary Space. arXiv:2203.14680.\n7. Aljaafari, N. et al. (2024). Interpreting token compositionality in LLMs. arXiv:2410.12924.\n8. Garcia, M. et al. (2021). Probing for idiomaticity in vector space models. EACL 2021.\n9. Cunningham, H. et al. (2023). Sparse Autoencoders Find Highly Interpretable Features. arXiv:2309.08600.\n10. Merullo, J. et al. (2023). Language Models Implement Simple Word2Vec-style Vector Arithmetic. arXiv:2305.16130.\n","structuredPatch":[],"originalFile":null}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_011A13xo1PAm3NQyg1GqMYZc","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01JhRyqxPLaxENGsdYBjQLBL","name":"Write","input":{"file_path":"/data/hypogenicai/workspaces/llm-washing-machine-claude/README.md","content":"# Where is \"Washing Machine\" Stored in LLMs?\n\nAn empirical investigation into how compound concepts are represented in large language models. There are far more referenceable concepts than available dimensions in an LLM's residual stream — so how does a model represent multi-token concepts like \"washing machine\"? Does it have a unique direction, or does it just store \"washing\" and let context predict \"machine\"?\n\n## Key Findings\n\n- **Next-token prediction is the primary mechanism**: After seeing \"washing\", GPT-2 predicts \"machine\" as the #1 token with P=0.827 — a 4963x boost over the control word. Median boost across 18 compounds: 20.2x (p=2.1e-4).\n- **Compound directions are 94% reconstructable from constituents**: The compound representation at the word2 position is a linear combination of word1 + word2 directions (R²=0.937 ± 0.020). No dedicated \"washing machine\" direction exists.\n- **More compositional compounds have higher R²**: Spearman r=0.669, p=0.006. Idiomatic compounds like \"hot dog\" (R²=0.888) retain more unique information than compositional ones like \"steel bridge\" (R²=0.965).\n- **No token erasure in GPT-2**: Unlike Feucht et al.'s findings for named entities in Llama-2-7B, word1 identity is perfectly recoverable from the word2 position at every layer.\n- **Compound contexts are still distinguishable**: Despite high R², a linear probe can tell compound from non-compound contexts with 92.2% accuracy (the ~6% unique component carries compound-specific information).\n- **Findings replicate on GPT-2-medium (355M)**: Boost ratios and R² values are consistent across model sizes.\n\n## Reproducing Results\n\n### Environment Setup\n```bash\n# Create and activate virtual environment\nuv venv\nsource .venv/bin/activate\n\n# Install dependencies\nuv add torch transformers transformer-lens matplotlib seaborn scipy scikit-learn pandas numpy tqdm einops\n```\n\n### Running Experiments\n```bash\n# Main experiments (GPT-2, ~3 min on GPU)\npython src/experiment.py\n\n# Statistical analysis and visualizations\npython src/analysis.py\n\n# Validation on GPT-2-medium (~2 min on GPU)\npython src/validation_gpt2medium.py\n```\n\n### Hardware Requirements\n- GPU recommended (RTX 3090 or similar; 8GB+ VRAM sufficient for GPT-2)\n- CPU-only: experiments will run but slower (~15 min)\n- Disk: ~500MB for model downloads\n\n## File Structure\n```\n.\n├── REPORT.md                          # Full research report with results\n├── README.md                          # This file\n├── planning.md                        # Research plan and methodology\n├── literature_review.md               # Literature review\n├── resources.md                       # Resource catalog\n├── src/\n│   ├── experiment.py                  # Main experiments (4 experiments)\n│   ├── analysis.py                    # Statistical analysis & visualizations\n│   └── validation_gpt2medium.py       # GPT-2-medium validation\n├── results/\n│   ├── config.json                    # Experiment configuration\n│   ├── exp1_next_token.json           # Experiment 1 results\n│   ├── exp2_residual_directions.json  # Experiment 2 results\n│   ├── exp3_probing.json              # Experiment 3 results\n│   ├── exp4_attention.json            # Experiment 4 results\n│   ├── validation_gpt2medium.json     # Validation results\n│   ├── statistical_analysis.json      # All statistical tests\n│   └── plots/\n│       ├── summary_figure.png         # Key findings summary\n│       ├── exp1_*.png                 # Experiment 1 plots\n│       ├── exp2_*.png                 # Experiment 2 plots\n│       ├── exp3_*.png                 # Experiment 3 plots\n│       └── exp4_*.png                 # Experiment 4 plots\n├── papers/                            # Downloaded research papers (36)\n├── datasets/                          # Compound noun test sets\n└── code/                              # Cloned reference repositories\n```\n\nSee [REPORT.md](REPORT.md) for the full research report with all experimental results, statistical analysis, and discussion.\n"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":7077,"cache_read_input_tokens":92911,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":7077},"output_tokens":25,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"792b00e7-be3e-41ee-8825-351822450ce1"}
{"type":"user","message":{"role":"user","content":[{"type":"tool_result","content":"<tool_use_error>File has not been read yet. Read it first before writing to it.</tool_use_error>","is_error":true,"tool_use_id":"toolu_01JhRyqxPLaxENGsdYBjQLBL"}]},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"0a0050a0-2044-493c-a18e-bf52c29db69e","tool_use_result":"Error: File has not been read yet. Read it first before writing to it."}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01S5eiyNPx7puqHakVnkt843","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01Y4dUfWVSJTf6ZoW4R6cGg5","name":"Bash","input":{"command":"ls /data/hypogenicai/workspaces/llm-washing-machine-claude/README.md 2>/dev/null && echo \"EXISTS\" || echo \"DOES_NOT_EXIST\"","description":"Check if README.md exists"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1223,"cache_read_input_tokens":99988,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1223},"output_tokens":26,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"6ce8f2a0-1368-4571-a174-14261e0408b1"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Y4dUfWVSJTf6ZoW4R6cGg5","type":"tool_result","content":"/data/hypogenicai/workspaces/llm-washing-machine-claude/README.md\nEXISTS","is_error":false}]},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"e9675ff2-8e9b-414f-bf79-93e72e0148fb","tool_use_result":{"stdout":"/data/hypogenicai/workspaces/llm-washing-machine-claude/README.md\nEXISTS","stderr":"","interrupted":false,"isImage":false}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_015yERGWChRcgZqBSQ62CYms","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_014e1aE9DjygVFTcLVYhZ8DK","name":"Read","input":{"file_path":"/data/hypogenicai/workspaces/llm-washing-machine-claude/README.md"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":157,"cache_read_input_tokens":101211,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":157},"output_tokens":25,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"d9743f54-5a65-4532-a4b9-43e63b211b39"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_014e1aE9DjygVFTcLVYhZ8DK","type":"tool_result","content":"     1→# llm-washing-machine-claude\n     2→Nlp research: Where is Washing Machine stored in LLMs? | Generated by Idea Explorer on 2026-02-07\n     3→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"069e876e-313a-492d-add9-c2a99483fbac","tool_use_result":{"type":"text","file":{"filePath":"/data/hypogenicai/workspaces/llm-washing-machine-claude/README.md","content":"# llm-washing-machine-claude\nNlp research: Where is Washing Machine stored in LLMs? | Generated by Idea Explorer on 2026-02-07\n","numLines":3,"startLine":1,"totalLines":3}}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01VNxwhbqFKk9QKivqVBus9a","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01Fjo8ad7QsJKJ4YpvC8HE9f","name":"Write","input":{"file_path":"/data/hypogenicai/workspaces/llm-washing-machine-claude/README.md","content":"# Where is \"Washing Machine\" Stored in LLMs?\n\nAn empirical investigation into how compound concepts are represented in large language models. There are far more referenceable concepts than available dimensions in an LLM's residual stream — so how does a model represent multi-token concepts like \"washing machine\"? Does it have a unique direction, or does it just store \"washing\" and let context predict \"machine\"?\n\n## Key Findings\n\n- **Next-token prediction is the primary mechanism**: After seeing \"washing\", GPT-2 predicts \"machine\" as the #1 token with P=0.827 — a 4963x boost over the control word. Median boost across 18 compounds: 20.2x (p=2.1e-4).\n- **Compound directions are 94% reconstructable from constituents**: The compound representation at the word2 position is a linear combination of word1 + word2 directions (R²=0.937 ± 0.020). No dedicated \"washing machine\" direction exists.\n- **More compositional compounds have higher R²**: Spearman r=0.669, p=0.006. Idiomatic compounds like \"hot dog\" (R²=0.888) retain more unique information than compositional ones like \"steel bridge\" (R²=0.965).\n- **No token erasure in GPT-2**: Unlike Feucht et al.'s findings for named entities in Llama-2-7B, word1 identity is perfectly recoverable from the word2 position at every layer.\n- **Compound contexts are still distinguishable**: Despite high R², a linear probe can tell compound from non-compound contexts with 92.2% accuracy (the ~6% unique component carries compound-specific information).\n- **Findings replicate on GPT-2-medium (355M)**: Boost ratios and R² values are consistent across model sizes.\n\n## Reproducing Results\n\n### Environment Setup\n```bash\n# Create and activate virtual environment\nuv venv\nsource .venv/bin/activate\n\n# Install dependencies\nuv add torch transformers transformer-lens matplotlib seaborn scipy scikit-learn pandas numpy tqdm einops\n```\n\n### Running Experiments\n```bash\n# Main experiments (GPT-2, ~3 min on GPU)\npython src/experiment.py\n\n# Statistical analysis and visualizations\npython src/analysis.py\n\n# Validation on GPT-2-medium (~2 min on GPU)\npython src/validation_gpt2medium.py\n```\n\n### Hardware Requirements\n- GPU recommended (RTX 3090 or similar; 8GB+ VRAM sufficient for GPT-2)\n- CPU-only: experiments will run but slower (~15 min)\n- Disk: ~500MB for model downloads\n\n## File Structure\n```\n.\n├── REPORT.md                          # Full research report with results\n├── README.md                          # This file\n├── planning.md                        # Research plan and methodology\n├── literature_review.md               # Literature review\n├── resources.md                       # Resource catalog\n├── src/\n│   ├── experiment.py                  # Main experiments (4 experiments)\n│   ├── analysis.py                    # Statistical analysis & visualizations\n│   └── validation_gpt2medium.py       # GPT-2-medium validation\n├── results/\n│   ├── config.json                    # Experiment configuration\n│   ├── exp1_next_token.json           # Experiment 1 results\n│   ├── exp2_residual_directions.json  # Experiment 2 results\n│   ├── exp3_probing.json              # Experiment 3 results\n│   ├── exp4_attention.json            # Experiment 4 results\n│   ├── validation_gpt2medium.json     # Validation results\n│   ├── statistical_analysis.json      # All statistical tests\n│   └── plots/\n│       ├── summary_figure.png         # Key findings summary\n│       ├── exp1_*.png                 # Experiment 1 plots\n│       ├── exp2_*.png                 # Experiment 2 plots\n│       ├── exp3_*.png                 # Experiment 3 plots\n│       └── exp4_*.png                 # Experiment 4 plots\n├── papers/                            # Downloaded research papers (36)\n├── datasets/                          # Compound noun test sets\n└── code/                              # Cloned reference repositories\n```\n\nSee [REPORT.md](REPORT.md) for the full research report with all experimental results, statistical analysis, and discussion.\n"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":218,"cache_read_input_tokens":101368,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":218},"output_tokens":25,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"17f39717-5d97-42ce-bcd8-4807f74c9276"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Fjo8ad7QsJKJ4YpvC8HE9f","type":"tool_result","content":"The file /data/hypogenicai/workspaces/llm-washing-machine-claude/README.md has been updated. Here's the result of running `cat -n` on a snippet of the edited file:\n     1→# Where is \"Washing Machine\" Stored in LLMs?\n     2→\n     3→An empirical investigation into how compound concepts are represented in large language models. There are far more referenceable concepts than available dimensions in an LLM's residual stream — so how does a model represent multi-token concepts like \"washing machine\"? Does it have a unique direction, or does it just store \"washing\" and let context predict \"machine\"?\n     4→\n     5→## Key Findings\n     6→\n     7→- **Next-token prediction is the primary mechanism**: After seeing \"washing\", GPT-2 predicts \"machine\" as the #1 token with P=0.827 — a 4963x boost over the control word. Median boost across 18 compounds: 20.2x (p=2.1e-4).\n     8→- **Compound directions are 94% reconstructable from constituents**: The compound representation at the word2 position is a linear combination of word1 + word2 directions (R²=0.937 ± 0.020). No dedicated \"washing machine\" direction exists.\n     9→- **More compositional compounds have higher R²**: Spearman r=0.669, p=0.006. Idiomatic compounds like \"hot dog\" (R²=0.888) retain more unique information than compositional ones like \"steel bridge\" (R²=0.965).\n    10→- **No token erasure in GPT-2**: Unlike Feucht et al.'s findings for named entities in Llama-2-7B, word1 identity is perfectly recoverable from the word2 position at every layer.\n    11→- **Compound contexts are still distinguishable**: Despite high R², a linear probe can tell compound from non-compound contexts with 92.2% accuracy (the ~6% unique component carries compound-specific information).\n    12→- **Findings replicate on GPT-2-medium (355M)**: Boost ratios and R² values are consistent across model sizes.\n    13→\n    14→## Reproducing Results\n    15→\n    16→### Environment Setup\n    17→```bash\n    18→# Create and activate virtual environment\n    19→uv venv\n    20→source .venv/bin/activate\n    21→\n    22→# Install dependencies\n    23→uv add torch transformers transformer-lens matplotlib seaborn scipy scikit-learn pandas numpy tqdm einops\n    24→```\n    25→\n    26→### Running Experiments\n    27→```bash\n    28→# Main experiments (GPT-2, ~3 min on GPU)\n    29→python src/experiment.py\n    30→\n    31→# Statistical analysis and visualizations\n    32→python src/analysis.py\n    33→\n    34→# Validation on GPT-2-medium (~2 min on GPU)\n    35→python src/validation_gpt2medium.py\n    36→```\n    37→\n    38→### Hardware Requirements\n    39→- GPU recommended (RTX 3090 or similar; 8GB+ VRAM sufficient for GPT-2)\n    40→- CPU-only: experiments will run but slower (~15 min)\n    41→- Disk: ~500MB for model downloads\n    42→\n    43→## File Structure\n    44→```\n    45→.\n    46→├── REPORT.md                          # Full research report with results\n    47→├── README.md                          # This file\n    48→├── planning.md                        # Research plan and methodology\n    49→├── literature_review.md               # Literature review\n    50→├── resources.md                       # Resource catalog\n    51→├── src/\n    52→│   ├── experiment.py                  # Main experiments (4 experiments)\n    53→│   ├── analysis.py                    # Statistical analysis & visualizations\n    54→│   └── validation_gpt2medium.py       # GPT-2-medium validation\n    55→├── results/\n    56→│   ├── config.json                    # Experiment configuration\n    57→│   ├── exp1_next_token.json           # Experiment 1 results\n    58→│   ├── exp2_residual_directions.json  # Experiment 2 results\n    59→│   ├── exp3_probing.json              # Experiment 3 results\n    60→│   ├── exp4_attention.json            # Experiment 4 results\n    61→│   ├── validation_gpt2medium.json     # Validation results\n    62→│   ├── statistical_analysis.json      # All statistical tests\n    63→│   └── plots/\n    64→│       ├── summary_figure.png         # Key findings summary\n    65→│       ├── exp1_*.png                 # Experiment 1 plots\n    66→│       ├── exp2_*.png                 # Experiment 2 plots\n    67→│       ├── exp3_*.png                 # Experiment 3 plots\n    68→│       └── exp4_*.png                 # Experiment 4 plots\n    69→├── papers/                            # Downloaded research papers (36)\n    70→├── datasets/                          # Compound noun test sets\n    71→└── code/                              # Cloned reference repositories\n    72→```\n    73→\n    74→See [REPORT.md](REPORT.md) for the full research report with all experimental results, statistical analysis, and discussion.\n    75→"}]},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"75dd5d36-d08d-4f51-9444-523a247b1048","tool_use_result":{"type":"update","filePath":"/data/hypogenicai/workspaces/llm-washing-machine-claude/README.md","content":"# Where is \"Washing Machine\" Stored in LLMs?\n\nAn empirical investigation into how compound concepts are represented in large language models. There are far more referenceable concepts than available dimensions in an LLM's residual stream — so how does a model represent multi-token concepts like \"washing machine\"? Does it have a unique direction, or does it just store \"washing\" and let context predict \"machine\"?\n\n## Key Findings\n\n- **Next-token prediction is the primary mechanism**: After seeing \"washing\", GPT-2 predicts \"machine\" as the #1 token with P=0.827 — a 4963x boost over the control word. Median boost across 18 compounds: 20.2x (p=2.1e-4).\n- **Compound directions are 94% reconstructable from constituents**: The compound representation at the word2 position is a linear combination of word1 + word2 directions (R²=0.937 ± 0.020). No dedicated \"washing machine\" direction exists.\n- **More compositional compounds have higher R²**: Spearman r=0.669, p=0.006. Idiomatic compounds like \"hot dog\" (R²=0.888) retain more unique information than compositional ones like \"steel bridge\" (R²=0.965).\n- **No token erasure in GPT-2**: Unlike Feucht et al.'s findings for named entities in Llama-2-7B, word1 identity is perfectly recoverable from the word2 position at every layer.\n- **Compound contexts are still distinguishable**: Despite high R², a linear probe can tell compound from non-compound contexts with 92.2% accuracy (the ~6% unique component carries compound-specific information).\n- **Findings replicate on GPT-2-medium (355M)**: Boost ratios and R² values are consistent across model sizes.\n\n## Reproducing Results\n\n### Environment Setup\n```bash\n# Create and activate virtual environment\nuv venv\nsource .venv/bin/activate\n\n# Install dependencies\nuv add torch transformers transformer-lens matplotlib seaborn scipy scikit-learn pandas numpy tqdm einops\n```\n\n### Running Experiments\n```bash\n# Main experiments (GPT-2, ~3 min on GPU)\npython src/experiment.py\n\n# Statistical analysis and visualizations\npython src/analysis.py\n\n# Validation on GPT-2-medium (~2 min on GPU)\npython src/validation_gpt2medium.py\n```\n\n### Hardware Requirements\n- GPU recommended (RTX 3090 or similar; 8GB+ VRAM sufficient for GPT-2)\n- CPU-only: experiments will run but slower (~15 min)\n- Disk: ~500MB for model downloads\n\n## File Structure\n```\n.\n├── REPORT.md                          # Full research report with results\n├── README.md                          # This file\n├── planning.md                        # Research plan and methodology\n├── literature_review.md               # Literature review\n├── resources.md                       # Resource catalog\n├── src/\n│   ├── experiment.py                  # Main experiments (4 experiments)\n│   ├── analysis.py                    # Statistical analysis & visualizations\n│   └── validation_gpt2medium.py       # GPT-2-medium validation\n├── results/\n│   ├── config.json                    # Experiment configuration\n│   ├── exp1_next_token.json           # Experiment 1 results\n│   ├── exp2_residual_directions.json  # Experiment 2 results\n│   ├── exp3_probing.json              # Experiment 3 results\n│   ├── exp4_attention.json            # Experiment 4 results\n│   ├── validation_gpt2medium.json     # Validation results\n│   ├── statistical_analysis.json      # All statistical tests\n│   └── plots/\n│       ├── summary_figure.png         # Key findings summary\n│       ├── exp1_*.png                 # Experiment 1 plots\n│       ├── exp2_*.png                 # Experiment 2 plots\n│       ├── exp3_*.png                 # Experiment 3 plots\n│       └── exp4_*.png                 # Experiment 4 plots\n├── papers/                            # Downloaded research papers (36)\n├── datasets/                          # Compound noun test sets\n└── code/                              # Cloned reference repositories\n```\n\nSee [REPORT.md](REPORT.md) for the full research report with all experimental results, statistical analysis, and discussion.\n","structuredPatch":[{"oldStart":1,"oldLines":2,"newStart":1,"newLines":74,"lines":["-# llm-washing-machine-claude","-Nlp research: Where is Washing Machine stored in LLMs? | Generated by Idea Explorer on 2026-02-07","+# Where is \"Washing Machine\" Stored in LLMs?","+","+An empirical investigation into how compound concepts are represented in large language models. There are far more referenceable concepts than available dimensions in an LLM's residual stream — so how does a model represent multi-token concepts like \"washing machine\"? Does it have a unique direction, or does it just store \"washing\" and let context predict \"machine\"?","+","+## Key Findings","+","+- **Next-token prediction is the primary mechanism**: After seeing \"washing\", GPT-2 predicts \"machine\" as the #1 token with P=0.827 — a 4963x boost over the control word. Median boost across 18 compounds: 20.2x (p=2.1e-4).","+- **Compound directions are 94% reconstructable from constituents**: The compound representation at the word2 position is a linear combination of word1 + word2 directions (R²=0.937 ± 0.020). No dedicated \"washing machine\" direction exists.","+- **More compositional compounds have higher R²**: Spearman r=0.669, p=0.006. Idiomatic compounds like \"hot dog\" (R²=0.888) retain more unique information than compositional ones like \"steel bridge\" (R²=0.965).","+- **No token erasure in GPT-2**: Unlike Feucht et al.'s findings for named entities in Llama-2-7B, word1 identity is perfectly recoverable from the word2 position at every layer.","+- **Compound contexts are still distinguishable**: Despite high R², a linear probe can tell compound from non-compound contexts with 92.2% accuracy (the ~6% unique component carries compound-specific information).","+- **Findings replicate on GPT-2-medium (355M)**: Boost ratios and R² values are consistent across model sizes.","+","+## Reproducing Results","+","+### Environment Setup","+```bash","+# Create and activate virtual environment","+uv venv","+source .venv/bin/activate","+","+# Install dependencies","+uv add torch transformers transformer-lens matplotlib seaborn scipy scikit-learn pandas numpy tqdm einops","+```","+","+### Running Experiments","+```bash","+# Main experiments (GPT-2, ~3 min on GPU)","+python src/experiment.py","+","+# Statistical analysis and visualizations","+python src/analysis.py","+","+# Validation on GPT-2-medium (~2 min on GPU)","+python src/validation_gpt2medium.py","+```","+","+### Hardware Requirements","+- GPU recommended (RTX 3090 or similar; 8GB+ VRAM sufficient for GPT-2)","+- CPU-only: experiments will run but slower (~15 min)","+- Disk: ~500MB for model downloads","+","+## File Structure","+```","+.","+├── REPORT.md                          # Full research report with results","+├── README.md                          # This file","+├── planning.md                        # Research plan and methodology","+├── literature_review.md               # Literature review","+├── resources.md                       # Resource catalog","+├── src/","+│   ├── experiment.py                  # Main experiments (4 experiments)","+│   ├── analysis.py                    # Statistical analysis & visualizations","+│   └── validation_gpt2medium.py       # GPT-2-medium validation","+├── results/","+│   ├── config.json                    # Experiment configuration","+│   ├── exp1_next_token.json           # Experiment 1 results","+│   ├── exp2_residual_directions.json  # Experiment 2 results","+│   ├── exp3_probing.json              # Experiment 3 results","+│   ├── exp4_attention.json            # Experiment 4 results","+│   ├── validation_gpt2medium.json     # Validation results","+│   ├── statistical_analysis.json      # All statistical tests","+│   └── plots/","+│       ├── summary_figure.png         # Key findings summary","+│       ├── exp1_*.png                 # Experiment 1 plots","+│       ├── exp2_*.png                 # Experiment 2 plots","+│       ├── exp3_*.png                 # Experiment 3 plots","+│       └── exp4_*.png                 # Experiment 4 plots","+├── papers/                            # Downloaded research papers (36)","+├── datasets/                          # Compound noun test sets","+└── code/                              # Cloned reference repositories","+```","+","+See [REPORT.md](REPORT.md) for the full research report with all experimental results, statistical analysis, and discussion."]}],"originalFile":"# llm-washing-machine-claude\nNlp research: Where is Washing Machine stored in LLMs? | Generated by Idea Explorer on 2026-02-07\n"}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_013px3TDAsGHwR3Z81xHvj3J","type":"message","role":"assistant","content":[{"type":"text","text":"Now let me verify everything is in order."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2561,"cache_read_input_tokens":101586,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":2561},"output_tokens":4,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"13db5c36-93c1-4753-b86d-fabcd1ec94de"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_013px3TDAsGHwR3Z81xHvj3J","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_012MvjCynAAXPDLCDdZfBbN1","name":"Bash","input":{"command":"ls -la /data/hypogenicai/workspaces/llm-washing-machine-claude/results/ && echo \"---\" && ls -la /data/hypogenicai/workspaces/llm-washing-machine-claude/results/plots/ && echo \"---\" && ls -la /data/hypogenicai/workspaces/llm-washing-machine-claude/src/","description":"Verify all output files exist"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2561,"cache_read_input_tokens":101586,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":2561},"output_tokens":4,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"2b1993e4-615b-4d5f-86b9-8d0f38595d08"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_012MvjCynAAXPDLCDdZfBbN1","type":"tool_result","content":"total 177\ndrwxrwx---  3 haokunliu haokunliu     10 Feb  7 19:56 .\ndrwxrwx--- 17 haokunliu haokunliu     26 Feb  7 20:00 ..\n-rw-rw----  1 haokunliu haokunliu    237 Feb  7 19:47 config.json\n-rw-rw----  1 haokunliu haokunliu  15038 Feb  7 19:47 exp1_next_token.json\n-rw-rw----  1 haokunliu haokunliu  88615 Feb  7 19:47 exp2_residual_directions.json\n-rw-rw----  1 haokunliu haokunliu   3611 Feb  7 19:53 exp3_probing.json\n-rw-rw----  1 haokunliu haokunliu 155012 Feb  7 19:53 exp4_attention.json\ndrwxrwx---  2 haokunliu haokunliu      9 Feb  7 19:56 plots\n-rw-rw----  1 haokunliu haokunliu   1463 Feb  7 19:56 statistical_analysis.json\n-rw-rw----  1 haokunliu haokunliu   1890 Feb  7 19:56 validation_gpt2medium.json\n---\ntotal 2453\ndrwxrwx--- 2 haokunliu haokunliu      9 Feb  7 19:56 .\ndrwxrwx--- 3 haokunliu haokunliu     10 Feb  7 19:56 ..\n-rw-rw---- 1 haokunliu haokunliu 319350 Feb  7 19:55 exp1_detailed_analysis.png\n-rw-rw---- 1 haokunliu haokunliu 219130 Feb  7 19:47 exp1_next_token_prediction.png\n-rw-rw---- 1 haokunliu haokunliu 351982 Feb  7 19:56 exp2_detailed_analysis.png\n-rw-rw---- 1 haokunliu haokunliu 611629 Feb  7 19:47 exp2_residual_directions.png\n-rw-rw---- 1 haokunliu haokunliu 110543 Feb  7 19:53 exp3_layerwise_probing.png\n-rw-rw---- 1 haokunliu haokunliu 324240 Feb  7 19:53 exp4_attention_patterns.png\n-rw-rw---- 1 haokunliu haokunliu 501869 Feb  7 19:56 summary_figure.png\n---\ntotal 51\ndrwxrwx---  2 haokunliu haokunliu     5 Feb  7 19:56 .\ndrwxrwx--- 17 haokunliu haokunliu    26 Feb  7 20:00 ..\n-rw-rw----  1 haokunliu haokunliu 22945 Feb  7 19:55 analysis.py\n-rw-rw----  1 haokunliu haokunliu 39582 Feb  7 19:46 experiment.py\n-rw-rw----  1 haokunliu haokunliu  7432 Feb  7 19:56 validation_gpt2medium.py","is_error":false}]},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"3debb4fb-3107-4834-a995-740a37afca73","tool_use_result":{"stdout":"total 177\ndrwxrwx---  3 haokunliu haokunliu     10 Feb  7 19:56 .\ndrwxrwx--- 17 haokunliu haokunliu     26 Feb  7 20:00 ..\n-rw-rw----  1 haokunliu haokunliu    237 Feb  7 19:47 config.json\n-rw-rw----  1 haokunliu haokunliu  15038 Feb  7 19:47 exp1_next_token.json\n-rw-rw----  1 haokunliu haokunliu  88615 Feb  7 19:47 exp2_residual_directions.json\n-rw-rw----  1 haokunliu haokunliu   3611 Feb  7 19:53 exp3_probing.json\n-rw-rw----  1 haokunliu haokunliu 155012 Feb  7 19:53 exp4_attention.json\ndrwxrwx---  2 haokunliu haokunliu      9 Feb  7 19:56 plots\n-rw-rw----  1 haokunliu haokunliu   1463 Feb  7 19:56 statistical_analysis.json\n-rw-rw----  1 haokunliu haokunliu   1890 Feb  7 19:56 validation_gpt2medium.json\n---\ntotal 2453\ndrwxrwx--- 2 haokunliu haokunliu      9 Feb  7 19:56 .\ndrwxrwx--- 3 haokunliu haokunliu     10 Feb  7 19:56 ..\n-rw-rw---- 1 haokunliu haokunliu 319350 Feb  7 19:55 exp1_detailed_analysis.png\n-rw-rw---- 1 haokunliu haokunliu 219130 Feb  7 19:47 exp1_next_token_prediction.png\n-rw-rw---- 1 haokunliu haokunliu 351982 Feb  7 19:56 exp2_detailed_analysis.png\n-rw-rw---- 1 haokunliu haokunliu 611629 Feb  7 19:47 exp2_residual_directions.png\n-rw-rw---- 1 haokunliu haokunliu 110543 Feb  7 19:53 exp3_layerwise_probing.png\n-rw-rw---- 1 haokunliu haokunliu 324240 Feb  7 19:53 exp4_attention_patterns.png\n-rw-rw---- 1 haokunliu haokunliu 501869 Feb  7 19:56 summary_figure.png\n---\ntotal 51\ndrwxrwx---  2 haokunliu haokunliu     5 Feb  7 19:56 .\ndrwxrwx--- 17 haokunliu haokunliu    26 Feb  7 20:00 ..\n-rw-rw----  1 haokunliu haokunliu 22945 Feb  7 19:55 analysis.py\n-rw-rw----  1 haokunliu haokunliu 39582 Feb  7 19:46 experiment.py\n-rw-rw----  1 haokunliu haokunliu  7432 Feb  7 19:56 validation_gpt2medium.py","stderr":"","interrupted":false,"isImage":false}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01WXz8hZPoyjNLB4AuaJtTJJ","type":"message","role":"assistant","content":[{"type":"text","text":"All files are in place. Let me do the final validation check."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1113,"cache_read_input_tokens":104147,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1113},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"a6f96657-a4f5-4434-b85b-935941225fbf"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01WXz8hZPoyjNLB4AuaJtTJJ","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01CCEruqupdjoh2Xs4XRPhVe","name":"TodoWrite","input":{"todos":[{"content":"Review pre-gathered resources (literature_review.md, resources.md, papers/, datasets/, code/)","status":"completed","activeForm":"Reviewing pre-gathered resources"},{"content":"Phase 0 & 1: Motivation, novelty assessment, and research plan (planning.md)","status":"completed","activeForm":"Writing motivation assessment and research plan"},{"content":"Phase 2: Environment & data setup","status":"completed","activeForm":"Setting up environment and data"},{"content":"Phase 3: Implementation - write experiment code","status":"completed","activeForm":"Implementing experiment code"},{"content":"Phase 4: Run experiments","status":"completed","activeForm":"Running experiments"},{"content":"Phase 5: Analysis - statistical analysis and visualizations","status":"completed","activeForm":"Analyzing results"},{"content":"Phase 6: Final documentation (REPORT.md, README.md)","status":"completed","activeForm":"Writing final documentation"}]}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1113,"cache_read_input_tokens":104147,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1113},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"d6182aad-b6cf-4dc1-aad7-50063df4c3d7"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01CCEruqupdjoh2Xs4XRPhVe","type":"tool_result","content":"Todos have been modified successfully. Ensure that you continue to use the todo list to track your progress. Please proceed with the current tasks if applicable"}]},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"bd188fc0-47fc-4d90-9354-49ad2916655e","tool_use_result":{"oldTodos":[{"content":"Review pre-gathered resources (literature_review.md, resources.md, papers/, datasets/, code/)","status":"completed","activeForm":"Reviewing pre-gathered resources"},{"content":"Phase 0 & 1: Motivation, novelty assessment, and research plan (planning.md)","status":"completed","activeForm":"Writing motivation assessment and research plan"},{"content":"Phase 2: Environment & data setup","status":"completed","activeForm":"Setting up environment and data"},{"content":"Phase 3: Implementation - write experiment code","status":"completed","activeForm":"Implementing experiment code"},{"content":"Phase 4: Run experiments","status":"completed","activeForm":"Running experiments"},{"content":"Phase 5: Analysis - statistical analysis and visualizations","status":"completed","activeForm":"Analyzing results"},{"content":"Phase 6: Final documentation (REPORT.md, README.md)","status":"in_progress","activeForm":"Writing final documentation"}],"newTodos":[{"content":"Review pre-gathered resources (literature_review.md, resources.md, papers/, datasets/, code/)","status":"completed","activeForm":"Reviewing pre-gathered resources"},{"content":"Phase 0 & 1: Motivation, novelty assessment, and research plan (planning.md)","status":"completed","activeForm":"Writing motivation assessment and research plan"},{"content":"Phase 2: Environment & data setup","status":"completed","activeForm":"Setting up environment and data"},{"content":"Phase 3: Implementation - write experiment code","status":"completed","activeForm":"Implementing experiment code"},{"content":"Phase 4: Run experiments","status":"completed","activeForm":"Running experiments"},{"content":"Phase 5: Analysis - statistical analysis and visualizations","status":"completed","activeForm":"Analyzing results"},{"content":"Phase 6: Final documentation (REPORT.md, README.md)","status":"completed","activeForm":"Writing final documentation"}]}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01Rg2P7fNZoU5sbQUucbV8SQ","type":"message","role":"assistant","content":[{"type":"text","text":"All phases are complete. Here's a summary of the research session:\n\n---\n\n## Research Complete: Where is \"Washing Machine\" Stored in LLMs?\n\n### Answer to the Research Question\n\n**\"Washing machine\" is NOT stored as a unique direction in GPT-2's residual stream.** Instead, the model uses two complementary mechanisms:\n\n1. **Next-token prediction boosting** (primary mechanism): After seeing \"washing\", the model predicts \"machine\" as the #1 next token with probability 0.827 — a 4963x boost over a control word like \"red\". This is the dominant mechanism: the model stores the statistical association between \"washing\" and \"machine\".\n\n2. **Compositional representation** (secondary): The compound's residual stream direction is 93.7% reconstructable as a linear combination of the \"washing\" and \"machine\" directions (R² = 0.937). Only ~6% of the representation is unique to the compound context — but this small component is enough to distinguish compound from non-compound contexts (92.2% probe accuracy).\n\n### Key Surprise Findings\n\n- **No token erasure**: Unlike named entities in larger models, GPT-2 retains perfect information about word1 at the word2 position across all layers\n- **\"Guinea pig\" has the strongest association** (boost = 7233x) despite being semantically opaque — the model learns statistical co-occurrence regardless of semantic compositionality\n- **Idiomatic compounds retain more unique information**: \"hot dog\" (R² = 0.888) has more compound-specific representation than \"steel bridge\" (R² = 0.965), consistent with needing extra information for opaque meanings\n- **U-shaped R² across layers**: Intermediate layers (4-5) perform the most compound-specific processing before later layers restore compositional representations\n\n### Deliverables\n- `REPORT.md` — Full research report with all results\n- `README.md` — Project overview and reproduction instructions\n- `src/experiment.py` — 4 experiments (next-token prediction, residual stream directions, probing, attention)\n- `src/analysis.py` — Statistical analysis with 7 plots\n- `src/validation_gpt2medium.py` — Scale validation on GPT-2-medium\n- `results/` — All raw results, statistical tests, and visualizations"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":357,"cache_read_input_tokens":105260,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":357},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","uuid":"a2a62754-5cb1-468b-a45a-5ea9e6eb7058"}
{"type":"result","subtype":"success","is_error":false,"duration_ms":1174152,"duration_api_ms":716844,"num_turns":39,"result":"All phases are complete. Here's a summary of the research session:\n\n---\n\n## Research Complete: Where is \"Washing Machine\" Stored in LLMs?\n\n### Answer to the Research Question\n\n**\"Washing machine\" is NOT stored as a unique direction in GPT-2's residual stream.** Instead, the model uses two complementary mechanisms:\n\n1. **Next-token prediction boosting** (primary mechanism): After seeing \"washing\", the model predicts \"machine\" as the #1 next token with probability 0.827 — a 4963x boost over a control word like \"red\". This is the dominant mechanism: the model stores the statistical association between \"washing\" and \"machine\".\n\n2. **Compositional representation** (secondary): The compound's residual stream direction is 93.7% reconstructable as a linear combination of the \"washing\" and \"machine\" directions (R² = 0.937). Only ~6% of the representation is unique to the compound context — but this small component is enough to distinguish compound from non-compound contexts (92.2% probe accuracy).\n\n### Key Surprise Findings\n\n- **No token erasure**: Unlike named entities in larger models, GPT-2 retains perfect information about word1 at the word2 position across all layers\n- **\"Guinea pig\" has the strongest association** (boost = 7233x) despite being semantically opaque — the model learns statistical co-occurrence regardless of semantic compositionality\n- **Idiomatic compounds retain more unique information**: \"hot dog\" (R² = 0.888) has more compound-specific representation than \"steel bridge\" (R² = 0.965), consistent with needing extra information for opaque meanings\n- **U-shaped R² across layers**: Intermediate layers (4-5) perform the most compound-specific processing before later layers restore compositional representations\n\n### Deliverables\n- `REPORT.md` — Full research report with all results\n- `README.md` — Project overview and reproduction instructions\n- `src/experiment.py` — 4 experiments (next-token prediction, residual stream directions, probing, attention)\n- `src/analysis.py` — Statistical analysis with 7 plots\n- `src/validation_gpt2medium.py` — Scale validation on GPT-2-medium\n- `results/` — All raw results, statistical tests, and visualizations","stop_reason":null,"session_id":"f308b4a2-7eec-4b93-90ab-3f64bf4c16f1","total_cost_usd":2.811600500000001,"usage":{"input_tokens":34,"cache_creation_input_tokens":90257,"cache_read_input_tokens":2283295,"output_tokens":42690,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":"standard","cache_creation":{"ephemeral_1h_input_tokens":90257,"ephemeral_5m_input_tokens":0}},"modelUsage":{"claude-haiku-4-5-20251001":{"inputTokens":26688,"outputTokens":764,"cacheReadInputTokens":0,"cacheCreationInputTokens":6335,"webSearchRequests":0,"costUSD":0.038426749999999996,"contextWindow":200000,"maxOutputTokens":64000},"claude-opus-4-6":{"inputTokens":34,"outputTokens":42690,"cacheReadInputTokens":2283295,"cacheCreationInputTokens":90257,"webSearchRequests":0,"costUSD":2.77317375,"contextWindow":200000,"maxOutputTokens":32000}},"permission_denials":[],"uuid":"c67f0f4b-c23a-42bb-9afc-d71fc1c3c930"}
